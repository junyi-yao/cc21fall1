[{"path":"index.html","id":"welcome","chapter":"1 Welcome!","heading":"1 Welcome!","text":"ideas can add welcome page? Open issue pull request.","code":""},{"path":"community-contribution.html","id":"community-contribution","chapter":"2 Community Contribution","heading":"2 Community Contribution","text":"fairly open-ended assignment provides opportunity receive credit contributing collective learning class, perhaps beyond. reflect minimum 3 hours work. complete assignment must submit short description contribution. appropriate, attach relevant files.many ways can contribute:organize lead workshop particular topic (date may assignment due date need schedule )help students find final project partnersgive well-rehearsed 5 minute lightning talk class datavis topic (theory tool) (email set date – may assignment due date need schedule )create video tutorial (length)create cheatsheet resourcewrite tutorial tool ’s well documentedbuild viz product (ex. htmlwidget RStudio add-) class use[idea](Note: translations allowed)may draw expand existing resources. , critical cite sources.","code":""},{"path":"community-contribution.html","id":"important-logistics","chapter":"2 Community Contribution","heading":"2.1 IMPORTANT LOGISTICS","text":"","code":""},{"path":"community-contribution.html","id":"groups","chapter":"2 Community Contribution","heading":"2.1.1 Groups","text":"may work partner choosing. work alone, need join group 1, simply submit work CourseWorks solo assignment.work partner, add group CC page People tab. Ed Discussion can used find partners similar interests.","code":""},{"path":"community-contribution.html","id":"what-to-submit","chapter":"2 Community Contribution","heading":"2.1.2 What to submit","text":"cases something tangible upload, tutorial, cheatsheet, etc. Alternatively may submit link material online (YouTube video, etc.) ’s nothing tangible include longer description (see 2.).cases something tangible upload, tutorial, cheatsheet, etc. Alternatively may submit link material online (YouTube video, etc.) ’s nothing tangible include longer description (see 2.).explanation motivation project, need addresses, evaluation project including learned / might differently next time. (1/2 page)explanation motivation project, need addresses, evaluation project including learned / might differently next time. (1/2 page)","code":""},{"path":"community-contribution.html","id":"submitting-your-assignment","chapter":"2 Community Contribution","heading":"2.1.3 Submitting your assignment","text":"must submit assignment twice: CourseWorks (can graded) class, details follow.CourseWorks submission (assignment): submit work .Rmd rendered .pdf .html file, just problem sets. work lend format, write assignment text box .CourseWorks submission (assignment): submit work .Rmd rendered .pdf .html file, just problem sets. work lend format, write assignment text box .Class (GitHub) submission: detail provided separate assignment.Class (GitHub) submission: detail provided separate assignment.","code":""},{"path":"community-contribution.html","id":"grading","chapter":"2 Community Contribution","heading":"2.1.4 Grading","text":"graded quality work, originality, effort invested. sources used must cited.","code":""},{"path":"github-submission-instructions.html","id":"github-submission-instructions","chapter":"3 GitHub submission instructions","heading":"3 GitHub submission instructions","text":"chapter gives information need upload community contribution. Please read entire document carefully making submission. particular note fact bookdown requires different .Rmd format ’re used , must make changes beginning file described submitting.","code":""},{"path":"github-submission-instructions.html","id":"background","chapter":"3 GitHub submission instructions","heading":"3.1 Background","text":"web site makes use bookdown package render collection .Rmd files nicely formatted online book chapters subchapters. job submit slightly modified version community contribution .Rmd file GitHub repository source files web site stored. backend, admins divide chapters book sections order .community contribution different format, create short .Rmd file explains , includes links relevant files, slides, etc. can post GitHub repo (another online site.)","code":""},{"path":"github-submission-instructions.html","id":"preparing-your-.rmd-file","chapter":"3 GitHub submission instructions","heading":"3.2 Preparing your .Rmd file","text":"submit ONE Rmd file.completing modifications, .Rmd look like sample .Rmd.Create concise, descriptive name project. instance, name base_r_ggplot_graph something similar work contrasting/working base R graphics ggplot2 graphics. Check .Rmd filenames file make sure name isn’t already taken. project name words joined underscores, white space. Use .Rmd .rmd. addition, letters must lowercase. Create copy .Rmd file new name.Create concise, descriptive name project. instance, name base_r_ggplot_graph something similar work contrasting/working base R graphics ggplot2 graphics. Check .Rmd filenames file make sure name isn’t already taken. project name words joined underscores, white space. Use .Rmd .rmd. addition, letters must lowercase. Create copy .Rmd file new name.Completely delete YAML header (section top .Rmd includes name, title, date, output, etc.) including --- line.Completely delete YAML header (section top .Rmd includes name, title, date, output, etc.) including --- line.Choose short, descriptive, human readable title project title show table contents – look examples panel left. Capitalize first letter (“sentence case”). first line document, enter single hashtag, followed single whitespace, title. important follow format bookdown renders title header. use single # headers anywhere else document.Choose short, descriptive, human readable title project title show table contents – look examples panel left. Capitalize first letter (“sentence case”). first line document, enter single hashtag, followed single whitespace, title. important follow format bookdown renders title header. use single # headers anywhere else document.second line blank, followed name(s):\n# Base R vs. ggplot2\n\nAaron Burr Alexander Hamilton\n\ncontent starts . second line blank, followed name(s):project requires data, please use built-dataset read directly URL, :\ndf <- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")  absolutely must include data file, please use small one, many reasons desirable keep repository size small possible.project requires data, please use built-dataset read directly URL, :df <- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")  absolutely must include data file, please use small one, many reasons desirable keep repository size small possible.included setup chunk .Rmd file, please remember remove label setup chunk, .e., use:\n{r, include=FALSE}\ninstead :\n{r setup, include=FALSE}included setup chunk .Rmd file, please remember remove label setup chunk, .e., use:instead :project requires libraries installed included document, please adhere following conventions. evaluate install.packages() statements document. Consumers .Rmd file won’t want packages get installed knit document. Include library() statements top .Rmd file, title, name, setup, content. chapter requires installation package source (GitHub installation), please add comment identifying . Please mention well PR. example library() section install statements won’t evaluated:\n\n# remotes::install_github(\"twitter/AnomalyDetection\")\nlibrary(\"AnomalyDetection\") # must installed sourceIf project requires libraries installed included document, please adhere following conventions. evaluate install.packages() statements document. Consumers .Rmd file won’t want packages get installed knit document. Include library() statements top .Rmd file, title, name, setup, content. chapter requires installation package source (GitHub installation), please add comment identifying . Please mention well PR. example library() section install statements won’t evaluated:developed .Rmd file moving library() statements rest file content, highly recommended knit review document . may change namespace available section code development, causing function work exhibit unexpected behavior.file contain getwd() / setwd() calls (never use scripts anyway!) write statements.Want get fancy? See optional tweaks section .","code":"# Base R vs. ggplot2\n\nAaron Burr and Alexander Hamilton\n\nYour content starts here. {r, include=FALSE}{r setup, include=FALSE}\n# remotes::install_github(\"twitter/AnomalyDetection\")\nlibrary(\"AnomalyDetection\") # must be installed from source"},{"path":"github-submission-instructions.html","id":"submission-steps","chapter":"3 GitHub submission instructions","heading":"3.3 Submission steps","text":"submit work, following “Workflow #4” – submitting pull request someone else’s repository write access. Instructions available lecture slides topic well tutorial. repeated abbreviated form, specific instructions naming conventions, content information, important details.Fork cc21fall1 repo (repo) GitHub account.Fork cc21fall1 repo (repo) GitHub account.Clone/download forked repo local computer.Clone/download forked repo local computer.Create new branch name project name, case sample_project. skip step. merge PR doesn’t come branch. already forgot , check tutorial fix .Create new branch name project name, case sample_project. skip step. merge PR doesn’t come branch. already forgot , check tutorial fix .Copy modified .Rmd file name root directory branch. example, sample_project.Rmd.Copy modified .Rmd file name root directory branch. example, sample_project.Rmd.include .html file. (order bookdown package work, .Rmd files rendered behind scenes.)include .html file. (order bookdown package work, .Rmd files rendered behind scenes.)[OPTIONAL] resources (images) included project, create folder resources/. example, resources/sample_project/. Put resources files . sure change links .Rmd include resources/.../, example:\n![Test Photo](resources/sample_project/pumpkins.jpg)[OPTIONAL] resources (images) included project, create folder resources/. example, resources/sample_project/. Put resources files . sure change links .Rmd include resources/.../, example:![Test Photo](resources/sample_project/pumpkins.jpg)ready submit project, push branch remote repo. Follow tutorial create pull request.ready submit project, push branch remote repo. Follow tutorial create pull request.point back forth begin team managing pull requests. asked make changes, simply make changes local branch, save, commit, push GitHub. new commits added pull request; need , , create new pull request. (, based circumstances, make sense close pull request start new one, tell .)point back forth begin team managing pull requests. asked make changes, simply make changes local branch, save, commit, push GitHub. new commits added pull request; need , , create new pull request. (, based circumstances, make sense close pull request start new one, tell .)pull request merged, ’s fine delete local clone (folder) well forked repository GitHub account.pull request merged, ’s fine delete local clone (folder) well forked repository GitHub account.","code":""},{"path":"github-submission-instructions.html","id":"optional-tweaks","chapter":"3 GitHub submission instructions","heading":"3.4 Optional tweaks","text":"prefer links chapter open new tabs, add {target=\"_blank\"} link, :\n[edav.info](edav.info){target=\"_blank\"}prefer links chapter open new tabs, add {target=\"_blank\"} link, :[edav.info](edav.info){target=\"_blank\"}Note headers (##, ###, etc.) converted numbered headings : ## –> 3.1 ### –> 3.1.1  headings appear chapter subheadings sub-subheadings navigation panel left. Think logical structure users navigate chapter. recommend using ## ### headings since “sub-sub-subheadings” 4.1.3.4 generally unnecessary look messy.Note headers (##, ###, etc.) converted numbered headings : ## –> 3.1 ### –> 3.1.1  headings appear chapter subheadings sub-subheadings navigation panel left. Think logical structure users navigate chapter. recommend using ## ### headings since “sub-sub-subheadings” 4.1.3.4 generally unnecessary look messy.Unfortunately, ’s simple way preview chapter ’s actually merged project. (bookdown preview_chapter() option works entire book rendered least become complex require packages project grows.) really want preview , fork clone minimal bookdown repo, add .Rmd file, click “Build book” button Build tab (next Git), open .html files _book folder web browser see rendered book.  ’re interested bookdown options, see official reference book.  useful tweaks share? Submit issue PR.Unfortunately, ’s simple way preview chapter ’s actually merged project. (bookdown preview_chapter() option works entire book rendered least become complex require packages project grows.) really want preview , fork clone minimal bookdown repo, add .Rmd file, click “Build book” button Build tab (next Git), open .html files _book folder web browser see rendered book.  ’re interested bookdown options, see official reference book.  useful tweaks share? Submit issue PR.","code":""},{"path":"github-submission-instructions.html","id":"faq","chapter":"3 GitHub submission instructions","heading":"3.5 FAQ","text":"","code":""},{"path":"github-submission-instructions.html","id":"what-should-i-expect-after-creating-a-pull-request","chapter":"3 GitHub submission instructions","heading":"3.5.1 What should I expect after creating a pull request?","text":"Within week create pull request, apply label assign classmate “PR merger” review files submit see meet requirements.Within week create pull request, apply label assign classmate “PR merger” review files submit see meet requirements.take time can process pull requests, long see pull request repo, don’t worry.take time can process pull requests, long see pull request repo, don’t worry.PR merger contacts regarding pull request, usually means files fail meet requirements. explain wrong, please fix soon possible.PR merger contacts regarding pull request, usually means files fail meet requirements. explain wrong, please fix soon possible.","code":""},{"path":"github-submission-instructions.html","id":"what-if-i-catch-mistakes-before-my-pull-request-is-merged","chapter":"3 GitHub submission instructions","heading":"3.5.2 What if I catch mistakes before my pull request is merged?","text":"Just make changes branch, commit push GitHub. automatically added pull request.","code":""},{"path":"github-submission-instructions.html","id":"what-if-i-catch-mistakes-after-my-pull-request-is-merged","chapter":"3 GitHub submission instructions","heading":"3.5.3 What if I catch mistakes after my pull request is merged?","text":"may submit additional pull requests fix material site. edits small, fixing typos, easiest make edits directly GitHub, following instructions. merge first pull requests edits, please patient.","code":""},{"path":"github-submission-instructions.html","id":"other-questions","chapter":"3 GitHub submission instructions","heading":"3.5.4 Other questions","text":"additional questions, please ask Discussions section respond.Thank contributions!","code":""},{"path":"sample-project.html","id":"sample-project","chapter":"4 Sample project","heading":"4 Sample project","text":"Joe Biden Donald TrumpThis chapter gives sample layout Rmd file.Test Photo","code":""},{"path":"introduction-to-the-lattice-package.html","id":"introduction-to-the-lattice-package","chapter":"5 Introduction to the lattice package","heading":"5 Introduction to the lattice package","text":"Eubin ParkThe lattice package data visualization package created Deepayan Sarkar. add-package improves defaults base R, emphasis displaying multivariate data - supporting creation trellis graphs. strength lattice package mainly ability manage dependent data.general format plotting using lattice functions : graph_type(formula, data). main workhorse function lattice package xyplot().","code":"\nlibrary(lattice)\nlibrary(car)"},{"path":"introduction-to-the-lattice-package.html","id":"producing-a-plot-in-lattice","chapter":"5 Introduction to the lattice package","heading":"5.1 Producing a Plot in Lattice","text":"can begin creating basic plots Lattice - scatterplot. Lattice, done using xyplot. example, use iris dataset.type scatterplot familiar many. seen , can see basic method plotting using xyplot() symbolic formula y ~ x, x independent variable y dependent variable.","code":"\ndata(iris)\nxyplot(Sepal.Length ~ Sepal.Width, data = iris,\n       xlab = \"Sepal Width\",\n       ylab = \"Sepal Length\")"},{"path":"introduction-to-the-lattice-package.html","id":"plotting-by-groups","chapter":"5 Introduction to the lattice package","heading":"5.2 Plotting by Groups","text":"2 main ways going plotting multivariate data lattice.1. Superposition:\ndata plotted region graph, distinct groups able categorized varying plot features color, shapes, etc. use superposition plots, groups argument must specified.2. Juxtaposition:\nData plotted separate regions larger graph. use juxtaposition plots, one must specify conditioning statement, : y ~ x | z, z conditioning variable.difference superposition juxtaposition can shown :Superposition:Juxtaposition:seen , real difference plotting two graphs whether one uses groups argument (Supposition) conditioning statement (Juxtaposition), Lattice able create two different graphs small difference.many problems supposition plot juxtaposition plot overcomes. example, good deal -plotting first plot, result difficult distinguish clear trends within species group. However, problems seen juxtaposition plot.sort advanrage becomes much conspicuous dealing larger multivariate datasets. next example, use quakes dataset.example, created shingles order essentially bin data. shingle contains data subset variable created .example, clear see advantages using juxtaposition method plotting.want re-arrange panels plot, can use layout argument. argument takes vector three values: number rows, number columns, number pages.However, using argument, skewed shapes plots. can fix using aspect argument, controls ratio plots.wanted fit regression lines panel, can use panel function argument xyplot function.","code":"\nxyplot(Sepal.Length ~ Sepal.Width, data=iris, \n       groups=iris$Species, # use groups argument\n       auto.key=list(text=c(\"setosa\", \"versicolor\", \"virginica\")),\n       xlab = \"Sepal Width\",\n       ylab = \"Sepal Length\")\nxyplot(Sepal.Length ~ Sepal.Width | Species, data=iris, # add conditioning statement\n       pch=1, col=\"black\",\n       xlab = \"Sepal Width\",\n       ylab = \"Sepal Length\")\ndata(quakes)\n# Create shingles\nDepth = equal.count(quakes$depth, number = 8, overlap = .1)\n\n# Plot graph using supposition\nxyplot(lat ~ long, data = quakes,\n       groups = Depth,\n       xlab = \"Longitude\",\n       ylab = \"Latitude\")\n# Plot graph using juxtaposition\nxyplot(lat ~ long | Depth, data = quakes,\n       xlab = \"Longtitude\",\n       ylab = \"Latitude\")\n# Use layout argument\nxyplot(lat ~ long | Depth, data = quakes,\n       layout = c(3, 3, 1),\n       xlab = \"Longtitude\",\n       ylab = \"Latitude\")\n# Use aspect argument\nxyplot(lat ~ long | Depth, data = quakes,\n       aspect = 1,\n       layout = c(3, 3, 1),\n       xlab = \"Longtitude\",\n       ylab = \"Latitude\")\n# Use the panel function argument\nxyplot(lat ~ long | Depth, data = quakes,\n       panel = function(x,y,subscripts,...){\n           panel.points(x,y,...)\n           panel.lmline(x,y,...) })"},{"path":"introduction-to-the-lattice-package.html","id":"histograms-and-density-plots","chapter":"5 Introduction to the lattice package","heading":"5.3 Histograms and Density Plots","text":"Lattice offers options , histograms density plots. example, use Duncan dataset car package.make histogram lattice package, use histogram() function.make density plot lattice package, use densityplot() function.can even combine histograms density plots using panel function argument. , can split data separate panels, useful multivariate data.","code":"\ndata(Duncan)\nhistogram(~ prestige, data=Duncan, \n          type=\"count\", # can take 'count', 'percent', or 'density'\n          nint = 10, # number of bins\n          endpoints = c(0, 100)\n          )\ndensityplot(~ prestige, data = Duncan,\n            col = \"black\",\n            plot.points = F # specify whether to have data points\n            )\nb <- with(Duncan, do.breaks(range(income), 3))\n\nxyplot(~income | type, data=Duncan,\n       xlim = range(b), ylim = c(0, 0.04),\n       panel = function(x){\n           panel.histogram(x, \n                           breaks = b, \n                           col=\"gray80\")\n           panel.densityplot(x, \n                             darg =list(n=100),\n                             col=\"red\",\n                             lwd=1.5,\n                             plot.points=F)\n       })"},{"path":"introduction-to-the-lattice-package.html","id":"boxplots-violinplots-and-dotplots","chapter":"5 Introduction to the lattice package","heading":"5.4 Boxplots, Violinplots, and Dotplots","text":"options offered Lattice package include boxplots dotplots. example, use ToothGrowth dataset.make boxplot, use bwplot() function. always lattice package, can use conditioning statement create juxtaposing panels.make violin plot, use bwplot() function specify panel argument.make dotplot, use dotplot() function.","code":"\nbwplot(len ~ supp | dose,  data = ToothGrowth,\n       layout = c(3, 1),\n        xlab = \"Dose\", ylab = \"Length\")\nbwplot(len ~ supp | dose,  data = ToothGrowth,\n       layout = c(3, 1), \n       panel = panel.violin, # specify panel argument to make violin plot\n        xlab = \"Dose\", ylab = \"Length\")\ndotplot(len ~ supp | dose,  data = ToothGrowth,\n       layout = c(3, 1),\n        xlab = \"Dose\", ylab = \"Length\")"},{"path":"introduction-to-the-lattice-package.html","id":"trivariate-plots","chapter":"5 Introduction to the lattice package","heading":"5.5 Trivariate Plots","text":"One option displaying trivariate continuous data utilize 3 axes. can done three-dimensional scatterplot.lattice package, one can create plot using cloud() function. function takes symbolic formula first argument, form: z ~ x * y, x, z, y three continuous variables.example use quakes dataset .view data different perspective, can rotate plot using screen argument. can play feature find best view data.Unfortunately, interactive options available Lattice package.","code":"\ncloud(depth ~ lat * long, data=quakes)\ncloud(depth ~ lat * long, data=quakes,\n      screen = list(z = 105, x = -70))"},{"path":"introduction-to-the-lattice-package.html","id":"pros-and-cons-of-lattice","chapter":"5 Introduction to the lattice package","heading":"5.6 Pros and Cons of Lattice","text":"Now basic overview kinds things lattice package can , let’s discuss advantages disadvantages data visualization package.Pros:good allowing one visualize multivariate data, .e. comparing variable y changes variable x across levels variable zMany settings set automatically entire plot created .Cons:Can difficult flesh entire plot one method callCannot add elements plot created; modified.","code":""},{"path":"graph-animation-with-gganimate-and-after-effects.html","id":"graph-animation-with-gganimate-and-after-effects","chapter":"6 Graph animation with gganimate and After Effects","heading":"6 Graph animation with gganimate and After Effects","text":"Anh-Vu Nguyen\nsite explains graph animation gganimate effects\nlink: https://anhvung.github.io/EDAV-CC/\n","code":""},{"path":"interactive-plots.html","id":"interactive-plots","chapter":"7 Interactive Plots","heading":"7 Interactive Plots","text":"Zhirui Yang","code":"\n# Libraries\n# Make sure these packages are installed before running code.\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(dygraphs)\nlibrary(xts)\nlibrary(dplyr)\nlibrary(igraph)\nlibrary(networkD3)"},{"path":"interactive-plots.html","id":"why-use-interactive-plots","chapter":"7 Interactive Plots","heading":"7.1 Why use interactive plots","text":"general, use ggplot2 plot static graph. way, can know data macroscopic perspective. want know subtle contents, like exact difference two points, still need write code find values two points. However, tedious step can avoided interactive graph. Interactive graphs important data analysis. can check value every point graph, also zoom graph check details.tutorial, introduce frequently used plot, provide examples. Moreover, introduce important parameters, can help customize plot.beginning tutorial, packages use . installed , can use install.packages(‘package_name’) install .","code":""},{"path":"interactive-plots.html","id":"interactive-scatter-plot","chapter":"7 Interactive Plots","heading":"7.2 Interactive Scatter plot","text":"Plotly’s R graphing library makes interactive, publication-quality graphs. Examples make line plots, scatter plots, area charts, bar charts, error bars, box plots, histograms, heatmaps, subplots, multiple-axes, 3D (WebGL based) charts.give examples show draw Scatterplot Plotly.","code":""},{"path":"interactive-plots.html","id":"compare-plotly-and-ggplot2","chapter":"7 Interactive Plots","heading":"7.2.1 Compare Plotly and ggplot2","text":"use iris dataset, provided natively R. part dataset.draw Scatterplot Sepal.Length vs Sepal.Width.can check value data point basic scatterplot, can interactive scatterplot.","code":"\nhead(iris)##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\n# basic scatterplot\nggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + \n  geom_point()\n# interactive scatterplot\nfig <- plot_ly(\n  data = iris, x = ~Sepal.Length, y = ~Petal.Length)\nfig"},{"path":"interactive-plots.html","id":"styled-scatter-plot","chapter":"7 Interactive Plots","heading":"7.2.2 Styled Scatter Plot","text":"can customize Scatter Plot using parameters plot_ly. Plotly three main attributions including plot_ly, add_trace layout. Every aspect Plotly chart (colors, grid-lines, data, ) corresponding key attributions.","code":""},{"path":"interactive-plots.html","id":"plot_ly","chapter":"7 Interactive Plots","heading":"7.2.2.1 plot_ly","text":"plot_ly used 1.1. function basically draw main content plot. basic structure .","code":"\n# plot_ly(\n# data,\n# type = \"scatter\", # all \"scatter\" attributes. We don't need to change it for scatter plot\n# x = ~x, # x of scatter plot\n# y = ~y, # y of scatter plot\n# marker = list(\n#   size = 5,\n#   color=\"#264E86\") # marker is used to change color, size and so on.\n# ) \nfig <- plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length,\n               marker = list(size = 10,\n                             color = 'red',\n                             line = list(color = 'blue',\n                                         width = 2)))\nfig"},{"path":"interactive-plots.html","id":"add_trace","chapter":"7 Interactive Plots","heading":"7.2.2.2 add_trace","text":"Plotly’s graph made two parts. One trace, can regard key component graph. example, trace scatter plot points graph, trace line plot line graph. can regard plot plot_ly background. sometimes want add multiple modes plot, need add_trace. basic structure , similar plot_ly.use example understand add_trace works.","code":"\n# add_trace(x = ~x2, # x2 of new trace\n#           y = ~y2, # y2 of new trace\n#           mode = 'lines', # type of mode\n#           line = list(\n#             color = \"#5E88FC\",  \n#             dash = \"dashed\"\n#             )\n# )\nfig <- plot_ly(data = iris, x = ~Sepal.Length)\nfig <- fig %>% add_trace(x = ~Sepal.Length, y = ~Petal.Length, name = 'Petal.Length',mode = 'markers', color = \"red\")\nfig <- fig %>% add_trace(x = ~Sepal.Length, y = ~Sepal.Width, name = 'Sepal.Width',mode = 'markers', color = \"blue\")\nfig <- fig %>% add_trace(x = ~Sepal.Length, y = ~Petal.Width, name = 'Petal.Width',mode = 'markers', color = \"green\")\nfig"},{"path":"interactive-plots.html","id":"layout","chapter":"7 Interactive Plots","heading":"7.2.2.3 layout","text":"layout used rest chart, like title, xaxis, annotations. basic structure .use example understand layout works.","code":"\n# layout(\n#   title = \"Unemployment\", # add title\n#   xaxis = list( # add xaxis\n#     title = \"Time\",\n#     showgrid = F),\n#   yaxis = list( # add xaxis\n#     title = \"uidx\")\n# )\nfig <- plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length, color = ~Species)\nfig <- fig %>% layout(title = 'Styled Scatter',\n         yaxis = list(title = \"y - Petal.Length\"),\n         xaxis = list(title = \"x - Sepal.Length\")\n         )\nfig"},{"path":"interactive-plots.html","id":"interactive-time-series-chart","chapter":"7 Interactive Plots","heading":"7.3 Interactive time series chart","text":"","code":""},{"path":"interactive-plots.html","id":"ggplot2-and-plotly","chapter":"7 Interactive Plots","heading":"7.3.1 ggplot2 and plotly","text":"two ways create interactive time series chart. first way creat line plot ggplot2, use plotly turn ggplot2 chart object interactive. example .can also just use plotly. make area plot interior filling set fill “tozeroy” call second trace. informations options fill option checkout https://plotly.com/r/reference/#scatter-fill.","code":"\n# Load dataset from github\ndata <- read.table(\"https://raw.githubusercontent.com/holtzy/data_to_viz/master/Example_dataset/3_TwoNumOrdered.csv\", header=T)\ndata$date <- as.Date(data$date)\n\n# Usual area chart\np <- data %>%\n  ggplot( aes(x=date, y=value)) +\n    geom_area(fill=\"red\", alpha=0.5) +\n    geom_line(color=\"blue\") +\n    ylab(\"bitcoin price ($)\")\np\n# Turn it interactive with ggplotly\np <- ggplotly(p)\np\nplot_ly(data=data, x=~date, y=~value, type=\"scatter\", mode=\"line\", fill='tozeroy')"},{"path":"interactive-plots.html","id":"dygraphs-and-xts","chapter":"7 Interactive Plots","heading":"7.3.2 dygraphs and xts","text":"dygraphs useful R package creating interactive time series plot. dygraphs package R interface dygraphs JavaScript charting library. provides rich facilities charting time-series data R, including: rich interactive features including zoom/pan series/point highlighting, automatically plots xts time series objects (object convertible xts), highly configurable axis series display (including optional second Y-axis) . use plot functions.input data dygraphs, transform data frame xts format (xts=eXtensible Time Series).can select interval data analysis, example.","code":"\nts <- xts(x = data$value, order.by = data$date)\n\n# Make the chart\np <- dygraph(ts)\np"},{"path":"interactive-plots.html","id":"interactive-network-diagram","chapter":"7 Interactive Plots","heading":"7.4 Interactive network diagram","text":"networkD3 useful creating interactive network diagrams. input contains edge, specifies two nodes.","code":""},{"path":"interactive-plots.html","id":"simple-network","chapter":"7 Interactive Plots","heading":"7.4.1 Simple Network","text":"can use simpleNetwork networkD3.","code":"\n# Create fake data\nsrc <- c(\"A\", \"A\", \"A\", \"A\",\n        \"B\", \"B\", \"C\", \"C\", \"D\")\ntarget <- c(\"B\", \"C\", \"D\", \"J\",\n            \"E\", \"F\", \"G\", \"H\", \"I\")\nnetworkData <- data.frame(src, target)\n\n# Plot\nsimpleNetwork(networkData)"},{"path":"interactive-plots.html","id":"customized-network","chapter":"7 Interactive Plots","heading":"7.4.2 Customized Network","text":"Many option available customize interactive diagram. options allow customize node, links label feature, like nodeColour fontSize. example, linkDistance controls numeric distance links pixels. charge controls numeric value indicating either strength node repulsion (negative value) attraction (positive value). fontSize fontFamily can control label. can use help(simpleNetwork) better understanding.can also customized complicated networks using forceNetwork. forceNetwork different input simpleNetwork. two main input Links Nodes. Links data frame object links nodes. include Source Target link. numbered starting 0. Nodes data frame containing node id properties nodes. ID specified nodes must order Source variable column Links data frame. Currently grouping variable allowed. examlpe forceNetwork.","code":"\n# create a dataset:\ndata <- data_frame(\n  from=c(\"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"D\", \"E\", \"K\", \"L\", \"M\", \"M\"),\n  to=c(\"C\", \"F\", \"D\", \"F\", \"G\", \"E\", \"L\", \"F\", \"E\", \"G\", \"Z\", \"J\", \"M\", \"L\", \"Z\")\n)\n\n# Plot\np <- simpleNetwork(data, height=\"100px\", width=\"100px\",        \n        Source = 1,                 # column number of source\n        Target = 2,                 # column number of target\n        linkDistance = 20,          # distance between node. Increase this value to have more space between nodes\n        charge = -900,                # numeric value indicating either the strength of the node repulsion (negative value) or attraction (positive value)\n        fontSize = 14,               # size of the node names\n        fontFamily = \"serif\",       # font og node names\n        linkColour = \"#666\",        # colour of edges, MUST be a common colour for the whole graph\n        nodeColour = \"#69b3a2\",     # colour of nodes, MUST be a common colour for the whole graph\n        opacity = 0.9,              # opacity of nodes. 0=transparent. 1=no transparency\n        zoom = T                    # Can you zoom on the figure?\n        )\np\nhead(MisLinks)##   source target value\n## 1      1      0     1\n## 2      2      0     8\n## 3      3      0    10\n## 4      3      2     6\n## 5      4      0     1\n## 6      5      0     1\nhead(MisNodes)##              name group size\n## 1          Myriel     1   15\n## 2        Napoleon     1   20\n## 3 Mlle.Baptistine     1   23\n## 4    Mme.Magloire     1   30\n## 5    CountessdeLo     1   11\n## 6        Geborand     1    9\nforceNetwork(Links = MisLinks, Nodes = MisNodes,\n            Source = \"source\", Target = \"target\",\n            Value = \"value\", NodeID = \"name\",\n            Group = \"group\", opacity = 0.8)"},{"path":"interactive-plots.html","id":"reference","chapter":"7 Interactive Plots","heading":"7.5 Reference","text":"https://www.r-graph-gallery.com/index.htmlhttps://www.r-bloggers.com/2020/05/7-useful-interactive-charts--r/http://christophergandrud.github.io/networkD3/https://plotly.com/r/","code":""},{"path":"r-vs.-python-visualization-cheatsheet.html","id":"r-vs.-python-visualization-cheatsheet","chapter":"8 R vs. Python Visualization Cheatsheet","heading":"8 R vs. Python Visualization Cheatsheet","text":"Dawei Minhui LiaoWe found primarily work R data visualization may familiar graphs Python. lot differences R Python, usually use ggplot2 R, closest comparable libraries Matplotlib Seaborn working Python. Therefore, made PDF version cheat sheet people primarily use R Python need use one another programming language make plots, easily compare difference graphs.Click following link check cheat sheet:https://github.com/Aaralyn-Liao/EDAV_Contribution_CC8/blob/main/r_vs_python_visualization.pdf","code":""},{"path":"rpackage-waffle-cheatsheet.html","id":"rpackage-waffle-cheatsheet","chapter":"9 Rpackage waffle cheatsheet","heading":"9 Rpackage waffle cheatsheet","text":"Yibo ChenThis project mainly include pdf version cheatsheet R package waffle.Take look cheatsheet using link :\nhttps://github.com/ChenYb9807/cu_edav_cc/blob/main/Community%20Contribution.pdf","code":""},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"r-cheatsheet-on-data-transforamtion-and-exploration","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10 R cheatsheet on data transforamtion and exploration","text":"Sai Krupa JangalaFew Pointers:purpose cheatsheet describe basic data operations start new project. also includes different types data transformations, explorations management.use data frames throughtout cheatsheet.use packages commonly used R. using packages different purposes.Different datasets used best illustrate transformation, management exploration.data sets used openintro::fastfood , openintro::seatlepets, cars, openintro::ames mtcars.Every chunk code loads data, ’s , means used data previous chunk.","code":""},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"required-packages","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.1 Required packages","text":"packages commonly R used following cheatsheet. using packages different purposes.","code":"\n#install.packages(\"tidyverse\")\n#install.packages(\"dplyr\")\n#install.packages(\"reshape\")\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(reshape)"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"output-the-head-tail-and-sample-of-the-dataframe.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.2 Output the head, tail and sample of the dataframe.","text":"Head - get first 5 rows dataframe.Tail - get last 5 rows dataframe","code":"\ndata <- cars\nhead(data, n=5)##   speed dist\n## 1     4    2\n## 2     4   10\n## 3     7    4\n## 4     7   22\n## 5     8   16\ntail(data, n=5)##    speed dist\n## 46    24   70\n## 47    24   92\n## 48    24   93\n## 49    24  120\n## 50    25   85"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"selection-of-only-a-few-columns-from-a-dataframe.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.3 Selection of only a few columns from a dataframe.","text":"Select restaurant, item calorie columns fastfood dataset. Two variations shown .can see , transformations produce result.","code":"\ndata <- openintro::fastfood\n# Variation 1\ndata <- data[, c(\"restaurant\",\"item\",\"calories\")]\n# Variation 2\ndata_1 <- select(data, c(restaurant, item, calories))\nhead(data)## # A tibble: 6 × 3\n##   restaurant item                                      calories\n##   <chr>      <chr>                                        <dbl>\n## 1 Mcdonalds  Artisan Grilled Chicken Sandwich               380\n## 2 Mcdonalds  Single Bacon Smokehouse Burger                 840\n## 3 Mcdonalds  Double Bacon Smokehouse Burger                1130\n## 4 Mcdonalds  Grilled Bacon Smokehouse Chicken Sandwich      750\n## 5 Mcdonalds  Crispy Bacon Smokehouse Chicken Sandwich       920\n## 6 Mcdonalds  Big Mac                                        540\nhead(data_1)## # A tibble: 6 × 3\n##   restaurant item                                      calories\n##   <chr>      <chr>                                        <dbl>\n## 1 Mcdonalds  Artisan Grilled Chicken Sandwich               380\n## 2 Mcdonalds  Single Bacon Smokehouse Burger                 840\n## 3 Mcdonalds  Double Bacon Smokehouse Burger                1130\n## 4 Mcdonalds  Grilled Bacon Smokehouse Chicken Sandwich      750\n## 5 Mcdonalds  Crispy Bacon Smokehouse Chicken Sandwich       920\n## 6 Mcdonalds  Big Mac                                        540"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"get-the-column-names","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.4 Get the column names","text":"Generate column names data frame","code":"\ndata <- openintro::fastfood\nnames(data)##  [1] \"restaurant\"  \"item\"        \"calories\"    \"cal_fat\"     \"total_fat\"  \n##  [6] \"sat_fat\"     \"trans_fat\"   \"cholesterol\" \"sodium\"      \"total_carb\" \n## [11] \"fiber\"       \"sugar\"       \"protein\"     \"vit_a\"       \"vit_c\"      \n## [16] \"calcium\"     \"salad\""},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"drop-one-or-more-columns.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.5 Drop one or more columns.","text":"Drop columns restaurant, item, calories data. can observe, column names dropped.","code":"\ndata <- openintro::fastfood\ndata <- select(data, -c(restaurant, item, calories))\nnames(data)##  [1] \"cal_fat\"     \"total_fat\"   \"sat_fat\"     \"trans_fat\"   \"cholesterol\"\n##  [6] \"sodium\"      \"total_carb\"  \"fiber\"       \"sugar\"       \"protein\"    \n## [11] \"vit_a\"       \"vit_c\"       \"calcium\"     \"salad\""},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"transformation-using-the-transform-function-in-r","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.6 Transformation using the transform() function in R","text":"creating new dataframe changing speed column. transformed multiplying 100Here transformed original dataframe creating new column.","code":"\ndata <- cars\ndata_1 <- transform(data, speed=speed*100)\nhead(data_1)##   speed dist\n## 1   400    2\n## 2   400   10\n## 3   700    4\n## 4   700   22\n## 5   800   16\n## 6   900   10\ndata <- transform(data, time=speed*dist)\nhead(data)##   speed dist time\n## 1     4    2    8\n## 2     4   10   40\n## 3     7    4   28\n## 4     7   22  154\n## 5     8   16  128\n## 6     9   10   90"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"conditional-transformation-in-r","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.7 Conditional Transformation in R","text":"Transformation based condition. creating new column called Grilled, assigned Grilled item contains Grilled ’s name else classified Grilled.","code":"\n#Check if it contains the word grilled.\ndata <- openintro::fastfood\ndata <- transform(data, Grilled=ifelse(str_detect(item, \"Grilled\"), \"Grilled\", \"Not Grilled\"))\nhead(data[,c(\"item\",\"Grilled\")])##                                        item     Grilled\n## 1          Artisan Grilled Chicken Sandwich     Grilled\n## 2            Single Bacon Smokehouse Burger Not Grilled\n## 3            Double Bacon Smokehouse Burger Not Grilled\n## 4 Grilled Bacon Smokehouse Chicken Sandwich     Grilled\n## 5  Crispy Bacon Smokehouse Chicken Sandwich Not Grilled\n## 6                                   Big Mac Not Grilled"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"add-a-new-column-to-the-dataframe-without-transform-function.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.8 Add a new column to the dataframe without transform() function.","text":"added new column called time.","code":"\ndata <- cars\ndata$time <- data$speed * data$dist\nhead(data)##   speed dist time\n## 1     4    2    8\n## 2     4   10   40\n## 3     7    4   28\n## 4     7   22  154\n## 5     8   16  128\n## 6     9   10   90"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"get-all-the-unique-values-of-a-column-in-a-dataframe.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.9 Get all the unique values of a column in a dataframe.","text":"","code":"\ndata <- openintro::fastfood\nunique(data$restaurant)## [1] \"Mcdonalds\"   \"Chick Fil-A\" \"Sonic\"       \"Arbys\"       \"Burger King\"\n## [6] \"Dairy Queen\" \"Subway\"      \"Taco Bell\""},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"using-the-filter-function-in-r.-different-logical-operators-can-be-used-to-filter-the-data.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.10 Using the filter function in R. Different logical operators can be used to filter the data.","text":"Filter rows mpg column value 21.0Filter rows mpg column value less 21.0Filter rows mpg column value greater 21.0Filter rows cyl column 4 carb column greater 1.","code":"\ndata <- mtcars\ndata_filtered <- filter(data, mpg==21.0)\nunique(data_filtered$mpg)## [1] 21\ndata_filtered_1 <- filter(data, mpg<21.0)\nunique(data_filtered_1$mpg)##  [1] 18.7 18.1 14.3 19.2 17.8 16.4 17.3 15.2 10.4 14.7 15.5 13.3 15.8 19.7 15.0\ndata_filtered_2 <- filter(data, mpg>21.0)\nunique(data_filtered_2$mpg)## [1] 22.8 21.4 24.4 32.4 30.4 33.9 21.5 27.3 26.0\ndata_filtered_logical <- filter(data, cyl == 4 & carb > 1)\nunique(data_filtered_logical$mpg)## [1] 24.4 22.8 30.4 26.0 21.4"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"select-only-few-rows-in-a-column-based-on-a-condition-without-using-the-filter-function.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.11 Select only few rows in a column based on a condition without using the filter() function.","text":"selecting rows restuarant name subway","code":"\ndata <- openintro::fastfood\n# Select the rows where the item contains the word \"Grilled\ndata <- data[data$restaurant == \"Subway\", ] \nunique(data$restaurant)## [1] \"Subway\""},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"merge-two-dataframes","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.12 Merge two dataframes","text":"Merging two dataframes based column names. Authors dataframe books dataframe merged surname name.","code":"\nauthors <- data.frame(\n    surname = c(\"Tukey\", \"Venables\", \"Tierney\", \"Ripley\", \"McNeil\"),\n    nationality = c(\"US\", \"Australia\", \"US\", \"UK\", \"Australia\"),\n    retired = c(\"yes\", rep(\"no\", 4)))\nbooks <- data.frame(\n    name = c(\"Tukey\", \"Venables\", \"Tierney\", \"Ripley\", \"Ripley\", \"McNeil\"),\n    title = c(\"Exploratory Data Analysis\",\n              \"Probability and Statistics\",\n              \"Finance and Structuring for Data Science\",\n              \"Algorithms for Data Science\",\n               \"Interactive Data Analysis\",\n              \"Deep Learning\"))\n    #other.author = c(NA, \"Ripley\", NA, NA, NA, NA))\nmerged <- merge(authors, books, by.x=\"surname\", by.y=\"name\")\nhead(merged)##    surname nationality retired                                    title\n## 1   McNeil   Australia      no                            Deep Learning\n## 2   Ripley          UK      no              Algorithms for Data Science\n## 3   Ripley          UK      no                Interactive Data Analysis\n## 4  Tierney          US      no Finance and Structuring for Data Science\n## 5    Tukey          US     yes                Exploratory Data Analysis\n## 6 Venables   Australia      no               Probability and Statistics"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"arrange-the-data-in-ascending-order-based-on-a-column","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.13 Arrange the data in ascending order based on a column","text":"","code":"\ndata <- openintro::fastfood\n# Arranging the data in ascending order\ndata <- data[order(data$total_fat),] \nhead(data[, c(\"restaurant\",\"total_fat\")])## # A tibble: 6 × 2\n##   restaurant  total_fat\n##   <chr>           <dbl>\n## 1 Dairy Queen         0\n## 2 Subway              1\n## 3 Chick Fil-A         2\n## 4 Dairy Queen         2\n## 5 Subway              2\n## 6 Subway              2"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"arrange-the-data-in-descending-order-based-on-a-column","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.14 Arrange the data in descending order based on a column","text":"","code":"\n# Arranging the data in descending order\ndata <- data[order(data$total_fat, decreasing = TRUE),]\nhead(data[, c(\"restaurant\",\"total_fat\")])## # A tibble: 6 × 2\n##   restaurant  total_fat\n##   <chr>           <dbl>\n## 1 Mcdonalds         141\n## 2 Burger King       126\n## 3 Mcdonalds         107\n## 4 Sonic             100\n## 5 Sonic              92\n## 6 Mcdonalds          88"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"get-the-summary-of-a-column---mean-median-var-sd-etc","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.15 Get the summary of a column -> mean, median, var, SD etc","text":"function gives us Minimum value, 1st Quartile value, Median, Mean, 3rd Quartile value, Maximum value column data frame.","code":"\nsummary(data$total_fat)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    0.00   14.00   23.00   26.59   35.00  141.00"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"convert-all-the-values-in-the-column-to-upper-case.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.16 Convert all the values in the column to upper case.","text":"","code":"\ndata$item <- tolower(data$item)\nhead(data$item)## [1] \"20 piece buttermilk crispy chicken tenders\"      \n## [2] \"american brewhouse king\"                         \n## [3] \"40 piece chicken mcnuggets\"                      \n## [4] \"garlic parmesan dunked ultimate chicken sandwich\"\n## [5] \"super sonic bacon double cheeseburger (w/mayo)\"  \n## [6] \"12 piece buttermilk crispy chicken tenders\""},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"convert-all-the-values-in-the-column-to-lower-case.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.17 Convert all the values in the column to lower case.","text":"","code":"\ndata$item <- toupper(data$item)\nhead(data$item)## [1] \"20 PIECE BUTTERMILK CRISPY CHICKEN TENDERS\"      \n## [2] \"AMERICAN BREWHOUSE KING\"                         \n## [3] \"40 PIECE CHICKEN MCNUGGETS\"                      \n## [4] \"GARLIC PARMESAN DUNKED ULTIMATE CHICKEN SANDWICH\"\n## [5] \"SUPER SONIC BACON DOUBLE CHEESEBURGER (W/MAYO)\"  \n## [6] \"12 PIECE BUTTERMILK CRISPY CHICKEN TENDERS\""},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"dropping-nas","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.18 Dropping NAs","text":"Dropping rows one columns NA","code":"\ndata <- openintro::seattlepets\ndata <- data[complete.cases(data), ]\n# Removes the rows with one or more columns having a NA"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"groupby-and-summarize-functions-usage","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.19 groupby( ) and summarize( ) functions usage","text":"use ames data demonstrate functions. want find minimum, maximum area houses particular neighborhood, group Neighborhood compute minimum maximum area columns using summarise function.","code":"\ndata <- openintro::ames\ndata <- data %>% group_by(Neighborhood) %>% summarise(max_area= max(area), min_area=min(area))\nhead(data, n=10)## # A tibble: 10 × 3\n##    Neighborhood max_area min_area\n##    <fct>           <int>    <int>\n##  1 Blmngtn          1589     1142\n##  2 Blueste          1556     1020\n##  3 BrDale           1365      948\n##  4 BrkSide          2134      334\n##  5 ClearCr          3086      988\n##  6 CollgCr          2828      768\n##  7 Crawfor          3447      694\n##  8 Edwards          5642      498\n##  9 Gilbert          2462      864\n## 10 Greens           1295      788"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"get-the-shape-of-the-dataframe-in-r.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.20 Get the shape of the dataframe in R.","text":"know number rows columns dataframe.First number list number rows second number list number columns dataframe","code":"\ndata <- openintro::ames\ndim(data)## [1] 2930   82"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"select-only-top-30-rows-or-90-rows-bottom-30-rows","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.21 Select only top 30 rows or 90 rows, bottom 30 rows","text":"","code":"\ndata <- openintro::ames\n# Selecting the top 30 rows\ndata <- data[1:30,]\n# Selecting the top 90 rows\ndata <- data[1:90,]\ndata <- openintro::ames\ndata <- data[2900:2930,] \n# Select the last 30 rows if your dataframe consists of 2930 rows"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"get-the-data-type-of-each-column-in-a-dataframe.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.22 Get the data type of each column in a dataframe.","text":"","code":"\ndata <- openintro::seattlepets\nmap(data, class)## $license_issue_date\n## [1] \"Date\"\n## \n## $license_number\n## [1] \"character\"\n## \n## $animal_name\n## [1] \"character\"\n## \n## $species\n## [1] \"character\"\n## \n## $primary_breed\n## [1] \"character\"\n## \n## $secondary_breed\n## [1] \"character\"\n## \n## $zip_code\n## [1] \"character\""},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"changing-the-type-of-data---int-to-char","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.23 Changing the type of data -> int to char","text":"Change values column character integer valid values.Note: rows may marked NA coercion.","code":"\ndata <- openintro::seattlepets\nhead(data$zip_code)## [1] \"98108\" \"98117\" \"98136\" \"98117\" \"98144\" \"98103\"\ndata$zip_code <- as.numeric(data$zip_code)\nhead(data$zip_code)## [1] 98108 98117 98136 98117 98144 98103"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"rename-column-names-in-r","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.24 Rename column names in R","text":"renaming column name zip_code zip_code_modified","code":"\nnames(data)[names(data) == 'zip_code'] <- 'zip_code_modified'\nnames(data)## [1] \"license_issue_date\" \"license_number\"     \"animal_name\"       \n## [4] \"species\"            \"primary_breed\"      \"secondary_breed\"   \n## [7] \"zip_code_modified\"\n# Zip code has been modified to zip_code_modified"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"find-minimum-and-maximum-values-in-a-column-in-r","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.25 Find minimum and maximum values in a column in R","text":"Minimum value area columnMaximum value area column","code":"\ndata <- openintro::ames\nmin <- min(data$area)\nmax <- max(data$area)\nmin## [1] 334\nmax## [1] 5642"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"number-of-unique-values-in-every-column-in-the-data-frame","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.26 Number of unique values in every column in the data frame","text":"dataset, 13930 unique animal names, 4 different species etc.","code":"\ndata <- openintro::seattlepets\ndata %>% summarize_all(n_distinct)## # A tibble: 1 × 7\n##   license_issue_date license_number animal_name species primary_breed\n##                <int>          <int>       <int>   <int>         <int>\n## 1               1064          52497       13930       4           336\n## # … with 2 more variables: secondary_breed <int>, zip_code <int>"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"reorder-columns-in-r-by-column-name.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.27 Reorder columns in R by column name.","text":"","code":"\nauthors <- data.frame(\n    surname = c(\"Tukey\", \"Venables\", \"Tierney\", \"Ripley\", \"McNeil\"),\n    nationality = c(\"US\", \"Australia\", \"US\", \"UK\", \"Australia\"),\n    retired = c(\"yes\", rep(\"no\", 4)))\nauthors##    surname nationality retired\n## 1    Tukey          US     yes\n## 2 Venables   Australia      no\n## 3  Tierney          US      no\n## 4   Ripley          UK      no\n## 5   McNeil   Australia      no\n#reorder by column name\nauthors <- authors[, c(\"retired\", \"nationality\", \"surname\")]\nauthors##   retired nationality  surname\n## 1     yes          US    Tukey\n## 2      no   Australia Venables\n## 3      no          US  Tierney\n## 4      no          UK   Ripley\n## 5      no   Australia   McNeil"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"reorder-columns-by-column-index.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.28 Reorder columns by column index.","text":"","code":"\nauthors <- authors[, c(1,3,2)]\nauthors##   retired  surname nationality\n## 1     yes    Tukey          US\n## 2      no Venables   Australia\n## 3      no  Tierney          US\n## 4      no   Ripley          UK\n## 5      no   McNeil   Australia"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"remove-duplicates-from-the-dataframe-based-on-one-column-or-multiple-columns.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.29 Remove Duplicates from the dataframe based on one column or multiple columns.","text":"","code":"\n# Remove the duplicate rows based on one variable\ndata <- mtcars\n# Have the rows with distinct carb\ndata_one_var <- distinct(data, carb, .keep_all= TRUE)\n# Keep the distinct data based on multiple variables\ndata_multi <- distinct(data, cyl, vs, .keep_all= TRUE)"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"calculate-mean-median-of-a-column-in-the-data-frame","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.30 Calculate Mean, Median of a column in the Data Frame","text":"MeanMedian","code":"\nmean <- mean(data$carb)\nmedian <- median(data$carb)\nmean## [1] 2.8125\nmedian## [1] 2"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"value-counts-in-r.-check-how-many-times-a-unique-variable-occurs-in-like-male---5-female--10-in-the-column-name-gender.","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.31 Value counts in R. Check how many times a unique variable occurs in like Male - 5, Female -10 in the column name Gender.","text":"Number rows cyl = 4 11, cyl=6 7 etcNumber rows carb = 4 10, carb=6 1 etc","code":"\ndata %>% count(cyl)##   cyl  n\n## 1   4 11\n## 2   6  7\n## 3   8 14\ndata %>% count(carb)##   carb  n\n## 1    1  7\n## 2    2 10\n## 3    3  3\n## 4    4 10\n## 5    6  1\n## 6    8  1"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"convert-the-index-column-to-a-new-column","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.32 Convert the index column to a new column","text":"created new column using index dataframe.","code":"\ndata <- cbind(car_name = rownames(data), data)\nhead(data)##                            car_name  mpg cyl disp  hp drat    wt  qsec vs am\n## Mazda RX4                 Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1\n## Mazda RX4 Wag         Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1\n## Datsun 710               Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1\n## Hornet 4 Drive       Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0\n## Hornet Sportabout Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0\n## Valiant                     Valiant 18.1   6  225 105 2.76 3.460 20.22  1  0\n##                   gear carb\n## Mazda RX4            4    4\n## Mazda RX4 Wag        4    4\n## Datsun 710           4    1\n## Hornet 4 Drive       3    1\n## Hornet Sportabout    3    2\n## Valiant              3    1"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"add-a-new-row-to-the-dataframe","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.33 Add a new row to the dataframe","text":"can new rows dataframe using rbind","code":"\nnew_row_to_add <- data.frame(\"Volvo 125\",22.5,3,120.2,108,2.23,2.89,19.08,1,0,4,3)\nnames(new_row_to_add) <- c(\"car_name\", \"mpg\", \"cyl\", \"disp\", \"hp\", \"drat\", \"wt\", \"qsec\", \"vs\", \"am\", \"gear\", \"carb\")\ndata <- rbind(data,new_row_to_add)\ntail(data)##                      car_name  mpg cyl  disp  hp drat    wt  qsec vs am gear\n## Lotus Europa     Lotus Europa 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5\n## Ford Pantera L Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5\n## Ferrari Dino     Ferrari Dino 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5\n## Maserati Bora   Maserati Bora 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5\n## Volvo 142E         Volvo 142E 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4\n## 1                   Volvo 125 22.5   3 120.2 108 2.23 2.890 19.08  1  0    4\n##                carb\n## Lotus Europa      2\n## Ford Pantera L    4\n## Ferrari Dino      6\n## Maserati Bora     8\n## Volvo 142E        2\n## 1                 3"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"logsquare-root-cube-root-transformation-in-r","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.34 Log,Square root, Cube root transformation in R","text":"","code":"\ndata <- cars\n# Taking the log of the speed column\ndata$log_transformation <- log10(data$speed)\n# Taking the square root of the speed column\ndata$sqrt_transformation <- sqrt(data$speed)\n# Taking the cube root of the speed column\ndata$cube_transformation <-(data$speed)^1/3\nhead(data)##   speed dist log_transformation sqrt_transformation cube_transformation\n## 1     4    2          0.6020600            2.000000            1.333333\n## 2     4   10          0.6020600            2.000000            1.333333\n## 3     7    4          0.8450980            2.645751            2.333333\n## 4     7   22          0.8450980            2.645751            2.333333\n## 5     8   16          0.9030900            2.828427            2.666667\n## 6     9   10          0.9542425            3.000000            3.000000"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"changing-the-dataframe-dimensions-from-wide-to-long","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.35 Changing the dataframe dimensions from wide to long","text":"following types can use melt() function R.Type 1:\ncreate two columns called variable - represent subject value represents grade subject.Type 2:\ninterested grade english math, can pass measure.vars parameter.","code":"\ndf_wide <- data.frame(\n  student = c(\"Krupa\", \"Goutham\", \"Sailaja\", \"Murthy\"),\n  school = c(\"St. Joseph's\", \"Timpany\", \"St.Joseph's\", \"Timpany\"),\n  exploratory_data_analysis = c(10, 100, 1000, 10000),  # eng grades\n  probability_and_statistics = c(20, 200, 2000, 20000),  # math grades\n  algorithms_for_ds = c(30, 300, 3000, 30000)   # physics grades\n)\ndf_long <- melt(data = df_wide, \n                id.vars = c(\"student\", \"school\"))\ndf_long##    student       school                   variable value\n## 1    Krupa St. Joseph's  exploratory_data_analysis    10\n## 2  Goutham      Timpany  exploratory_data_analysis   100\n## 3  Sailaja  St.Joseph's  exploratory_data_analysis  1000\n## 4   Murthy      Timpany  exploratory_data_analysis 10000\n## 5    Krupa St. Joseph's probability_and_statistics    20\n## 6  Goutham      Timpany probability_and_statistics   200\n## 7  Sailaja  St.Joseph's probability_and_statistics  2000\n## 8   Murthy      Timpany probability_and_statistics 20000\n## 9    Krupa St. Joseph's          algorithms_for_ds    30\n## 10 Goutham      Timpany          algorithms_for_ds   300\n## 11 Sailaja  St.Joseph's          algorithms_for_ds  3000\n## 12  Murthy      Timpany          algorithms_for_ds 30000\ndf_long <- melt(data = df_wide, \n                id.vars = \"student\",\n                measure.vars = c(\"exploratory_data_analysis\", \"algorithms_for_ds\"))\ndf_long##   student                  variable value\n## 1   Krupa exploratory_data_analysis    10\n## 2 Goutham exploratory_data_analysis   100\n## 3 Sailaja exploratory_data_analysis  1000\n## 4  Murthy exploratory_data_analysis 10000\n## 5   Krupa         algorithms_for_ds    30\n## 6 Goutham         algorithms_for_ds   300\n## 7 Sailaja         algorithms_for_ds  3000\n## 8  Murthy         algorithms_for_ds 30000"},{"path":"r-cheatsheet-on-data-transforamtion-and-exploration.html","id":"replace-na-with-a-specific-value","chapter":"10 R cheatsheet on data transforamtion and exploration","heading":"10.0.0.36 Replace NA with a specific value","text":"replacing NA None.References:\n* https://towardsdatascience.com/data-cleaning--r-made-simple-1b77303b0b17\n* https://towardsdatascience.com/data-transformation--r-288e95438ff9\n* https://bookdown.org/aschmi11/RESMHandbook/data-preparation--cleaning--r.html","code":"\ndata <- openintro::seattlepets\ndata[is.na(data)] <- \"None\""},{"path":"r-vs-python-basic-data-wrangling.html","id":"r-vs-python-basic-data-wrangling","chapter":"11 R vs Python Basic Data Wrangling","heading":"11 R vs Python Basic Data Wrangling","text":"Yihao GaoThis pdf syntax comparison cheat sheet basic data wrangling R (dplyr, tidyr) Python (pandas) including row/column selection, missing value imputation, sorting, mapping, grouping aggregation etc. motivation creating cheat sheet give quick reference might sometimes mix syntax Python R save time.Access cheat sheet using link .\nhttps://github.com/yiiihao/yg2820_edav_CC/blob/main/cheetsheet.pdf","code":""},{"path":"tidyverse_cheatsheet.html","id":"tidyverse_cheatsheet","chapter":"12 tidyverse_cheatsheet","heading":"12 tidyverse_cheatsheet","text":"Ziyu SongMotivation:R one widely used programming languages today’s society. R can help people build statistical models also visualize data analysis results. However, many R packages functions users may feel hard remember details apply data analysis process. project, create cheat sheet Tidyverse, powerful collection R packages data tools transforming visualizing data, help users quickly find information need want exploratory data visualization R.cheat sheet includes main knowledge points popular functions Tidyverse, including definition Tidyverse, core Tidyverse packages, typical data analysis workflow using Tidyverse, key functions core packages. order make easier users understand function provided, incorporated example axis parameters.Self-Evaluation:creating cheat sheet summarizing main knowledge points Tidyverse, gained better understanding main packages Tidyverse consolidated knowledge learned class. found Tidyverse provides efficient, fast, well-documented workflow general data modeling visualization tasks. hand, many important useful packages Tidyverse. Therefore, hope create complete cheat sheet Tidyverse next time help people better understand apply data analysis process.Cheatsheet:\nhttps://github.com/zs2488/cc21fall1/blob/main/Community%20Contribution%20-%20Cheat%20Sheet.pdf","code":""},{"path":"cheatsheet-tidyverse.html","id":"cheatsheet-tidyverse","chapter":"13 Cheatsheet Tidyverse","heading":"13 Cheatsheet Tidyverse","text":"Jiazhen Li","code":""},{"path":"cheatsheet-tidyverse.html","id":"section","chapter":"13 Cheatsheet Tidyverse","heading":"13.1 ","text":"cheatsheet helping students start learn analysis graph R. class, learn tidyverse, powerful collection R packages. cheatsheet, pay attention two packages: ggplot2 dplyr. specifically list functions dylyr frequently use grammer graphics ggplot2 packages. useful new student learn.Cheatsheet Tidyverse: https://github.com/Jiazhen980326/contribution-/blob/master/cheatsheet-Jiazhen%20Li%20.pdf","code":""},{"path":"use-of-ggprism-and-ggsci-packages.html","id":"use-of-ggprism-and-ggsci-packages","chapter":"14 Use of ggprism and ggsci packages","heading":"14 Use of ggprism and ggsci packages","text":"Yifan JiangThis cheatsheet introduces use ggprism ggsci respectively set style color picture generated ggplot. style color used large number papers.cheatsheet link:\nhttps://github.com/Josieeeeee/cc_github/blob/main/ggprism_and_ggsci_cheatsheets.pdf","code":""},{"path":"interactive-plot-introduction.html","id":"interactive-plot-introduction","chapter":"15 Interactive plot introduction","heading":"15 Interactive plot introduction","text":"Yujie ZhouInteractive plots used widely today’s data analysis.tutorial introduce four commonly used interactive plots: interactive bubble plot, interactive area plot, interactive heatmap, interactive network. Unlike static plot, interactive plot can enable users zoom give user better use experience simplify analysis process.","code":"\n#install.packages(\"gapminder\")\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(gapminder)\nlibrary(\"tidyr\")\n#install.packages(\"heatmaply\")\nlibrary(\"heatmaply\")\n#install.packages(\"igraph\")\nlibrary(igraph)\n#install.packages(\"networkD3\")\nlibrary(networkD3)"},{"path":"interactive-plot-introduction.html","id":"interactive-bubble-plot","chapter":"15 Interactive plot introduction","heading":"15.1 Interactive Bubble Plot:","text":"bubble plot third dimension added scatterplot. size bubble represent additional numeric variable.can draw plot directly using “plotly” just right draw bubble plot using “ggplot”. following example see number lifespan people different nations associated.interactive bubble plot show positive relationship GPD human’s lifespan, also gives additional information number people dot. However, drawback bubble plots hard judge relationship x y variables variables (polpulation size example).","code":"\nknitr::opts_chunk$set(warning = F, message = F)\n\nhead(gapminder)## # A tibble: 6 × 6\n##   country     continent  year lifeExp      pop gdpPercap\n##   <fct>       <fct>     <int>   <dbl>    <int>     <dbl>\n## 1 Afghanistan Asia       1952    28.8  8425333      779.\n## 2 Afghanistan Asia       1957    30.3  9240934      821.\n## 3 Afghanistan Asia       1962    32.0 10267083      853.\n## 4 Afghanistan Asia       1967    34.0 11537966      836.\n## 5 Afghanistan Asia       1972    36.1 13079460      740.\n## 6 Afghanistan Asia       1977    38.4 14880372      786.\np <- gapminder %>%\n  filter(year==1967) %>%\n  ggplot( aes(x=gdpPercap, y=lifeExp, size=pop,color=continent)) +\n  geom_point() +\n  scale_x_log10() +\n  theme_bw()\n\nggplotly(p)"},{"path":"interactive-plot-introduction.html","id":"interactive-area-plot","chapter":"15 Interactive plot introduction","heading":"15.2 Interactive Area Plot:","text":"Area plot differ lot regular line graphs, two exceptions:\n1. area x-axis individual line filled color\n2. x-axis must zero valueArea plots use different colors give users good sense quantities changed time period time. However, users carefully use area plots, overlapping areas plots hide information area line hard percisely calculated user just looking graph.can easily see student mean performance subject associated parents’ educational background just glancing area separate line.","code":"\nknitr::opts_chunk$set(warning = F, message = F)\ndf <- read.csv(\"resources/interactive_plot_plotly_cheatsheet/StudentsPerformancePart.csv\")\nhead(df)##   gender race.ethnicity parental.level.of.education        lunch\n## 1 female        group B           bachelor's degree     standard\n## 2 female        group C                some college     standard\n## 3 female        group B             master's degree     standard\n## 4   male        group A          associate's degree free/reduced\n## 5   male        group C                some college     standard\n## 6 female        group B          associate's degree     standard\n##   test.preparation.course math.score reading.score writing.score\n## 1                    none         72            72            74\n## 2               completed         69            90            88\n## 3                    none         90            95            93\n## 4                    none         47            57            44\n## 5                    none         76            78            75\n## 6                    none         71            83            78\ndf %>%\n  filter(gender == \"female\",race.ethnicity==\"group B\")%>%\n  pivot_longer(\n    cols = c('math.score','reading.score','writing.score'),\n    names_to = \"Subject\",\n    values_to = \"score\"\n  ) %>%\n  group_by(Subject, parental.level.of.education) %>%\n  summarise(score = mean(score)) %>%\n  mutate(parental.level.of.education = factor(parental.level.of.education,levels=c(\"associate's degree\", \"bachelor's degree\", \"high school\", \"master's degree\", \"some college\", \"some high school\")))%>%\n  mutate(parental.level.of.education = as.numeric(parental.level.of.education)) %>%\n  ggplot(aes(x= parental.level.of.education ,y=score,fill=Subject))+\n  geom_area(alpha = 0.7) +\n  scale_fill_manual(values = c(\"#F6D7A7\", \"#C8E3D4\", \"#87AAAA\")) +\n  scale_x_continuous(breaks =1:6,labels = c(\"associate's degree\", \"bachelor's degree\", \"high school\", \"master's degree\", \"some college\", \"some high school\"))+\n  theme_minimal() -> p2\n\np2\nggplotly(p2)"},{"path":"interactive-plot-introduction.html","id":"interactive-heatmap","chapter":"15 Interactive plot introduction","heading":"15.3 Interactive Heatmap:","text":"Heatmap useful visualization tool two-dimensional data reveal patterns correlations rows columns. easy--use, introduce interactive heatmap. already familiar heatmap R package draw heatmap, use useful R package “heatmaply” build interactive cluster heatmap.mtcars collection fuel consumption corresponding 10 automobile designs 32 automobiles. noteworthy first data transformations, normalizing percentizing make variables comparable. Normalizing matrix done using scale argument. can applied row column. column option chosen.Passing NULL Colv heatmap tends reorder column clustering algorithm. Removing column dendrogram can enable users compare raw data.also good use terrain.color(), rainbow(), heat.colors(), topo.colors() cm.colors() interchangeably selecting different color palette heatmap.Instead vertically naming x-axis heatmap , interactive heatmap automatically rotate name x-axis values names long fit.visual user friendly tool,shinyHeatmaply, create interactive heatmap invented byJonathan Sidi. apply tool, can install ‘shinyHeatmaply’ R package, , alternatively, run GitHub entering “devtools::install_github(‘yonicd/shinyHeatmaply’)”. output heatmap shinyHeatmaply provide detail parameter summaries.","code":"\nknitr::opts_chunk$set(warning = F, message = F)\ndata(\"mtcars\")\nheatmaply(mtcars, scale=\"column\", Colv = NULL,col =  topo.colors(10),xlab=\"design\", ylab=\"car type\", main=\" interactive heatmap\")"},{"path":"interactive-plot-introduction.html","id":"interactive-network","chapter":"15 Interactive plot introduction","heading":"15.4 Interactive Network","text":"Network consist mainly two parts: nodes edge. graph reflect interrelationships note (.e. entity). advantage using network include important entities analyze whole instead see entity separately. Two addtional packages need import interactive network igraph networkD3. Let’s first see igraph used plot static network square matrix generated ramdonly.arrow indicates direction relationship two notes. example, one relationship 4 2, relationship 2 4.Now, let’s step interactive networks. simple function: simpleNetwork can generate interactive network handy way.Interactive network can rotate, zoom , zoom network see 3D layout. Compared static network, interactive network much better looking data gets bigger, avoid overlapping links.","code":"\nknitr::opts_chunk$set(warning = F, message = F)\n\nset.seed(12345)\nrandomdf <- matrix(sample(0:3, 16, replace=TRUE), nrow=4)\n\noutput <- graph_from_adjacency_matrix(randomdf)\nplot(output)\nknitr::opts_chunk$set(warning = F, message = F)\n\ndata <- data.frame(\n  from=c(\"A\", \"A\", \"B\", \"D\", \"C\", \"D\", \"E\", \"B\", \"C\", \"D\", \"K\", \"A\", \"M\"),\n  to=c(\"B\", \"E\", \"F\", \"A\", \"C\", \"A\", \"B\", \"Z\", \"A\", \"C\", \"A\", \"B\", \"K\") #reference:https://www.r-graph-gallery.com/network-interactive.html\n)\np <- simpleNetwork(data,height=\"50px\", width=\"50px\",        \n                   Source = 1,\n                   Target = 2,\n                   fontSize = 25,                    \n                   linkColour = \"#123\",   \n                   nodeColour = \"#F47E5E\",    \n                   opacity = 0.9,             \n                   zoom = T)\np"},{"path":"interactive-plot-introduction.html","id":"reference-1","chapter":"15 Interactive plot introduction","heading":"15.5 Reference:","text":"https://www.r-graph-gallery.com/network-interactive.html","code":""},{"path":"multithreading-crawler-frame.html","id":"multithreading-crawler-frame","chapter":"16 Multithreading Crawler Frame","heading":"16 Multithreading Crawler Frame","text":"Yi YangAll work uploaded Github, ’s url:https://github.com/yiyangnju/multithreading-crawler-frame","code":""},{"path":"regression-and-classification-in-r.html","id":"regression-and-classification-in-r","chapter":"17 Regression and Classification in R","heading":"17 Regression and Classification in R","text":"Parv JoshiThis video tutorial, can found https://youtu./J2rnDy9PB3E. code created part video given contents file, reference. links used data set:Data.csvData.csvTitanic.csvTitanic.csvAmes_Housing_data.csvAmes_Housing_data.csvBoxcox Implementation R - 1Boxcox Implementation R - 1Boxcox Implementation R - 2Boxcox Implementation R - 2Peanalized RegressionPeanalized RegressionStepwise Selection MethodStepwise Selection MethodAccuracy MetricsAccuracy MetricsRmd CheatsheetRmd Cheatsheet","code":""},{"path":"regression-and-classification-in-r.html","id":"libraries-and-warnings","chapter":"17 Regression and Classification in R","heading":"17.0.1 Libraries and Warnings","text":"","code":"\n# Removing messages and warnings from knited version\nknitr::opts_chunk$set(warning = FALSE, message = FALSE)\n\n# Libraries\n# Make sure these are installed before running them. They all are a part of CRAN.\n\nlibrary(RCurl)\nlibrary(tidyverse)\nlibrary(randomForest)\nlibrary(caTools)\nlibrary(car)\nlibrary(MASS)\nlibrary(leaps)\nlibrary(caret)\nlibrary(bestglm)\nlibrary(rpart)\nlibrary(rattle)"},{"path":"regression-and-classification-in-r.html","id":"reading-data","chapter":"17 Regression and Classification in R","heading":"17.0.2 Reading Data","text":"","code":"\n# Importing the dataset\n\ndataset = read.csv(\"https://raw.githubusercontent.com/Parv-Joshi/EDAV_CC_Datasets/main/Data.csv\")\n\n# str(dataset)\n# View(dataset)"},{"path":"regression-and-classification-in-r.html","id":"data-preprocessing","chapter":"17 Regression and Classification in R","heading":"17.0.3 Data Preprocessing","text":"","code":"\n# Mean Imputation for Missing Data\ndataset$Age = ifelse(is.na(dataset$Age),\n                     ave(dataset$Age, FUN = function(x) mean(x, na.rm = T)),\n                     dataset$Age)\n\ndataset$Salary = ifelse(is.na(dataset$Salary),\n                        ave(dataset$Salary, FUN = function(x) mean(x, na.rm = T)),\n                        dataset$Salary)\n\n# Encoding Categorical Variables\ndataset$Country = factor(dataset$Country, \n                         labels = c(\"France\", \"Spain\", \"Germany\"), \n                         levels = c(\"France\", \"Spain\", \"Germany\"))\ndataset$Purchased = factor(dataset$Purchased, \n                           levels = c(\"Yes\", \"No\"), \n                           labels = c(1, 0))\n\n# Splitting Data into Training and Testing\n\nset.seed(123)\n\nsplit = sample.split(dataset$Purchased, SplitRatio = 0.8)\ntraining_set = subset(dataset, split == T)\ntest_set = subset(dataset, split == F)\n\n# Feature Scaling\ntraining_set[, 2:3] = scale(training_set[, 2:3])\ntest_set[, 2:3] = scale(test_set[, 2:3])"},{"path":"regression-and-classification-in-r.html","id":"regression","chapter":"17 Regression and Classification in R","heading":"17.0.4 Regression","text":"","code":"\n# Data \n\ndata(\"Salaries\", package = \"carData\")\n# force(Salaries)\n\nattach(Salaries)\ndetach(Salaries)\n\n# str(Salaries)\n# View(Salaries)\n\n# Simple Variable Regression\n\nmodel = lm(Salaries$salary ~ Salaries$yrs.since.phd)\nmodel = lm(salary ~ yrs.since.phd, data = Salaries)\n\nmodel## \n## Call:\n## lm(formula = salary ~ yrs.since.phd, data = Salaries)\n## \n## Coefficients:\n##   (Intercept)  yrs.since.phd  \n##       91718.7          985.3\nsummary(model)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -84171 -19432  -2858  16086 102383 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    91718.7     2765.8  33.162   <2e-16 ***\n## yrs.since.phd    985.3      107.4   9.177   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 27530 on 395 degrees of freedom\n## Multiple R-squared:  0.1758, Adjusted R-squared:  0.1737 \n## F-statistic: 84.23 on 1 and 395 DF,  p-value: < 2.2e-16\nstargazer::stargazer(model, type = \"text\")## \n## ===============================================\n##                         Dependent variable:    \n##                     ---------------------------\n##                               salary           \n## -----------------------------------------------\n## yrs.since.phd               985.342***         \n##                              (107.365)         \n##                                                \n## Constant                   91,718.680***       \n##                             (2,765.792)        \n##                                                \n## -----------------------------------------------\n## Observations                    397            \n## R2                             0.176           \n## Adjusted R2                    0.174           \n## Residual Std. Error    27,533.580 (df = 395)   \n## F Statistic           84.226*** (df = 1; 395)  \n## ===============================================\n## Note:               *p<0.1; **p<0.05; ***p<0.01\n# Multiple Variable Regression\n\nmodel1 = lm(salary ~ yrs.since.phd + yrs.service, data = Salaries)\nsummary(model1)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd + yrs.service, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -79735 -19823  -2617  15149 106149 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    89912.2     2843.6  31.620  < 2e-16 ***\n## yrs.since.phd   1562.9      256.8   6.086 2.75e-09 ***\n## yrs.service     -629.1      254.5  -2.472   0.0138 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 27360 on 394 degrees of freedom\n## Multiple R-squared:  0.1883, Adjusted R-squared:  0.1842 \n## F-statistic: 45.71 on 2 and 394 DF,  p-value: < 2.2e-16\n### Model:\n### salary = 89912.2 + 1562.9 * yrs.since.phd + (-629.1) * yrs.service\n\n\n# Categorical Variables\n\ncontrasts(Salaries$sex)##        Male\n## Female    0\n## Male      1\n# sex = relevel(sex, ref = \"Male\")\n\nmodel2 = lm(salary ~ yrs.since.phd + yrs.service + sex, data = Salaries)\nsummary(model2)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd + yrs.service + sex, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -79586 -19564  -3018  15071 105898 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    82875.9     4800.6  17.264  < 2e-16 ***\n## yrs.since.phd   1552.8      256.1   6.062 3.15e-09 ***\n## yrs.service     -649.8      254.0  -2.558   0.0109 *  \n## sexMale         8457.1     4656.1   1.816   0.0701 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 27280 on 393 degrees of freedom\n## Multiple R-squared:  0.1951, Adjusted R-squared:  0.189 \n## F-statistic: 31.75 on 3 and 393 DF,  p-value: < 2.2e-16\ncar::Anova(model2)## Anova Table (Type II tests)\n## \n## Response: salary\n##                   Sum Sq  Df F value   Pr(>F)    \n## yrs.since.phd 2.7346e+10   1 36.7512 3.15e-09 ***\n## yrs.service   4.8697e+09   1  6.5447  0.01089 *  \n## sex           2.4547e+09   1  3.2990  0.07008 .  \n## Residuals     2.9242e+11 393                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nmodel3 = lm(salary ~ ., data = Salaries)\ncar::Anova(model3)## Anova Table (Type II tests)\n## \n## Response: salary\n##                   Sum Sq  Df F value    Pr(>F)    \n## rank          6.9508e+10   2 68.4143 < 2.2e-16 ***\n## discipline    1.9237e+10   1 37.8695 1.878e-09 ***\n## yrs.since.phd 2.5041e+09   1  4.9293   0.02698 *  \n## yrs.service   2.7100e+09   1  5.3348   0.02143 *  \n## sex           7.8068e+08   1  1.5368   0.21584    \n## Residuals     1.9812e+11 390                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(model3)## \n## Call:\n## lm(formula = salary ~ ., data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -65248 -13211  -1775  10384  99592 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    65955.2     4588.6  14.374  < 2e-16 ***\n## rankAssocProf  12907.6     4145.3   3.114  0.00198 ** \n## rankProf       45066.0     4237.5  10.635  < 2e-16 ***\n## disciplineB    14417.6     2342.9   6.154 1.88e-09 ***\n## yrs.since.phd    535.1      241.0   2.220  0.02698 *  \n## yrs.service     -489.5      211.9  -2.310  0.02143 *  \n## sexMale         4783.5     3858.7   1.240  0.21584    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 22540 on 390 degrees of freedom\n## Multiple R-squared:  0.4547, Adjusted R-squared:  0.4463 \n## F-statistic:  54.2 on 6 and 390 DF,  p-value: < 2.2e-16\n# Transformations and Interaction Terms\n\nmodel4 = lm(salary ~ yrs.since.phd^2 + yrs.service, data = Salaries)\nsummary(model4)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd^2 + yrs.service, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -79735 -19823  -2617  15149 106149 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    89912.2     2843.6  31.620  < 2e-16 ***\n## yrs.since.phd   1562.9      256.8   6.086 2.75e-09 ***\n## yrs.service     -629.1      254.5  -2.472   0.0138 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 27360 on 394 degrees of freedom\n## Multiple R-squared:  0.1883, Adjusted R-squared:  0.1842 \n## F-statistic: 45.71 on 2 and 394 DF,  p-value: < 2.2e-16\nmodel4 = lm(salary ~ yrs.since.phd + I(yrs.since.phd^2) + yrs.service, data = Salaries)\nsummary(model4)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd + I(yrs.since.phd^2) + yrs.service, \n##     data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -63538 -18063  -1946  14919 105025 \n## \n## Coefficients:\n##                     Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)        64971.002   3950.746  16.445  < 2e-16 ***\n## yrs.since.phd       4222.493    394.237  10.711  < 2e-16 ***\n## I(yrs.since.phd^2)   -62.321      7.389  -8.434 6.42e-16 ***\n## yrs.service         -234.596    239.075  -0.981    0.327    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 25210 on 393 degrees of freedom\n## Multiple R-squared:  0.3127, Adjusted R-squared:  0.3075 \n## F-statistic: 59.61 on 3 and 393 DF,  p-value: < 2.2e-16\nmodel4 = lm(salary ~ yrs.since.phd + I(yrs.since.phd^2) + I(yrs.since.phd^3) + yrs.service, data = Salaries)\nsummary(model4)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd + I(yrs.since.phd^2) + I(yrs.since.phd^3) + \n##     yrs.service, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -63538 -18062  -1947  14917 105023 \n## \n## Coefficients:\n##                      Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)         6.498e+04  5.559e+03  11.688  < 2e-16 ***\n## yrs.since.phd       4.221e+03  8.990e+02   4.696 3.68e-06 ***\n## I(yrs.since.phd^2) -6.227e+01  3.877e+01  -1.606    0.109    \n## I(yrs.since.phd^3) -6.720e-04  4.935e-01  -0.001    0.999    \n## yrs.service        -2.346e+02  2.395e+02  -0.979    0.328    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 25240 on 392 degrees of freedom\n## Multiple R-squared:  0.3127, Adjusted R-squared:  0.3057 \n## F-statistic:  44.6 on 4 and 392 DF,  p-value: < 2.2e-16\nmodel4 = lm(I(log(salary)) ~ yrs.since.phd + I(yrs.since.phd^2) + I(yrs.since.phd^3) + yrs.service, data = Salaries)\nsummary(model4)## \n## Call:\n## lm(formula = I(log(salary)) ~ yrs.since.phd + I(yrs.since.phd^2) + \n##     I(yrs.since.phd^3) + yrs.service, data = Salaries)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.68247 -0.15590 -0.00244  0.14242  0.74830 \n## \n## Coefficients:\n##                      Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)         1.115e+01  4.617e-02 241.467  < 2e-16 ***\n## yrs.since.phd       4.073e-02  7.467e-03   5.454 8.72e-08 ***\n## I(yrs.since.phd^2) -6.626e-04  3.220e-04  -2.058   0.0403 *  \n## I(yrs.since.phd^3)  6.168e-07  4.099e-06   0.150   0.8805    \n## yrs.service        -1.433e-03  1.989e-03  -0.720   0.4718    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.2096 on 392 degrees of freedom\n## Multiple R-squared:  0.3575, Adjusted R-squared:  0.3509 \n## F-statistic: 54.52 on 4 and 392 DF,  p-value: < 2.2e-16\nmodel5 = lm(salary ~ yrs.since.phd:yrs.service, data = Salaries)\nsummary(model5)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd:yrs.service, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -80936 -21633  -3841  17621 106895 \n## \n## Coefficients:\n##                            Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)               1.071e+05  1.983e+03  53.982  < 2e-16 ***\n## yrs.since.phd:yrs.service 1.218e+01  2.431e+00   5.009 8.26e-07 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 29410 on 395 degrees of freedom\n## Multiple R-squared:  0.05973,    Adjusted R-squared:  0.05735 \n## F-statistic: 25.09 on 1 and 395 DF,  p-value: 8.263e-07\n#### Boxcox\n\nsal = Salaries[, c(3,4,6)]\nshapiro.test(Salaries$salary)## \n##  Shapiro-Wilk normality test\n## \n## data:  Salaries$salary\n## W = 0.95988, p-value = 6.076e-09\n# Null: Data is normally distributed\n# p-value = 6.076e-09 < 0.05, reject null -> NOT Normal.\n\nmodel1 = lm(salary ~ yrs.since.phd + yrs.service, data = Salaries)\nsummary(model1)## \n## Call:\n## lm(formula = salary ~ yrs.since.phd + yrs.service, data = Salaries)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -79735 -19823  -2617  15149 106149 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    89912.2     2843.6  31.620  < 2e-16 ***\n## yrs.since.phd   1562.9      256.8   6.086 2.75e-09 ***\n## yrs.service     -629.1      254.5  -2.472   0.0138 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 27360 on 394 degrees of freedom\n## Multiple R-squared:  0.1883, Adjusted R-squared:  0.1842 \n## F-statistic: 45.71 on 2 and 394 DF,  p-value: < 2.2e-16\nbc = boxcox(model1)\nbest.lam = bc$x[which(bc$y == max(bc$y))]\nbest.lam## [1] -0.2222222\nmodel6 = lm(I(salary^best.lam) ~ yrs.since.phd + yrs.service, data = Salaries)\nsummary(model6)## \n## Call:\n## lm(formula = I(salary^best.lam) ~ yrs.since.phd + yrs.service, \n##     data = Salaries)\n## \n## Residuals:\n##        Min         1Q     Median         3Q        Max \n## -0.0099656 -0.0027195 -0.0000644  0.0028614  0.0150252 \n## \n## Coefficients:\n##                 Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    7.942e-02  4.095e-04 193.953  < 2e-16 ***\n## yrs.since.phd -2.260e-04  3.698e-05  -6.110 2.39e-09 ***\n## yrs.service    8.892e-05  3.665e-05   2.426   0.0157 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.00394 on 394 degrees of freedom\n## Multiple R-squared:  0.1929, Adjusted R-squared:  0.1888 \n## F-statistic: 47.09 on 2 and 394 DF,  p-value: < 2.2e-16\n### Adj. R^2 increased\n\n# Predictions using Training and Testing data\n\nset.seed(123)\nsplit = sample.split(Salaries$salary, SplitRatio = 0.8)\ntraining_set = subset(Salaries, split == T)\ntest_set = subset(Salaries, split == F)\n\nmodel7 = lm(salary ~ ., data = training_set)\ny_pred = predict(model7, test_set)\n# y_pred\ndata.frame(y_pred, test_set$salary)##        y_pred test_set.salary\n## 2   133991.08          173200\n## 4   138905.04          115000\n## 5   134650.37          141500\n## 8   135930.61          147765\n## 11  100457.55          119800\n## 16  135214.59          117150\n## 20  116504.49          137000\n## 21  121107.75           89565\n## 24  120009.45          113068\n## 31  139939.95          132261\n## 32   89375.54           79916\n## 34   87417.62           80225\n## 50   85955.45           70768\n## 53   86623.38           74692\n## 59   98656.53          100135\n## 65   86921.88           68404\n## 67  137279.32          101000\n## 68  136344.57           99418\n## 69  126670.46          111512\n## 84   88722.90           88825\n## 87  134675.41          152708\n## 88   86112.35           88400\n## 89  132792.62          172272\n## 104 130115.59          127512\n## 106 120116.27          113543\n## 107  84699.94           82099\n## 111 118886.12          112429\n## 114 119570.45          104279\n## 118 121371.46          117515\n## 126 124716.43           78162\n## 132 122055.79           76840\n## 137 117267.04          108262\n## 139  84543.04           73877\n## 145 133106.42          112696\n## 151 132058.21          128148\n## 173 141120.02           93164\n## 179 139551.03          147349\n## 181 130596.04          142467\n## 189 100984.98          106300\n## 190 135767.06          153750\n## 193 132346.97          122100\n## 195 101644.27           90000\n## 202 135146.11          119700\n## 206 141584.07           96545\n## 219  97391.59          109650\n## 220 131901.31          119500\n## 222 138923.43          145200\n## 230 120379.98          133900\n## 238  67420.64           63100\n## 240 123190.87           96200\n## 248 118547.28          101100\n## 249 120637.05          128800\n## 260 119777.43           92550\n## 261  91885.61           88600\n## 262 120825.64          107550\n## 264 118629.05          126000\n## 271 121346.42          143250\n## 277 123906.89          107200\n## 294  88170.11          104800\n## 296 122024.10           97150\n## 297 116589.36          126300\n## 300  91521.73           70700\n## 316  88227.16           84716\n## 317  95094.83           71065\n## 320 131876.27          135027\n## 321 133131.46          104428\n## 327 136444.74          124714\n## 330 132478.83          134778\n## 334 140988.16          145098\n## 340 145581.67          137317\n## 347 142243.36          142023\n## 352 134832.31           93519\n## 356 134775.58          145028\n## 360  75889.64           78785\n## 363 118472.15          138771\n## 373 118126.66          109707\n## 376 119149.83          103649\n## 380  84699.94          104121\n## 386 119093.10          114330\n## 391 130451.66          166605\n# Variable Selection\n\n# data\ndata(\"swiss\")\nattach(swiss)\n\n# ?swiss\n\n# Best Subsets regression\n\nmodels = leaps::regsubsets(Fertility ~ ., data = swiss, nvmax = 5)\nsummary(models)## Subset selection object\n## Call: regsubsets.formula(Fertility ~ ., data = swiss, nvmax = 5)\n## 5 Variables  (and intercept)\n##                  Forced in Forced out\n## Agriculture          FALSE      FALSE\n## Examination          FALSE      FALSE\n## Education            FALSE      FALSE\n## Catholic             FALSE      FALSE\n## Infant.Mortality     FALSE      FALSE\n## 1 subsets of each size up to 5\n## Selection Algorithm: exhaustive\n##          Agriculture Examination Education Catholic Infant.Mortality\n## 1  ( 1 ) \" \"         \" \"         \"*\"       \" \"      \" \"             \n## 2  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \" \"             \n## 3  ( 1 ) \" \"         \" \"         \"*\"       \"*\"      \"*\"             \n## 4  ( 1 ) \"*\"         \" \"         \"*\"       \"*\"      \"*\"             \n## 5  ( 1 ) \"*\"         \"*\"         \"*\"       \"*\"      \"*\"\n### Therefore, \n### Best 1-variable model: Fertility ~ Education\n### Best 2-variables model: Fertility ~ Education + Catholic\n### Best 3-variables model: Fertility ~ Education + Catholic + Infant.Mortality\n### Best 4-variables model: Fertility ~ Agriculture + Education + Catholic + Infant.Mortality\n### Best 5-variables model: Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality\n\nmodels.summary = summary(models)\ndata.frame(Adj.R2 = which.max(models.summary$adjr2),\n           CP = which.min(models.summary$cp),\n           BIC = which.min(models.summary$bic))##   Adj.R2 CP BIC\n## 1      5  4   4\n### Fertility ~ Agriculture + Education + Catholic + Infant.Mortality\n\n# Stepwise Variable Selection\nfit = lm(Fertility ~ ., data = swiss)\nstep = MASS::stepAIC(fit, direction = \"both\", trace = F) # change both to forward and backward\nstep## \n## Call:\n## lm(formula = Fertility ~ Agriculture + Education + Catholic + \n##     Infant.Mortality, data = swiss)\n## \n## Coefficients:\n##      (Intercept)       Agriculture         Education          Catholic  \n##          62.1013           -0.1546           -0.9803            0.1247  \n## Infant.Mortality  \n##           1.0784\ndetach(swiss)\n\n\n# Penalized Regression\n\names = read.csv(\"https://raw.githubusercontent.com/Parv-Joshi/EDAV_CC_Datasets/main/Ames_Housing_Data.csv\")\n# str(ames)\nanyNA(ames)## [1] FALSE\nset.seed(123)\ntraining.samples = createDataPartition(ames$SalePrice, p = 0.75, list = FALSE)\n\ntrain.data = ames[training.samples,]\ntest.data = ames[-training.samples,]\n\nlambda = 10^seq(-3, 3, length = 100)\n\n# Ridge Regression\nset.seed(123)\nridge = train(SalePrice ~ ., data = train.data, method = \"glmnet\",\n  trControl = trainControl(\"cv\", number = 10),\n  tuneGrid = expand.grid(alpha = 0, lambda = lambda))\n\n# LASSO\nset.seed(123)\nlasso = train(SalePrice ~ ., data = train.data, method = \"glmnet\",\n  trControl = trainControl(\"cv\", number = 10),\n  tuneGrid = expand.grid(alpha = 1, lambda = lambda))\n\n# Elastic Net\nset.seed(123)\nelastic = train(SalePrice ~ ., data = train.data, method = \"glmnet\",\n  trControl = trainControl(\"cv\", number = 10),\n  tuneLength = 10)\n\n# Comparison\nmodels = list(ridge = ridge, lasso = lasso, elastic = elastic)\nresamples(models) %>% summary(metric = \"RMSE\")## \n## Call:\n## summary.resamples(object = ., metric = \"RMSE\")\n## \n## Models: ridge, lasso, elastic \n## Number of resamples: 10 \n## \n## RMSE \n##             Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\n## ridge   24044.91 29603.57 30799.80 32919.29 37210.80 45150.33    0\n## lasso   23614.27 29604.97 31077.67 32800.93 37787.06 44271.58    0\n## elastic 23725.92 29688.82 31124.32 32770.19 37752.31 44115.51    0\n# Since Elastic model has the lowest mean RMSE, we can conclude that the Elastic model is the best."},{"path":"regression-and-classification-in-r.html","id":"classification","chapter":"17 Regression and Classification in R","heading":"17.0.5 Classification","text":"","code":"\n# Data\n\ndata(\"PimaIndiansDiabetes2\", package = \"mlbench\")\n\n# str(PimaIndiansDiabetes2)\n# View(PimaIndiansDiabetes2)\n\nPimaIndiansDiabetes2$diabetes = as.factor(PimaIndiansDiabetes2$diabetes)\nPimaIndiansDiabetes2 = na.omit(PimaIndiansDiabetes2)\n\nattach(PimaIndiansDiabetes2)\n\n# Training and Testing\n\nset.seed(123)\n\ntraining.samples = createDataPartition(diabetes, p = 0.8, list = FALSE)\n\ntrain.data = PimaIndiansDiabetes2[training.samples,]\ntest.data = PimaIndiansDiabetes2[-training.samples,]\n\n# Logistic Regression\n\nmodel = glm(diabetes ~ ., data = train.data, family = binomial)\nsummary(model)## \n## Call:\n## glm(formula = diabetes ~ ., family = binomial, data = train.data)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -2.5832  -0.6544  -0.3292   0.6248   2.5968  \n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)    \n## (Intercept) -1.053e+01  1.440e+00  -7.317 2.54e-13 ***\n## pregnant     1.005e-01  6.127e-02   1.640  0.10092    \n## glucose      3.710e-02  6.486e-03   5.719 1.07e-08 ***\n## pressure    -3.876e-04  1.383e-02  -0.028  0.97764    \n## triceps      1.418e-02  1.998e-02   0.710  0.47800    \n## insulin      5.940e-04  1.508e-03   0.394  0.69371    \n## mass         7.997e-02  3.180e-02   2.515  0.01190 *  \n## pedigree     1.329e+00  4.823e-01   2.756  0.00585 ** \n## age          2.718e-02  2.020e-02   1.346  0.17840    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 398.80  on 313  degrees of freedom\n## Residual deviance: 267.18  on 305  degrees of freedom\n## AIC: 285.18\n## \n## Number of Fisher Scoring iterations: 5\nprobabilities = predict(model, test.data, type = \"response\")\nprobabilities##          19          21          32          55          64          71 \n## 0.192628377 0.485262263 0.662527248 0.798681474 0.278073391 0.145877334 \n##          72          74          98          99         108         111 \n## 0.314265178 0.232071188 0.007697533 0.066394837 0.357546947 0.552586956 \n##         115         128         154         182         215         216 \n## 0.715548197 0.132717063 0.706670106 0.189297618 0.291196167 0.911862874 \n##         224         229         260         293         297         313 \n## 0.704569592 0.993419157 0.932506403 0.721153294 0.328274489 0.293808296 \n##         316         326         357         369         376         385 \n## 0.120862955 0.201559764 0.390156419 0.022075579 0.885924184 0.075765425 \n##         386         393         394         410         429         447 \n## 0.042383376 0.102435789 0.095664525 0.885380718 0.379195274 0.053098974 \n##         450         453         468         470         477         487 \n## 0.091641699 0.097155564 0.122327231 0.831420989 0.216021458 0.525840641 \n##         541         542         546         552         555         556 \n## 0.461122260 0.270914264 0.890122464 0.066719675 0.068520682 0.197336318 \n##         562         563         564         577         589         592 \n## 0.894087110 0.075000107 0.091244654 0.163897301 0.912857186 0.200938223 \n##         595         600         609         610         621         634 \n## 0.491041316 0.048192839 0.549602575 0.034910473 0.203922043 0.081878938 \n##         666         673         674         681         683         694 \n## 0.133609108 0.100033198 0.782544310 0.007547670 0.145787456 0.629221735 \n##         697         699         710         716         717         719 \n## 0.485455842 0.290737653 0.141965217 0.925604098 0.839268863 0.161190610 \n##         722         731         733         734         746         766 \n## 0.168129887 0.191170873 0.852375783 0.078840151 0.305248512 0.125461309\ncontrasts(diabetes)##     pos\n## neg   0\n## pos   1\npredicted.classes = ifelse(probabilities > 0.5, \"pos\", \"neg\")\npredicted.classes##    19    21    32    55    64    71    72    74    98    99   108   111   115 \n## \"neg\" \"neg\" \"pos\" \"pos\" \"neg\" \"neg\" \"neg\" \"neg\" \"neg\" \"neg\" \"neg\" \"pos\" \"pos\" \n##   128   154   182   215   216   224   229   260   293   297   313   316   326 \n## \"neg\" \"pos\" \"neg\" \"neg\" \"pos\" \"pos\" \"pos\" \"pos\" \"pos\" \"neg\" \"neg\" \"neg\" \"neg\" \n##   357   369   376   385   386   393   394   410   429   447   450   453   468 \n## \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\" \"neg\" \"neg\" \n##   470   477   487   541   542   546   552   555   556   562   563   564   577 \n## \"pos\" \"neg\" \"pos\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\" \n##   589   592   595   600   609   610   621   634   666   673   674   681   683 \n## \"pos\" \"neg\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \n##   694   697   699   710   716   717   719   722   731   733   734   746   766 \n## \"pos\" \"neg\" \"neg\" \"neg\" \"pos\" \"pos\" \"neg\" \"neg\" \"neg\" \"pos\" \"neg\" \"neg\" \"neg\"\ncaret::confusionMatrix(factor(predicted.classes),\n                factor(test.data$diabetes),\n                positive = \"pos\")## Confusion Matrix and Statistics\n## \n##           Reference\n## Prediction neg pos\n##        neg  44  11\n##        pos   8  15\n##                                          \n##                Accuracy : 0.7564         \n##                  95% CI : (0.646, 0.8465)\n##     No Information Rate : 0.6667         \n##     P-Value [Acc > NIR] : 0.05651        \n##                                          \n##                   Kappa : 0.4356         \n##                                          \n##  Mcnemar's Test P-Value : 0.64636        \n##                                          \n##             Sensitivity : 0.5769         \n##             Specificity : 0.8462         \n##          Pos Pred Value : 0.6522         \n##          Neg Pred Value : 0.8000         \n##              Prevalence : 0.3333         \n##          Detection Rate : 0.1923         \n##    Detection Prevalence : 0.2949         \n##       Balanced Accuracy : 0.7115         \n##                                          \n##        'Positive' Class : pos            \n## \n# Stepwise regression\n\nstep = MASS::stepAIC(model, direction = \"both\", k = log(nrow(PimaIndiansDiabetes2)), trace = FALSE)\nstep$anova## Stepwise Model Path \n## Analysis of Deviance Table\n## \n## Initial Model:\n## diabetes ~ pregnant + glucose + pressure + triceps + insulin + \n##     mass + pedigree + age\n## \n## Final Model:\n## diabetes ~ pregnant + glucose + mass + pedigree\n## \n## \n##         Step Df     Deviance Resid. Df Resid. Dev      AIC\n## 1                                  305   267.1825 320.9239\n## 2 - pressure  1 0.0007857024       306   267.1833 314.9534\n## 3  - insulin  1 0.1591672501       307   267.3425 309.1413\n## 4  - triceps  1 0.4434205054       308   267.7859 303.6135\n## 5      - age  1 2.4276790188       309   270.2136 300.0699\n# Best subset regression\n\ncv_data = model.matrix( ~ ., PimaIndiansDiabetes2)[,-1]\ncv_data = data.frame(cv_data)\nbest = bestglm(cv_data, IC = \"BIC\", family = binomial)\nbest## BIC\n## BICq equivalent for q in (0.359009418385306, 0.859446547266463)\n## Best Model:\n##                 Estimate  Std. Error   z value     Pr(>|z|)\n## (Intercept) -10.09201799 1.080251137 -9.342289 9.427384e-21\n## glucose       0.03618899 0.004981946  7.264026 3.757357e-13\n## mass          0.07444854 0.020266697  3.673442 2.393046e-04\n## pedigree      1.08712862 0.419408437  2.592052 9.540525e-03\n## age           0.05301206 0.013439480  3.944502 7.996582e-05\ndetach(PimaIndiansDiabetes2)\n\n# Decision Tree Classification\n\ndata = read.csv(\"https://raw.githubusercontent.com/Parv-Joshi/EDAV_CC_Datasets/main/Titanic.csv\")\nattach(data)\n\n# str(data)\n\n# Excluding Variables\ndata = subset(data, select = -c(Name, Ticket, Cabin))\n\n# Removing Missing Data\ndata = subset(data, !is.na(Age))\n\n# Testing and Training set\n\nset.seed(123)\ntraining.samples = data$Survived %>% \n  createDataPartition(p = 0.8, list = FALSE)\n\ntrain.data = data[training.samples,]\ntest.data = data[-training.samples,]\n\n# Factoring Survived\ntrain.data$Survived = as.factor(train.data$Survived)\ntest.data$Survived = as.factor(test.data$Survived)\n\n# Decision Trees\nmodel = rpart::rpart(Survived ~ ., data = train.data, control = rpart.control(cp = 0))\nrattle::fancyRpartPlot(model, cex = 0.5)\nset.seed(123)\ntrain.data$Survived = as.factor(train.data$Survived)\nmodel2 = train(Survived ~ ., \n               data = train.data, \n               method = \"rpart\", \n               trControl = trainControl(\"cv\", number = 10), \n               tuneLength = 100)\n\nfancyRpartPlot(model2$finalModel, cex = 0.6)\nprobabilities = predict(model2, newdata = test.data)\n# we don't need to do  contrasts since Survived is already given in o and 1.\npredicted.classes = ifelse(probabilities == 1, \"1\", \"0\")\n\ncaret::confusionMatrix(factor(predicted.classes),\n                factor(test.data$Survived),\n                positive = \"1\")## Confusion Matrix and Statistics\n## \n##           Reference\n## Prediction  0  1\n##          0 74 19\n##          1  5 44\n##                                          \n##                Accuracy : 0.831          \n##                  95% CI : (0.759, 0.8886)\n##     No Information Rate : 0.5563         \n##     P-Value [Acc > NIR] : 3.722e-12      \n##                                          \n##                   Kappa : 0.6497         \n##                                          \n##  Mcnemar's Test P-Value : 0.007963       \n##                                          \n##             Sensitivity : 0.6984         \n##             Specificity : 0.9367         \n##          Pos Pred Value : 0.8980         \n##          Neg Pred Value : 0.7957         \n##              Prevalence : 0.4437         \n##          Detection Rate : 0.3099         \n##    Detection Prevalence : 0.3451         \n##       Balanced Accuracy : 0.8176         \n##                                          \n##        'Positive' Class : 1              \n## \n# Random Forest\n\nset.seed(123)\nmodel3 = train(Survived ~ ., \n              data = train.data, \n              method = \"rf\",\n              trControl = trainControl(\"cv\", number = 10),\n              importance = TRUE)\n\nprobabilities = predict(model3, newdata = test.data)\npredicted.classes = ifelse(probabilities == 1, \"1\", \"0\")\ncaret::confusionMatrix(factor(predicted.classes),\n                factor(test.data$Survived),\n                positive = \"1\")## Confusion Matrix and Statistics\n## \n##           Reference\n## Prediction  0  1\n##          0 76 21\n##          1  3 42\n##                                          \n##                Accuracy : 0.831          \n##                  95% CI : (0.759, 0.8886)\n##     No Information Rate : 0.5563         \n##     P-Value [Acc > NIR] : 3.722e-12      \n##                                          \n##                   Kappa : 0.6474         \n##                                          \n##  Mcnemar's Test P-Value : 0.0005202      \n##                                          \n##             Sensitivity : 0.6667         \n##             Specificity : 0.9620         \n##          Pos Pred Value : 0.9333         \n##          Neg Pred Value : 0.7835         \n##              Prevalence : 0.4437         \n##          Detection Rate : 0.2958         \n##    Detection Prevalence : 0.3169         \n##       Balanced Accuracy : 0.8143         \n##                                          \n##        'Positive' Class : 1              \n## \nrandomForest::varImpPlot(model3$finalModel, type = 1) # MeanDecreaseAccuracy\ncaret::varImp(model3, type = 1)## rf variable importance\n## \n##             Overall\n## Sexmale     100.000\n## Pclass       54.019\n## Fare         38.444\n## Age          37.316\n## SibSp        24.658\n## Parch        19.187\n## EmbarkedQ     4.655\n## EmbarkedS     3.630\n## EmbarkedC     3.560\n## PassengerId   0.000\nrandomForest::varImpPlot(model3$finalModel, type = 2) # MeanDecreaseGini\ncaret::varImp(model3, type = 2)## rf variable importance\n## \n##             Overall\n## Sexmale     100.000\n## Fare         62.753\n## Age          54.613\n## PassengerId  48.686\n## Pclass       35.447\n## SibSp        15.503\n## Parch        14.097\n## EmbarkedS     3.623\n## EmbarkedC     3.606\n## EmbarkedQ     0.000\ndetach(data)"},{"path":"tibble-vs.-dataframe.html","id":"tibble-vs.-dataframe","chapter":"18 Tibble vs. DataFrame","heading":"18 Tibble vs. DataFrame","text":"Jingfei Fang","code":"\nlibrary(tidyverse)\nlibrary(tibble)"},{"path":"tibble-vs.-dataframe.html","id":"introduction","chapter":"18 Tibble vs. DataFrame","heading":"18.0.1 Introduction","text":"tibble often considered neater format data frame, often used tidyverse ggplot2 packages. contains information data frame, manipulation representation tibbles different data frames aspects.","code":""},{"path":"tibble-vs.-dataframe.html","id":"getting-started-with-tibbles","chapter":"18 Tibble vs. DataFrame","heading":"18.0.2 1. Getting started with tibbles","text":"can tidyverse:can installing tibble package directly:","code":"\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n#install.packages(\"tibble\")\nlibrary(tibble)"},{"path":"tibble-vs.-dataframe.html","id":"creating-a-tibble","chapter":"18 Tibble vs. DataFrame","heading":"18.0.3 2. Creating a tibble","text":"can create tibble directly:can create tibble existing data frame using as_tibble(). use ‘iris’ dataset example:","code":"\ntib <- tibble(a = c(1,2,3), b = c(4,5,6), c = c(7,8,9))\ntib## # A tibble: 3 × 3\n##       a     b     c\n##   <dbl> <dbl> <dbl>\n## 1     1     4     7\n## 2     2     5     8\n## 3     3     6     9\ndf <- iris\nclass(df)## [1] \"data.frame\"\ntib <- as_tibble(df)\ntib## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # … with 140 more rows"},{"path":"tibble-vs.-dataframe.html","id":"unlike-data-frames-tibbles-dont-show-the-entire-dataset-when-you-print-it.","chapter":"18 Tibble vs. DataFrame","heading":"18.0.4 3. Unlike data frames, tibbles don’t show the entire dataset when you print it.","text":"","code":"\ntib## # A tibble: 150 × 5\n##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n##           <dbl>       <dbl>        <dbl>       <dbl> <fct>  \n##  1          5.1         3.5          1.4         0.2 setosa \n##  2          4.9         3            1.4         0.2 setosa \n##  3          4.7         3.2          1.3         0.2 setosa \n##  4          4.6         3.1          1.5         0.2 setosa \n##  5          5           3.6          1.4         0.2 setosa \n##  6          5.4         3.9          1.7         0.4 setosa \n##  7          4.6         3.4          1.4         0.3 setosa \n##  8          5           3.4          1.5         0.2 setosa \n##  9          4.4         2.9          1.4         0.2 setosa \n## 10          4.9         3.1          1.5         0.1 setosa \n## # … with 140 more rows"},{"path":"tibble-vs.-dataframe.html","id":"tibbles-cannot-access-a-column-when-you-provide-a-partial-name-of-the-column-but-data-frames-can.","chapter":"18 Tibble vs. DataFrame","heading":"18.0.5 4. Tibbles cannot access a column when you provide a partial name of the column, but data frames can.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble","chapter":"18 Tibble vs. DataFrame","heading":"18.0.5.1 Tibble","text":"try match column name partial name, work.provide entire column name, work.","code":"\ntib <- tibble(str = c(\"a\",\"b\",\"c\",\"d\"), int = c(1,2,3,4))\ntib$st## NULL\ntib$str## [1] \"a\" \"b\" \"c\" \"d\""},{"path":"tibble-vs.-dataframe.html","id":"data-frame","chapter":"18 Tibble vs. DataFrame","heading":"18.0.5.2 Data Frame","text":"However, can access “str” column providing partial column name “st” (long partial name unique).","code":"\ndf <- data.frame(str = c(\"a\",\"b\",\"c\",\"d\"), int = c(1,2,3,4))\ndf$st## [1] \"a\" \"b\" \"c\" \"d\""},{"path":"tibble-vs.-dataframe.html","id":"when-you-access-only-one-column-of-a-tibble-it-will-keep-the-tibble-structure.-but-when-you-access-one-column-of-a-data-frame-it-will-become-a-vector.","chapter":"18 Tibble vs. DataFrame","heading":"18.0.6 5. When you access only one column of a tibble, it will keep the tibble structure. But when you access one column of a data frame, it will become a vector.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble-1","chapter":"18 Tibble vs. DataFrame","heading":"18.0.6.1 Tibble","text":"Checking ’s still tibble:can see tibble structure preserved.","code":"\ntib[,\"str\"]## # A tibble: 4 × 1\n##   str  \n##   <chr>\n## 1 a    \n## 2 b    \n## 3 c    \n## 4 d\nis_tibble(tib[,\"str\"])## [1] TRUE"},{"path":"tibble-vs.-dataframe.html","id":"data-frame-1","chapter":"18 Tibble vs. DataFrame","heading":"18.0.6.2 Data Frame","text":"Checking ’s still data frame:’s longer data frame.","code":"\ndf[,\"str\"]## [1] \"a\" \"b\" \"c\" \"d\"\nis.data.frame(df[,\"str\"])## [1] FALSE"},{"path":"tibble-vs.-dataframe.html","id":"however-other-forms-of-subsetting-including-and-work-the-same-for-tibbles-and-data-frames.","chapter":"18 Tibble vs. DataFrame","heading":"18.0.6.3 However, other forms of subsetting, including [[ ]] and $, work the same for tibbles and data frames.","text":"can see subsetting [[ ]] $ also don’t preserve tibble structure.","code":"\ntib[[\"str\"]]## [1] \"a\" \"b\" \"c\" \"d\"\ndf[[\"str\"]]## [1] \"a\" \"b\" \"c\" \"d\"\ntib$str## [1] \"a\" \"b\" \"c\" \"d\"\ndf$str## [1] \"a\" \"b\" \"c\" \"d\""},{"path":"tibble-vs.-dataframe.html","id":"when-assigning-a-new-column-to-a-tibble-the-input-will-not-be-recycled-which-means-you-have-to-provide-an-input-of-the-same-length-of-the-other-columns.-but-a-data-frame-will-recycle-the-input.","chapter":"18 Tibble vs. DataFrame","heading":"18.0.7 6. When assigning a new column to a tibble, the input will not be recycled, which means you have to provide an input of the same length of the other columns. But a data frame will recycle the input.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble-2","chapter":"18 Tibble vs. DataFrame","heading":"18.0.7.1 Tibble","text":"gives error tibble columns length 4, input (5,6) length 2 recycled.\nprovide input length:","code":"\ntib## # A tibble: 4 × 2\n##   str     int\n##   <chr> <dbl>\n## 1 a         1\n## 2 b         2\n## 3 c         3\n## 4 d         4\ntib$newcol <- c(5,6)## Error: Assigned data `c(5, 6)` must be compatible with existing data.\n## ✖ Existing data has 4 rows.\n## ✖ Assigned data has 2 rows.\n## ℹ Only vectors of size 1 are recycled.\ntib$newcol <- rep(c(5,6),2)\ntib## # A tibble: 4 × 3\n##   str     int newcol\n##   <chr> <dbl>  <dbl>\n## 1 a         1      5\n## 2 b         2      6\n## 3 c         3      5\n## 4 d         4      6"},{"path":"tibble-vs.-dataframe.html","id":"data-frame-2","chapter":"18 Tibble vs. DataFrame","heading":"18.0.7.2 Data Frame","text":"Data frames recycle input.","code":"\ndf##   str int\n## 1   a   1\n## 2   b   2\n## 3   c   3\n## 4   d   4\ndf$newcol <- c(5,6)\ndf##   str int newcol\n## 1   a   1      5\n## 2   b   2      6\n## 3   c   3      5\n## 4   d   4      6"},{"path":"tibble-vs.-dataframe.html","id":"reading-with-builtin-read.csv-function-will-output-data-frames-while-reading-with-read_csv-in-readr-package-inside-tidyverse-will-output-tibbles.","chapter":"18 Tibble vs. DataFrame","heading":"18.0.8 7. Reading with builtin read.csv() function will output data frames, while reading with read_csv() in “readr” package inside tidyverse will output tibbles.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"reading-csv-file-with-read.csv","chapter":"18 Tibble vs. DataFrame","heading":"18.0.8.1 Reading csv file with read.csv()","text":"","code":"\ndata <- read.csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")\nclass(data)## [1] \"data.frame\""},{"path":"tibble-vs.-dataframe.html","id":"reading-csv-file-with-read_csv","chapter":"18 Tibble vs. DataFrame","heading":"18.0.8.2 Reading csv file with read_csv()","text":"","code":"\ndata <- read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")\nclass(data)## [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\""},{"path":"tibble-vs.-dataframe.html","id":"tibbles-dont-support-support-arithmetic-operations-on-all-columns-well-the-result-will-be-converted-into-a-data-frame-without-any-notice.","chapter":"18 Tibble vs. DataFrame","heading":"18.0.9 8. Tibbles don’t support support arithmetic operations on all columns well, the result will be converted into a data frame without any notice.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble-3","chapter":"18 Tibble vs. DataFrame","heading":"18.0.9.1 Tibble","text":"can see try multiply elements tibble 2, result correct turned data frame without notifications.","code":"\ntib <- tibble(a = c(1,2,3), b = c(4,5,6), c = c(7,8,9))\nclass(tib*2)## [1] \"data.frame\""},{"path":"tibble-vs.-dataframe.html","id":"data-frame-3","chapter":"18 Tibble vs. DataFrame","heading":"18.0.9.2 Data Frame","text":"data frames issue , converted type.","code":"\ndf <- data.frame(a = c(1,2,3), b = c(4,5,6), c = c(7,8,9))\nclass(df*2)## [1] \"data.frame\""},{"path":"tibble-vs.-dataframe.html","id":"tibbles-preserve-all-the-variable-types-while-data-frames-have-the-option-to-convert-string-into-factor.-in-older-versions-of-r-data-frames-will-convert-string-into-factor-by-default","chapter":"18 Tibble vs. DataFrame","heading":"18.0.10 9. Tibbles preserve all the variable types, while data frames have the option to convert string into factor. (In older versions of R, data frames will convert string into factor by default)","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble-4","chapter":"18 Tibble vs. DataFrame","heading":"18.0.10.1 Tibble","text":"can see original data types variables preserved tibble.","code":"\ntib <- tibble(str = c(\"a\",\"b\",\"c\",\"d\"), int = c(1,2,3,4))\nstr(tib)## tibble [4 × 2] (S3: tbl_df/tbl/data.frame)\n##  $ str: chr [1:4] \"a\" \"b\" \"c\" \"d\"\n##  $ int: num [1:4] 1 2 3 4"},{"path":"tibble-vs.-dataframe.html","id":"data-frame-4","chapter":"18 Tibble vs. DataFrame","heading":"18.0.10.2 Data Frame","text":"use data frame, also preserve original types, “stringAsFactors = FALSE” default new versions R.However, also option convert string factor creating data frame setting “stringAsFactors = TRUE”.can see “str” column converted factor.","code":"\ndf <- data.frame(str = c(\"a\",\"b\",\"c\",\"d\"), int = c(1,2,3,4))\nstr(df)## 'data.frame':    4 obs. of  2 variables:\n##  $ str: chr  \"a\" \"b\" \"c\" \"d\"\n##  $ int: num  1 2 3 4\ndf <- data.frame(str = c(\"a\",\"b\",\"c\",\"d\"), int = c(1,2,3,4), stringsAsFactors = TRUE)\nclass(df$str)## [1] \"factor\""},{"path":"tibble-vs.-dataframe.html","id":"tibbles-work-well-with-ggplot2-just-like-data-frames.","chapter":"18 Tibble vs. DataFrame","heading":"18.0.11 10. Tibbles work well with ggplot2, just like data frames.","text":"","code":""},{"path":"tibble-vs.-dataframe.html","id":"tibble-5","chapter":"18 Tibble vs. DataFrame","heading":"18.0.11.1 Tibble:","text":"","code":"\nggplot(data = tib, mapping = aes(x=str, y=int)) +\n  geom_col(width = 0.3)"},{"path":"tibble-vs.-dataframe.html","id":"data-frame-5","chapter":"18 Tibble vs. DataFrame","heading":"18.0.11.2 Data Frame:","text":"","code":"\nggplot(data = df, mapping = aes(x=str, y=int)) +\n  geom_col(width = 0.3)"},{"path":"tibble-vs.-dataframe.html","id":"works-cited","chapter":"18 Tibble vs. DataFrame","heading":"18.1 Works Cited","text":"https://tibble.tidyverse.org/https://cran.r-project.org/web/packages/tibble/vignettes/tibble.htmlhttps://www.youtube.com/watch?v=_qHdqWx-vsQ&ab_channel=JoshuaFrench","code":""},{"path":"introduction-to-time-series.html","id":"introduction-to-time-series","chapter":"19 Introduction to Time Series","heading":"19 Introduction to Time Series","text":"Parth Gupta (pg2677)writing tutorial time series forecasting covering classical techniques time series forecasting.","code":""},{"path":"introduction-to-time-series.html","id":"motivation","chapter":"19 Introduction to Time Series","heading":"19.1 Motivation,","text":"Modeling temporal processes always one important problems. wide variety applications, ranging stock price prediction weather forecasting forecasting web traffic website.three types temporal data,Time SeriesTime SeriesPanelPanelCross SectionalCross SectionalIn time series data one individual observed different time steps. Panel data multiple individuals observed different time steps. Cross sectional data different individuals observed time step.Time series analysis comprises methods analyzing time series data order extract meaningful statistics characteristics data. Time series forecasting use model predict future values based previously observed values. Time series forecasting useful lot real life applications.Visualizing time series data important able get much better understanding underlying patterns data. Like trends increase decrease price item time, seasonal changes like people watch movies weekends. far prediction actual truth.using birth per month dataset. tune parameters different models based training period Jan 1946 Dec 1951. forecast next year. generally use Mean Absolute Percentage Error Root Mean Squared Error evaluate model.$$MAPE = _{= 0}^{N}|( - y_i)|/ y_i\\RMSE = (_{= 0}^{N}( - y_i)^2/ N)^{1/2}$$Every time series three components, trends, seasonality residualsTime Series = Trend + Seasonality + ResidualsTrend, refers overall general direction data, obtained ignoring short term effects seasonal variations noise.Trend, refers overall general direction data, obtained ignoring short term effects seasonal variations noise.Seasonality, refers periodic fluctuations repeated throughout time series period.Seasonality, refers periodic fluctuations repeated throughout time series period.Residuals, refers left part trend seasonality.Residuals, refers left part trend seasonality.plots trying visualize seasonality aspect time series data. plotted data month whole training period.","code":"\ndf <-births <- scan(\"http://robjhyndman.com/tsdldata/data/nybirths.dat\")\ndata <- df[1:72]\nfuture <- df[73:84]\nprint(data)##  [1] 26.663 23.598 26.931 24.740 25.806 24.364 24.477 23.901 23.175 23.227\n## [11] 21.672 21.870 21.439 21.089 23.709 21.669 21.752 20.761 23.479 23.824\n## [21] 23.105 23.110 21.759 22.073 21.937 20.035 23.590 21.672 22.222 22.123\n## [31] 23.950 23.504 22.238 23.142 21.059 21.573 21.548 20.000 22.424 20.615\n## [41] 21.761 22.874 24.104 23.748 23.262 22.907 21.519 22.025 22.604 20.894\n## [51] 24.677 23.673 25.320 23.583 24.671 24.454 24.122 24.252 22.084 22.991\n## [61] 23.287 23.049 25.076 24.037 24.430 24.667 26.451 25.618 25.014 25.110\n## [71] 22.964 23.981\ntime_series <- ts(data, start=c(1946, 1), end=c(1951, 12), frequency=12)\nplot(time_series)\nfit <- stl(time_series, s.window=\"period\")\nplot(fit)\nmonthplot(time_series)\nseasonplot(time_series)"},{"path":"introduction-to-time-series.html","id":"stationary-time-series","chapter":"19 Introduction to Time Series","heading":"19.2 Stationary Time Series","text":"Stationarity one important concepts time series forecasting. stationary time series one whose properties depend time series observed. Thus, time series trends, seasonality, stationary — trend seasonality affect value time series different times. hand, white noise series stationary — matter observe , look much point time.Differencing process computing differences consecutive observations.apply log transformations stabilise variance time series. Differencing can also help stabilising mean time series removing changes level time series, therefore eliminating (reducing) trend seasonality. also tests check stationarity time series.","code":""},{"path":"introduction-to-time-series.html","id":"holtwinters-model","chapter":"19 Introduction to Time Series","heading":"19.3 HoltWinters model,","text":"model three parameters alpha, beta gamma.alpha: refers “base value”. Higher alpha puts weight recent observations.alpha: refers “base value”. Higher alpha puts weight recent observations.beta: corresponds “trend value”. Higher beta means trend slope dependent recent trend slopes.beta: corresponds “trend value”. Higher beta means trend slope dependent recent trend slopes.gamma: weighs “seasonal component”. Higher gamma puts weighting recent seasonal cycles.gamma: weighs “seasonal component”. Higher gamma puts weighting recent seasonal cycles.mathematical formulation follows,$$\n{y}{t+h|t} = l_t + hb_t + s{t+h-m(k+1)} \\l_t = (y_t - s_{t-m}) + (1- )*(l_{t-1} + b_{t-1})\\b_t = ^* (l_t - l_{t-1}) + (1-^*)b_{t-1}\\s_t = (y_t - l_{t-1} - b_{t-1}) + (1-)s_{t-m}\n$$Let’s start simplest model, model forecast future value last value , .e.y[t+] = y[t], >=1 t last time step training period.$$_{T+} = y_T \\\n>=1\n$$Now can set beta non zero value can account trends, model forecast future value last value + trend.Finally, set three parameters, alpha, beta gamma non zero values account trend seasonality .Naturally, model performs better previous two models.","code":"\n# simple exponential - models level\nfit_1 <- HoltWinters(time_series, beta=FALSE, gamma=FALSE)\nf1 = forecast(fit_1, 12)\nplot(forecast(fit_1, 12))\n# double exponential - models level and trend\nfit_2 <- HoltWinters(time_series, gamma=FALSE)\nf2 = forecast(fit_2, 12)\nplot(forecast(fit_2, 12))\n# triple exponential - models level, trend, and seasonal components\nfit_3 <- HoltWinters(time_series)\nf3 = forecast(fit_3, 12)\nplot(forecast(fit_3, 12))\n# Automated forecasting using an exponential model\nfit_4 <- ets(time_series)\nf4 = forecast(fit_4, 12)\nplot(forecast(fit_4, 12))"},{"path":"introduction-to-time-series.html","id":"exponential-smooting","chapter":"19 Introduction to Time Series","heading":"19.4 Exponential Smooting","text":"model, assign weights past observations decrease exponentially go back time. model ensures give weights recent observations less less weights older observations$$\n{T+1|T} = y_T + (1-)* y{t-1} + (1-)^2 *y_{t-2} + …..\\{T+1|T} = {j = 0}{T-1}(1-)jy_{T-j} + (1-)^Tl_0\n$$","code":""},{"path":"introduction-to-time-series.html","id":"arima-model","chapter":"19 Introduction to Time Series","heading":"19.5 ARIMA model,","text":"ARIMA stands Auto Regressive Integrated Moving Average. generalization simpler AutoRegressive Moving Average adds notion integration. Let’s look term individually.AR: Autoregression. refers model predicts future values using past observations.: Integrated. use concept differencing raw observations (e.g. subtracting observation observation previous time step) order make time series stationary.MA: Moving Average. refers model uses dependency observation residual error moving average model applied lagged observations.need three parameters define model. use notation ARIMA(p,d,q).parameters ARIMA model defined follows:p: number lag observations included model, also called lag order.\nd: number times raw observations differenced, also called degree differencing.\nq: size moving average window, also called order moving average.seasonal effect , generally considered better use SARIMA (seasonal ARIMA) model increase order AR MA parts model.Now, difficult choose values p, q can use Autocorrelation function (ACF), Partial autocorrelation function (PACF) plots series determine order AR / MA terms.autocorrelation function (ACF) technique can use identify correlated values time series . ACF plots correlation coefficient lag. lag corresponds certain point time observe first value time series.Partial autocorrelation statistical measure captures correlation two variables controlling effects variables.Now, can use another implementation ARIMA R .e auto.arima() function uses variation Hyndman-Khandakar algorithm (Hyndman & Khandakar, 2008). combines unit root tests, minimisation AICc MLE obtain ARIMA model., can clearly see MAPE RMSE bar plots Auto ARIMA ETS performed best followed Holt Winter\nmodel non zero alpha, beta gamma.References,Hyndman, R.J., & Athanasopoulos, G. (2018) Forecasting: principles practice, 2nd edition, OTexts: Melbourne,\nAustralia.OTexts.com/fpp2.Hyndman, R.J., & Athanasopoulos, G. (2018) Forecasting: principles practice, 2nd edition, OTexts: Melbourne,\nAustralia.OTexts.com/fpp2.https://en.wikipedia.org/wiki/Time_serieshttps://en.wikipedia.org/wiki/Time_serieshttps://www.analyticsvidhya.com/blog/2018/02/time-series-forecasting-methods/https://www.analyticsvidhya.com/blog/2018/02/time-series-forecasting-methods/","code":"\n#using an ARIMA model\nfit_5 <- Arima(time_series, order = c(10, 1, 1))\nf5 = forecast(fit_5, 12)\nplot(forecast(fit_5, 12))\n#using an ARIMA model\nacf(time_series)\npacf(time_series)\n# Forecasting using an ARIMA model\nfit_6 <- auto.arima(time_series)\nf6 = forecast(fit_6, 12)\nplot(forecast(fit_6, 12))\nrmse_1 = accuracy(forecast(fit_1))[2]\nrmse_2 = accuracy(forecast(fit_2))[2]\nrmse_3 = accuracy(forecast(fit_3))[2]\nrmse_4 = accuracy(forecast(fit_4))[2]\nrmse_5 = accuracy(forecast(fit_5))[2]\nrmse_6 = accuracy(forecast(fit_6))[2]\nrmse = c(rmse_1, rmse_2, rmse_3, rmse_4, rmse_5, rmse_6)\n\nbarplot(rmse, main=\"RMSE Plot\", xlab=\"Models\", names.arg = c(\"HW_1\", \"HW_2\", \"HW_3\", \"ETS\", \"ARIMA\", \"Auto ARIMA\"))\nMAPE_1 = accuracy(forecast(fit_1))[5]\nMAPE_2 = accuracy(forecast(fit_2))[5]\nMAPE_3 = accuracy(forecast(fit_3))[5]\nMAPE_4 = accuracy(forecast(fit_4))[5]\nMAPE_5 = accuracy(forecast(fit_5))[5]\nMAPE_6 = accuracy(forecast(fit_6))[5]\nMAPE = c(MAPE_1, MAPE_2, MAPE_3, MAPE_4, MAPE_5, MAPE_6)\n\nbarplot(MAPE, main=\"MAPE Plot\", xlab=\"Models\", names.arg = c(\"HW_1\", \"HW_2\", \"HW_3\", \"ETS\", \"ARIMA\", \"Auto ARIMA\"))"},{"path":"vipul-edav-community-contribution-kickstart-r.html","id":"vipul-edav-community-contribution-kickstart-r","chapter":"20 Vipul EDAV Community Contribution Kickstart R","heading":"20 Vipul EDAV Community Contribution Kickstart R","text":"Vipul H HariharThis hand written notes specially made understanding basics Exploratory Data Analysis R. material summation Professor Joyce’s teachings classroom lectures R documentation files.\ntried write neatly clearly reader might benefit notes easily, hope easily understandable legible.\ntopics involved notes follows:\n1) Introduction\n2) R Programming EDAV\n3) Fun Facts R\n4) Features R makes perfect “EDAV”\n5) Application R Programming\n6) Understanding Basic Data Types R\n7a) Handy Functions\n7b) Vector\n7c) List\n7d) Factors - IMPORTANT\n7e) Data Frame\n7f) Missing Values\n8) Functions R\n9) Data Science Process (Visual Description)\n10) visulizations use EDAV?Please find link submitted file:\nhttps://github.com/virslaan/EDAV_Community_Contribution/blob/main/Community%20Contribution%202.pdf","code":""},{"path":"caret---a-machine-learning-package-turotial.html","id":"caret---a-machine-learning-package-turotial","chapter":"21 caret - a machine learning package turotial","heading":"21 caret - a machine learning package turotial","text":"Jiang Zhu Xuechun BaiMotivation: motivation community contribution project introduce classmates package R can easily implement machine learning algorithms lines code. python users commonly use package scikit-learn deploy machine laerning models, strived find similar R package similar functions. finding resources online, discovered caret great package neatly defined functions create easy-use interface machine learning algorithms, time, abundant machine learning models preprocessing model selection functions. However, found great tutorial easy--read API’s caret. Therefore, markdown file, illustrate use caret package example-based manner. eliminate mathematics behind model much possible focus implementation algorithm R. also demonstrate results experiments caret model datasets visualization tools.","code":"\nlibrary(caret)\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(kernlab)\nlibrary(earth)\nlibrary(RANN)"},{"path":"caret---a-machine-learning-package-turotial.html","id":"introduction-and-description-of-dataset","chapter":"21 caret - a machine learning package turotial","heading":"21.1 Introduction and description of dataset","text":"tutorial, use data frame Orange Juice includes two orange juice brands, Citrus Hill (CH) Minute Maid (MM) selling information according brand. URL dataset : https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv, contains 18 cloumns 1070 rows.first column “Purchase” introduces brand orange juice. data contains weekly amount purchase two brands (WeekofPurchase) store id (StoreID) orange juice sold, price orange juice according brand CH (PriceCH) MM (PriceMM). data also includes discount (“DiscCH” “DiscMM”), sale price(“SalePriceCH” “SalePriceMM”) useful information two orange juice brands. goal tutorial predict customers’ preference two brands choosing buy orange juice, focusing “Purchase” now.Now let us firstly import data, state briefly summary data:","code":"\n# Import dataset\ndf <- read.csv('https://raw.githubusercontent.com/selva86/datasets/master/orange_juice_withmissing.csv')\n\n# Structure of the dataframe\nhead(df)##   Purchase WeekofPurchase StoreID PriceCH PriceMM DiscCH DiscMM SpecialCH\n## 1       CH            237       1    1.75    1.99   0.00    0.0         0\n## 2       CH            239       1    1.75    1.99   0.00    0.3         0\n## 3       CH            245       1    1.86    2.09   0.17    0.0         0\n## 4       MM            227       1    1.69    1.69   0.00    0.0         0\n## 5       CH            228       7    1.69    1.69   0.00    0.0         0\n## 6       CH            230       7    1.69    1.99   0.00    0.0         0\n##   SpecialMM  LoyalCH SalePriceMM SalePriceCH PriceDiff Store7 PctDiscMM\n## 1         0 0.500000        1.99        1.75      0.24     No  0.000000\n## 2         1 0.600000        1.69        1.75     -0.06     No  0.150754\n## 3         0 0.680000        2.09        1.69      0.40     No  0.000000\n## 4         0 0.400000        1.69        1.69      0.00     No  0.000000\n## 5         0 0.956535        1.69        1.69      0.00    Yes  0.000000\n## 6         1 0.965228        1.99        1.69      0.30    Yes  0.000000\n##   PctDiscCH ListPriceDiff STORE\n## 1  0.000000          0.24     1\n## 2  0.000000          0.24     1\n## 3  0.091398          0.23     1\n## 4  0.000000          0.00     1\n## 5  0.000000          0.00     0\n## 6  0.000000          0.30     0"},{"path":"caret---a-machine-learning-package-turotial.html","id":"pre-processing","chapter":"21 caret - a machine learning package turotial","heading":"21.2 Pre-processing","text":"importing dataset, need separate data training testing sets. training set used examples machine learning models learn generalize, test set used evaluate preformance models. can achieve using createDataPartition() caret package.y specifies column partition datay specifies column partition datatimes specifies many times partition nthe datatimes specifies many times partition nthe datap specifies proportion split datap specifies proportion split datalist boolean indicating whether return listlist boolean indicating whether return listHere set 70% training set 30% testing set.next step clear refill missing values NAs dataset. several ways trasnformation fill missing value mean, mode simply delete row missing values. Using caret package, can apply NAs practical values, predict missing values values listed dataset. way caret package can use preProcess() function make k-Nearest Neighbors use training set.data specifies dataframe want apply preprocessingdata specifies dataframe want apply preprocessingmethod string specifies method preprocessingmethod string specifies method preprocessingThen get Nearest model perdicting missing values. , use predict() fill missing values prediction.result, can see prediction model centered 16 variables, ignored 2 created 825 samples 18 variables. importing NAs “predict” function, check missing values remaining dataset using angNA() function. result “FALSE” shows missing values replaced.Another work caret package can transform categorical variables one-hot vectors numerical representation categorical variables. one-hot vector constructed follows: suppose \\(n\\) classes categorical variables. represent class \\(\\) \\(n\\)-dimensional vector \\(o_i\\) \\(o_i[]=1\\) \\(o_i[j]=0\\) \\(j\\neq \\)can acheive one-hot transformation using dummyVars()formula repersents way inpute dataformula repersents way inpute datadata represents dataframedata represents dataframeAs can see, Store7.Store7.Yes represent one-hot encoding. actually apply dataset caret supports factor labels.","code":"\ncreateDataPartition(\n  y,\n  times,\n  p,\n  list\n)\n#set random seed to produce the same result\nset.seed(1)\n\n#use createDataPartition() function to get row of training. The input variable here is \"Purchase\" in df, and p = .7 implies the percentage of dataset we want to take. Here we set the training with 70%, so we let p equals to 0.7. Using List = F we are able to prevent the result as being a list instead of a dataframe.\nrowOfTrain <- createDataPartition(df$Purchase, p=0.7, list=FALSE)\n\n# create datasets for training and testing\ntrain_df <- df[rowOfTrain,]\ntest_df <- df[-rowOfTrain,]\npreProcess(\n  data,\n  method\n)\n# Create k-Nearest with training data using method = 'knnImpute'\nknn_inputer <- preProcess(train_df, method='knnImpute')\nknn_inputer## Created from 727 samples and 18 variables\n## \n## Pre-processing:\n##   - centered (16)\n##   - ignored (2)\n##   - 5 nearest neighbor imputation (16)\n##   - scaled (16)\n# Import the prediction into missing values using function predict()\ntrain_df <- predict(knn_inputer, newdata = train_df)\n\n#Check the NAs in the training dataset\nanyNA(train_df)## [1] FALSE\ndummyVars(\n  formula,\n  data\n)\n# define the one-hot encoding object\none_hot_encoder <- dummyVars(Purchase~., train_df)\n\n# results after applying one-hot encoding\nhead(data.frame(predict(one_hot_encoder, train_df)))##   WeekofPurchase   StoreID     PriceCH     PriceMM     DiscCH     DiscMM\n## 1     -1.1406992 -1.267157 -1.16230500 -0.70167093 -0.4532457 -0.5650681\n## 2     -1.0116414 -1.267157 -1.16230500 -0.70167093 -0.4532457  0.8702789\n## 3     -0.6244679 -1.267157 -0.08909746  0.03485153  0.9895487 -0.5650681\n## 4     -1.7859884 -1.267157 -1.74769093 -2.91123832 -0.4532457 -0.5650681\n## 5     -1.7214595  1.327114 -1.74769093 -2.91123832 -0.4532457 -0.5650681\n## 6     -1.5924017  1.327114 -1.74769093 -0.70167093 -0.4532457 -0.5650681\n##    SpecialCH  SpecialMM     LoyalCH SalePriceMM SalePriceCH  PriceDiff Store7No\n## 1 -0.4101973 -0.4461947 -0.24490422  0.08791265  -0.4606397  0.3276049        1\n## 2 -0.4101973  2.2381700  0.08369962 -1.10522569  -0.4606397 -0.7838676        1\n## 3 -0.4101973 -0.4461947  0.34658269  0.48562543  -0.8807610  0.9203903        1\n## 4 -0.4101973 -0.4461947 -0.57350806 -1.10522569  -0.8807610 -0.5615731        1\n## 5 -0.4101973 -0.4461947  1.25528731 -1.10522569  -0.8807610 -0.5615731        0\n## 6 -0.4101973  2.2381700  1.28385285  0.08791265  -0.8807610  0.5498994        0\n##   Store7Yes  PctDiscMM PctDiscCH ListPriceDiff      STORE\n## 1         0 -0.5718037 -0.449862     0.2132873 -0.4419062\n## 2         0  0.9396462 -0.449862     0.2132873 -0.4419062\n## 3         0 -0.5718037  1.016257     0.1218262 -0.4419062\n## 4         0 -0.5718037 -0.449862    -1.9817791 -0.4419062\n## 5         1 -0.5718037 -0.449862    -1.9817791 -1.1401926\n## 6         1 -0.5718037 -0.449862     0.7620539 -1.1401926"},{"path":"caret---a-machine-learning-package-turotial.html","id":"model-training","chapter":"21 caret - a machine learning package turotial","heading":"21.3 Model training","text":"machine learning models defined trained caret train() function. core function masks tedious detail machine learning algorithms provide convenient concise interface. train() function versions different parameters:formula specifies way want construct modelformula specifies way want construct modeldata specifies training data want use construct labeldata specifies training data want use construct labelmethod string specifiying model want apply datamethod string specifiying model want apply dataThe first version train function recommended data single dataframe. another word, column represents feature \\(x_i\\) one column represents \\(y\\). second version train function recommended \\(x\\) \\(y\\) separate dataframes. following code, use first version train() prediction.method parameter can specified conveniently string. far 238 models supported caret can found https://topepo.github.io/caret/available-models.html. tutorial, illustrate apply several common classification algorithms dataset.One amazing feature caret almost methods, automatically finds best hyperparameters user.","code":"\n# first version of train\nmodel <- train(\n  formula,\n  data,\n  method,\n)\n\n# second version of train\nmodel <- train(\n  x,\n  y,\n  method,\n)"},{"path":"caret---a-machine-learning-package-turotial.html","id":"k-nearest-neighbors","chapter":"21 caret - a machine learning package turotial","heading":"21.3.1 K-nearest neighbors","text":"k-nearest neighbor intuitive classification algorithm. Given positive \\(k\\) data \\(x\\), k-neigherest neighbor finds k nearest neighbors training set based euclidian distance\n\\[dist(x,x')=\\sqrt{(x_1-x'_1)^2+(x_2-x'_2)^2+\\cdots + (x_n-x'_n)^2}\\]\nclassifies \\(x\\) class contains nearst neighbors.implement algorithm, specify parameter method=knn","code":"\n# training the knn model\nknn_model <- train(\n  Purchase ~.,\n  train_df,\n  method = \"knn\"\n)\n\nknn_model## k-Nearest Neighbors \n## \n## 750 samples\n##  17 predictor\n##   2 classes: 'CH', 'MM' \n## \n## No pre-processing\n## Resampling: Bootstrapped (25 reps) \n## Summary of sample sizes: 750, 750, 750, 750, 750, 750, ... \n## Resampling results across tuning parameters:\n## \n##   k  Accuracy   Kappa    \n##   5  0.7430519  0.4561180\n##   7  0.7506511  0.4701385\n##   9  0.7522812  0.4717872\n## \n## Accuracy was used to select the optimal model using the largest value.\n## The final value used for the model was k = 9."},{"path":"caret---a-machine-learning-package-turotial.html","id":"logistics-regression","chapter":"21 caret - a machine learning package turotial","heading":"21.3.2 Logistics Regression","text":"logistics regression linear model binary classification, another word, given features \\(x_1,x_2,\\cdots,x_n\\), want predict \\(y=\\{0,1\\}\\). model can described equation\n\\[\\hat{y}=\\sigma(w_1\\cdot x_1+w_2\\cdot x_2+\\cdots+w_n\\cdot x_n)\\]\n\\(\\sigma\\) function defined \n\\[\\sigma(x)=\\frac{1}{1+e^{-x}}\\]hope logistics regression algorithm can find optimal \\(w_1,\\cdots,w_n\\) \\(\\hat{y}\\) closed true label \\(y\\) possible.implement algorithm, specify parameter method=\"glm\":","code":"\n# training the logistics regression model\nlr_model <- train(\n  Purchase ~.,\n  train_df,\n  method = \"glm\"\n)\n\nlr_model## Generalized Linear Model \n## \n## 750 samples\n##  17 predictor\n##   2 classes: 'CH', 'MM' \n## \n## No pre-processing\n## Resampling: Bootstrapped (25 reps) \n## Summary of sample sizes: 750, 750, 750, 750, 750, 750, ... \n## Resampling results:\n## \n##   Accuracy   Kappa    \n##   0.8219706  0.6207552"},{"path":"caret---a-machine-learning-package-turotial.html","id":"support-vector-machine","chapter":"21 caret - a machine learning package turotial","heading":"21.3.3 Support vector machine","text":"support vector machine hyperplane separates input space two subspaces. case \\(x_1\\) \\(x_2\\), want draw line saparates cartesian plane. criteria choosing plane one maximizes distance closest data points classes. gives rise optimization objective\n\\[\\max_{w,b}\\frac{1}{\\vert\\vert w\\vert\\vert_2}\\min_{x_i\\D}\\vert w^Tx_i+b\\vert,\\quad \\text{ s.t. }\\forall ,\\quad y_i(w^Tx_i+b)\\ge 0 \\]\nimplement algorithm, specify parameter method=\"svmRadial\"","code":"\n# training the support vector machine model, the library kernlab is needed to perform kernal transformation\nsvm_model <- train(\n  Purchase ~.,\n  train_df,\n  method = \"svmRadial\"\n)\n\nsvm_model## Support Vector Machines with Radial Basis Function Kernel \n## \n## 750 samples\n##  17 predictor\n##   2 classes: 'CH', 'MM' \n## \n## No pre-processing\n## Resampling: Bootstrapped (25 reps) \n## Summary of sample sizes: 750, 750, 750, 750, 750, 750, ... \n## Resampling results across tuning parameters:\n## \n##   C     Accuracy   Kappa    \n##   0.25  0.8126657  0.5977679\n##   0.50  0.8143211  0.6016239\n##   1.00  0.8123949  0.5975775\n## \n## Tuning parameter 'sigma' was held constant at a value of 0.05934766\n## Accuracy was used to select the optimal model using the largest value.\n## The final values used for the model were sigma = 0.05934766 and C = 0.5."},{"path":"caret---a-machine-learning-package-turotial.html","id":"random-forest","chapter":"21 caret - a machine learning package turotial","heading":"21.3.4 Random Forest","text":"decision tree algorithm learns predict value target variable learning simple decision rules inferred data features. process constructing tree first select root node \\(x_i\\) decision boundry \\(b_i\\). recirsively select children nodes corresponding decision threshold \\(b\\) maximizes information gain. Since different initialization produces different results, random forest aims create multiple trees different initialization collectively ageraging result produced individual decision treesTo implement algorithm, specify parameter method=\"earch\"","code":"\n# training the random forest model, the library earth is needed\nrf_model <- train(\n  Purchase ~.,\n  train_df,\n  method = \"earth\"\n)\n\nrf_model## Multivariate Adaptive Regression Spline \n## \n## 750 samples\n##  17 predictor\n##   2 classes: 'CH', 'MM' \n## \n## No pre-processing\n## Resampling: Bootstrapped (25 reps) \n## Summary of sample sizes: 750, 750, 750, 750, 750, 750, ... \n## Resampling results across tuning parameters:\n## \n##   nprune  Accuracy   Kappa    \n##    2      0.7958702  0.5634097\n##   12      0.8095924  0.5959591\n##   23      0.8081299  0.5933340\n## \n## Tuning parameter 'degree' was held constant at a value of 1\n## Accuracy was used to select the optimal model using the largest value.\n## The final values used for the model were nprune = 12 and degree = 1."},{"path":"caret---a-machine-learning-package-turotial.html","id":"model-prediction-and-evaluation","chapter":"21 caret - a machine learning package turotial","heading":"21.4 Model prediction and evaluation","text":"successfully train models, time evaluate test set validate good model. key function achieve predict() function:evaluate models trained , can call predict() function models:can compute confution matrix model:Confusion matrix knn model:Confusion matrix logistics regression model:Confusion matrix svm model:Confusion matrix random forest model:caret package also provides convenient function resamples() compare metric models.can see random forest best performance dataset.","code":"\npredict(\n  object,\n  newdata\n)\n# inpute the test data first\ntest_df <- predict(knn_inputer, test_df)\nknn_cm <- confusionMatrix(reference = factor(test_df$Purchase), data = predict(knn_model, test_df), mode='everything', positive='MM')\n\nknn_cm$table##           Reference\n## Prediction  CH  MM\n##         CH 169  30\n##         MM  26  95\nggplot(data = data.frame(knn_cm$table), aes(x=Reference, y=Prediction))+\n  geom_tile(aes(fill=Freq)) +\n  scale_fill_gradient2(low=\"light blue\", high=\"blue\") +\n  geom_text(aes(label=Freq)) +\n  ggtitle(\"Confution matrix for KNN model\")\nlr_cm <- confusionMatrix(reference = factor(test_df$Purchase), data = predict(lr_model, test_df), mode='everything', positive='MM')\n\nlr_cm$table##           Reference\n## Prediction  CH  MM\n##         CH 164  20\n##         MM  31 105\nggplot(data = data.frame(lr_cm$table), aes(x=Reference, y=Prediction))+\n  geom_tile(aes(fill=Freq)) +\n  scale_fill_gradient2(low=\"light blue\", high=\"blue\") +\n  geom_text(aes(label=Freq)) +\n  ggtitle(\"Confution matrix for Logistics Regression model\")\nsvm_cm <- confusionMatrix(reference = factor(test_df$Purchase), data = predict(svm_model, test_df), mode='everything', positive='MM')\n\nsvm_cm$table##           Reference\n## Prediction  CH  MM\n##         CH 170  27\n##         MM  25  98\nggplot(data = data.frame(svm_cm$table), aes(x=Reference, y=Prediction))+\n  geom_tile(aes(fill=Freq)) +\n  scale_fill_gradient2(low=\"light blue\", high=\"blue\") +\n  geom_text(aes(label=Freq)) +\n  ggtitle(\"Confution matrix for SVM model\")\nrf_cm <- confusionMatrix(reference = factor(test_df$Purchase), data = predict(svm_model, test_df), mode='everything', positive='MM')\n\nrf_cm$table##           Reference\n## Prediction  CH  MM\n##         CH 170  27\n##         MM  25  98\nggplot(data = data.frame(rf_cm$table), aes(x=Reference, y=Prediction))+\n  geom_tile(aes(fill=Freq)) +\n  scale_fill_gradient2(low=\"light blue\", high=\"blue\") +\n  geom_text(aes(label=Freq)) +\n  ggtitle(\"Confution matrix for random forest model\")\nmodel_list <- list(KNN = knn_model, LR = lr_model, SVM = svm_model, RF = rf_model)\n\nmodels_compare <- resamples(model_list)\n\nsummary(models_compare)## \n## Call:\n## summary.resamples(object = models_compare)\n## \n## Models: KNN, LR, SVM, RF \n## Number of resamples: 25 \n## \n## Accuracy \n##          Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\n## KNN 0.7025090 0.7343173 0.7491166 0.7522812 0.7703180 0.8197880    0\n## LR  0.7909408 0.8118081 0.8201439 0.8219706 0.8297101 0.8763636    0\n## SVM 0.7620818 0.8013937 0.8172043 0.8143211 0.8239700 0.8525180    0\n## RF  0.7750000 0.7906137 0.8058608 0.8095924 0.8230769 0.8625954    0\n## \n## Kappa \n##          Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\n## KNN 0.3824306 0.4294194 0.4604863 0.4717872 0.5098018 0.6148838    0\n## LR  0.5476278 0.5914299 0.6196513 0.6207552 0.6368782 0.7459377    0\n## SVM 0.4965787 0.5830797 0.6013610 0.6016239 0.6178862 0.6848073    0\n## RF  0.5198789 0.5579644 0.5906583 0.5959591 0.6214686 0.7077705    0"},{"path":"caret---a-machine-learning-package-turotial.html","id":"reference-2","chapter":"21 caret - a machine learning package turotial","heading":"21.5 Reference","text":"Caret Package – Practical Guide Machine Learning R - Selva Prabhakaran:\nhttps://www.machinelearningplus.com/machine-learning/caret-package/#61howtotrainthemodelandinterprettheresults?basic tutorial caret: machine learning package R - Rebecca Barter:\nhttps://www.rebeccabarter.com/blog/2017-11-17-caret_tutorial/caret Package - Max Kuhn:\nhttps://topepo.github.io/caret/index.html","code":""},{"path":"streamlit-for-financial-analysis.html","id":"streamlit-for-financial-analysis","chapter":"22 Streamlit for Financial Analysis","heading":"22 Streamlit for Financial Analysis","text":"Smaranjit Ghose Siddhant Pravin MahurkarMotivation project:previous experiences working Data Science teams personal trading endeavors, observed huge gap literature available easily building useful dashboards analysis price financial instruments like stocks, bonds crypto. internet flooded false promising articles use Reinforcement Learning accurately predict stock prices less material actually code’s customized dashboard analyze various indicators making trade. Furthermore, rise streamlit de facto app deploying end end machine learning applications,saw opportunity bring benefits problem financial data visualization. Moreover, lot people get stuck work done JupyterNotebook RMarkdown fail take production often demand working Data Science team needs present MVP clients. Hence, also shown take dashboard production users can interact real time.Link Project can found hereThe Link Blog can found hereThe Link Repository can found ","code":""},{"path":"interactive-graphs-tutorial.html","id":"interactive-graphs-tutorial","chapter":"23 Interactive graphs tutorial","heading":"23 Interactive graphs tutorial","text":"Chuyang XiaoThe following content brief introductory tutorial create interactive graphs common packages R.","code":"\nlibrary(ggvis)\nlibrary(dplyr)\n\nlibrary(plotly)\n\nlibrary(igraph)\nlibrary(networkD3)"},{"path":"interactive-graphs-tutorial.html","id":"introduction-1","chapter":"23 Interactive graphs tutorial","heading":"23.1 Introduction","text":"rmd file incorporates hand--hand tutorial several useful tools create interactive figures via multiple popular toolboxes. Though pretty attractive well persuasive data presentation, creation interactive diagrams seldom mentioned lecture. Thus, self-learnt couple useful tools decided make detailed tutorial create interactive diagrams.Commonly, compared data selection, critical parameters determining appearances styles diagrams, spline line size dots, even difficult decide. Sometimes, may laborious alter function parameters one--one check output. Hence, interactive graph may pretty helpful condition, enables flexibly modify appearances graphs. Moreover, data presentation, interactive graph also facilitate emphasize specific characteristics well overall patterns graph.following sections, shall run code chunk one--one. description method front code chunk (please read running code) analysis output . lecture, contents fully explained far, hence, pretty confident , finishing reading tutorial, master decent number methods create interactive graphs.way, please read rmd file rather html file check graphs, since dynamic graphs become static .","code":""},{"path":"interactive-graphs-tutorial.html","id":"create-interactive-graphs-via-ggvis","chapter":"23 Interactive graphs tutorial","heading":"23.2 Create Interactive Graphs via ggvis","text":"library ggvis similar ggplot2 extents, ’s expressed little differently, adds new features make plots interactive.graphics produced ggvis mostly web graphics work differently traditional R graphics. presentation graphs becomes various fabulous, yet computationally costly. example, every interactive ggvis plot must connected running R session (static plots need running R session viewed). great exploration, can anything interactive plot can R, ’s great publication. overcome issues time, now aware many existing tools reimplement can everything ggvis can base graphics.Firstly, shall import library ggvis. (Since installation packages installed top file, mind, please uncomment following contents install )Similar ggplot2, ggvis also portray make basic plots\nRenderer: \nSVG\n | \nCanvas\n\nDownload\nHence, observed ggvis well create scatterplot graphs, difference geom_points changed layer_points. hand, also options create similar basic graphs ggplot. try methods useful parameters well:layer_bars(width = , stack = ): create bar chart, width stands width bar, stack represents whether bars stackedlayer_points(size = , fill = ): create scatter plot, size stands size dots, andlayer_lines(): create line chartlayer_smooths(span = ): create smooth conditional mean, span stands extent spanning linelayer_histogram(width = ): create histogram, width stands width barslayer_densities(kernel = ): create density curve, kernel stands kind distribution curve tends obeyIn addition static graphs, library ggvis furthermore known abundant methods creating interactive graphs. instance, via input series method, modify parameters ux interface.following code chunk, input_slider employed, conduct sliders span conditional mean size dots. Please run code , try slide sliders aware changes graph. finish modifications, please click esc key exit interactive interface.\nRenderer: \nSVG\n | \nCanvas\n\nDownload\njust saw graph, two sliders bottom graph. sliding horizontally, determine size dots span smooths optimal state. Likewise, see code, instead particular numeric value, span size replaced new function input_slider. input_slider method requires four parameters set range: first two minimum maximum range, value default value slider, label defines name slider. interactive interface pretty useful determining continuous variables, sizes dots scatter plots width bars bar charts histograms.way, sliders inserted functions parameter values reused. Just like following code:\nRenderer: \nSVG\n | \nCanvas\n\nDownload\nJust like code demonstrate, parameters types ranges, establish one slider object first insert function.addition sliders, ggvis provides multiple methods interact graph. Another common method input_select, provide band including various options. Please run code , try change mode kernel, aware changes graph. finish modifications, please click esc key exit interactive interface.\nRenderer: \nSVG\n | \nCanvas\n\nDownload\ninteractive graph created , seen selection box bottom graph, change kernel via selecting different options . code input_select take list basic parameters, mapping displayed options internal parameters graph. instance, Gaussian appeared selection box stand gaussian option kernel. Compared slider object, selection box appropriate categorical parameters, distribution, color, shape.addition sliders selection box, ggvis also offers number interactive controls, particular applications:input_checkbox(): check-box, feature useful determine boolean valuesinput_checkboxgroup(): group check boxes, feature useful determine number boolean valuesinput_numeric(): spin box, best numeric parametersinput_radiobuttons(): pick one set options, best categorical parametersinput_select(): create drop-text box, best categorical parametersinput_text(): arbitrary text input, best string inputs, x y labels titles.conclude, replacing static parameters functions input series, flexibly modify alterable parameters graph.Moreover, ggvis also provides sorts interactive patterns useful data presentations. presenting bar chart, may need emphasize certain bar explanation. Hence, parameter fill.hover helpful indeed. Please run code , swipe mouse bars, see changes graph.\nRenderer: \nSVG\n | \nCanvas\n\nDownload\nJust like just saw, bar change color cursor landing . function fill fill.hover. parameter fill.hover takes one value, specific color, therefore bar turn color touched cursor. helpful presenting diagram someone else.Similarly, method applied kind graphs. Please run code , swipe mouse line, see changes graph.\nRenderer: \nSVG\n | \nCanvas\n\nDownload\ncan see graph , line turn red cursor lands . function exceptionally useful many convoluted overlapped lines specify one presentation.conclude, package ggvis cover major functions ggplot2, well create interactive graphs helpful experiment presentation.","code":"\n# if(!require(ggvis)) install.packages(\"ggvis\")\n# if(!require(dplyr)) install.packages(\"dplyr\")\n\n# library(ggvis)\n# library(dplyr)\n\n# Most of the following diagrams would be generated by the dataset \"iris\"\ndf <- iris\n# Create an ordinary scatterplot\ndf %>%\n  ggvis(~Sepal.Length,\n        ~Sepal.Width, \n        fill=~Species) %>%\n  layer_points()\ndf %>%\n  ggvis(~Sepal.Length, ~Sepal.Width) %>%\n  layer_smooths(span = input_slider(0.5, 1, value = 1, label = \"Span\")) %>%\n  layer_points(size := input_slider(20, 100, value = 20, label = \"Dot Sizes\"))\nslider <- input_slider(20, 100, value = 20, label = \"Dot Sizes\")\ndf %>% ggvis(~Sepal.Length, ~Sepal.Width) %>%\n  layer_points(size := slider) %>% \n  layer_points(fill := \"red\", opacity := 0.5, size := slider)\ndf %>% ggvis(x = ~Sepal.Length) %>%\n    layer_densities(\n      adjust = input_slider(.1, 2, value = 1, step = .1, label = \"Bandwidth adjustment\"),\n      kernel = input_select(\n        c(\"Gaussian\" = \"gaussian\",\n          \"Epanechnikov\" = \"epanechnikov\",\n          \"Rectangular\" = \"rectangular\",\n          \"Triangular\" = \"triangular\",\n          \"Biweight\" = \"biweight\",\n          \"Cosine\" = \"cosine\",\n          \"Optcosine\" = \"optcosine\"),\n        label = \"Kernel\")\n      )\ndf %>% \n  ggvis(~Sepal.Length, \n        fill := \"#fff8dc\", \n        fill.hover := \"#fcb5a2\") %>%\n  layer_histograms(width = 0.25)\ndf %>% \n  ggvis(~Sepal.Length, \n        ~Sepal.Width,\n        stroke = ~Species,\n        stroke.hover := \"red\",\n        strokeWidth := 2\n        ) %>%\n  layer_lines()"},{"path":"interactive-graphs-tutorial.html","id":"create-interactive-graphs-via-plotly","chapter":"23 Interactive graphs tutorial","heading":"23.3 Create Interactive Graphs via plotly","text":"Similar ggvis, plotly also powerful tool create interactive graphs. Compared conventional ggplot ggvis, create complicated well vivid graphs based data various sources.first, please run code install package. (Since installation packages installed top file, mind, please uncomment following contents install )First foremost, plotly, graph created function plot_ly, style setting set function add_lines. Please run code take look graph created.move cursor along curve line, interact graph clearly see x y coordinates dots, truly helpful estimating maximum minimum graph. Likewise, kind graphs created function plot_ly(data =, x =, type = XXX), XXX replace following methods:‘bar’, ‘barpolar’, ‘box’, ‘candlestick’, ‘carpet’, ‘choropleth’, ‘choroplethmapbox’, ‘cone’, ‘contour’, ‘contourcarpet’, ‘densitymapbox’, ‘funnel’, ‘funnelarea’, ‘heatmap’, ‘heatmapgl’, ‘histogram’, ‘histogram2d’, ‘histogram2dcontour’, ‘icicle’, ‘image’, ‘indicator’, ‘isosurface’, ‘mesh3d’, ‘ohlc’, ‘parcats’, ‘parcoords’, ‘pie’, ‘pointcloud’, ‘sankey’, ‘scatter’, ‘scatter3d’, ‘scattercarpet’, ‘scattergeo’, ‘scattergl’, ‘scattermapbox’, ‘scatterpolar’, ‘scatterpolargl’, ‘scatterternary’, ‘splom’, ‘streamtube’, ‘sunburst’, ‘surface’, ‘table’, ‘treemap’, ‘violin’, ‘volume’, ‘waterfall’However, package plotly far . ggvis simply modify appearances graphs, plotly alter type style graphs. following code, added feature named updatememus, panel one figure allows interact , added figure. Please run code try push two buttons see change graph.According graph, easily see two buttons left change style graph violin plot box plot. Likewise, land cursor box violin, statistic values including median, maximum, minimum values outliers shown, exceedingly convenient. Moreover, focus code, see two list button section corresponds two buttons left graph. parameters list defined :method = “restyle” : modify style graph, parameter always “restyle”\nargs = list(“type”, “box”) : first item type parameter plot_ly desired changed, also color\nlabel = “Box Graph” : name appeared buttonIt indeed easy change style graph clicking buttons, please make sure input data acceptable styles graphs choose.Moreover, besides style graphs, color schema graphs modified well pattern. Please run code click button see changes make graph.observed graph , data structure suitable, easily transformed heatmap, contour lines, surface graphs, well various color schema. Regarding code, buttons stored two lists, color types chart types, incorporated final graph operate separately. Thus, like update certain graph various perspectives, please generate one kind buttons within one list zip together updatemenus final graph. Besides, just like previous graphs, moving cursor graph, also see 3-dimensional coordinate segment, swipe cursors surface graph zoom zoom ., previous shown content just tiny proportion plotly, package still contains numerous powerful toolboxes construct interactive graphs explore.","code":"\n# if(!require(plotly)) install.packages(\"plotly\")\n\n# library(plotly)\nx <- seq(-2*pi, 2*pi, length.out = 1000)\ndf <- data.frame(x, y1 = cos(x))\n\nfig <- plot_ly(df, x = ~x) %>% \n  add_lines(y = ~y1)\n\nfig\nfig = plot_ly(midwest, x = ~percollege, color = ~state, type = \"box\")\n\nfig <- fig %>% layout(\n  xaxis = list(domain = c(0.1, 1)),\n  yaxis = list(title = \"y\"),\n  updatemenus = list(\n    list(\n      type = \"buttons\",\n      y = 0.8,\n      # Establish a button to restyle the graph\n      buttons = list(\n        list(method = \"restyle\",\n             args = list(\"type\", \"box\"),\n             label = \"Box Graph\"),\n        \n        list(method = \"restyle\",\n             args = list(\"type\", \"violin\"),\n             label = \"Violin Graph\")\n        ))\n  ))\n\nfig\nfig <- plot_ly(z = ~as.matrix(mtcars), type = \"heatmap\", colorscale='Rainbow')\n\n# chart option buttons\nchart_types <- list(\n  type = \"buttons\",\n  direction = \"right\",\n  xanchor = 'center',\n  yanchor = \"top\",\n  pad = list('r'= 0, 't'= 10, 'b' = 10),\n  x = 0.5,\n  y = 1.27,\n  \n  # type option buttons\n  buttons = list(\n\n    list(method = \"restyle\",\n         args = list(\"type\", \"heatmap\"),\n         label = \"Heatmap\"),\n\n    list(method = \"restyle\",\n         args = list(\"type\", \"contour\"),\n         label = \"Contour\"),\n\n    list(method = \"restyle\",\n         args = list(\"type\", \"surface\"),\n         label = \"Surface\")\n  ))\n\n# color option buttons  \ncolor_types <- list(\n  type = \"buttons\",\n  direction = \"right\",\n  xanchor = 'center',\n  yanchor = \"top\",\n  pad = list('r'= 0, 't'= 10, 'b' = 10),\n  x = 0.5,\n  y = 1.17,\n  buttons = list(\n\n    list(method = \"restyle\",\n         args = list(\"colorscale\", \"Rainbow\"),\n         label = \"Rainbow\"),\n\n    list(method = \"restyle\",\n         args = list(\"colorscale\", \"Jet\"),\n         label = \"Jet\"),\n\n    list(method = \"restyle\",\n         args = list(\"colorscale\", \"Earth\"),\n         label = \"Earth\"),\n\n    list(method = \"restyle\",\n         args = list(\"colorscale\", \"Electric\"),\n         label = \"Electric\")\n  ))\n\nannot <- list(list(text = \"Chart<br>Type\", x=0.2, y=1.25, xref='paper', yref='paper', showarrow=FALSE),\n              list(text = \"Color<br>Type\", x=0.2, y=1.15, xref='paper', yref='paper', showarrow=FALSE))\n\n# plot\nfig <- fig %>% layout(\n  xaxis = list(domain = c(0.1, 1)),\n  yaxis = list(title = \"y\"),\n  updatemenus = list(chart_types,color_types),\n  annotations = annot)\n\nfig"},{"path":"interactive-graphs-tutorial.html","id":"create-interactive-graphs-via-networkd3","chapter":"23 Interactive graphs tutorial","heading":"23.4 Create Interactive Graphs via networkD3","text":"packages ggplot2 ggvis plotly mostly focus presenting values given data, package networkD3 specializes demonstrating relationship data tree diagrams network diagrams. addition, kinds diagrams relatively structured simple form, interactive pattern package may let flexibly manipulate diaragm highlight certain parts.first, please run code chunk install packages import libraries. (Since installation packages installed top file, mind, please uncomment following contents install )Firstly, simply connected data, create simple network function simpleNetwork. Please run code chunk see output graph. also drag nodes diagrams see happen.see diagram , connective relationship diagram defined two zipped lists, . connection node b, please add list add b list , edge presented graph. Moreover, generated network graph highly flexible, rearrange flexibly expected form simply dragging cursor.hierarchical diagrams, appropriate function dendroNetwork, generate tree diagram displaying hierarchy items horizontally. Please run code swipe cursor along child node right see happens.see, method requires two sections. Firstly, cluster child nodes (model cars original data) hierarchical clusters method hclust. method take two parameters, input dataframe, method cluster . case, data clustered based ave (average). , hclust object generated displayed method dendroNetwork, accepts hclust inputs, conduct tree diagram. diagram, adjacency child nodes represents similarities average. Furthermore, swipe mouse nodes’ names, magnify font immediately, function shall pretty helpful presentations.addition simple networks, still functions package may utilize:\n1. sankeyNetwork: generate flow chart illustrate outflow inflow\n2. forceNetwork: control appearance forced directed network plot complicated networks.\n3. radialNetwork: radar-like appearances, source node locates center graph, spreads numerous child nodes.\n4. diagonalNetwork: similar dendroNetwork, links nodes via smooth curves.","code":"\n# if(!require(igraph)) install.packages(\"igraph\")\n# if(!require(networkD3)) install.packages(\"networkD3\")\n\n# library(igraph)\n# library(networkD3)\n# create a dataset:\ndata <- tibble(\n  from=c(\"A\", \"A\", \"B\", \"D\", \"C\", \"D\", \"E\", \"B\", \"C\", \"D\", \"K\", \"A\", \"M\"),\n  to=c(\"B\", \"E\", \"F\", \"A\", \"C\", \"A\", \"B\", \"Z\", \"A\", \"C\", \"A\", \"B\", \"K\")\n)\n\n# Plot\nsimpleNetwork(data,\n              height=\"100px\", \n              width=\"100px\"\n              )\ndf <- hclust(dist(mtcars), \"ave\")\n\ndendroNetwork(df, fontSize = 10)"},{"path":"interactive-graphs-tutorial.html","id":"conclusion","chapter":"23 Interactive graphs tutorial","heading":"23.5 Conclusion","text":"summarize, still number fantastic tools create interactive graphs, addition ggvis, plotly, networkD3. However, master functions mentioned tutorial, quite convenient produce nice graphs projects.","code":""},{"path":"interactive-graphs-tutorial.html","id":"reference-3","chapter":"23 Interactive graphs tutorial","heading":"23.6 Reference","text":"Plotly R Graphing Library. (2021). R | Plotly. https://plotly.com/r/\nGandrud, Christopher. (2017). christophergandrud. http://christophergandrud.github.io/networkD3/","code":""},{"path":"guideline-on-using-package-rcurl-and-xml-for-web-scraping.html","id":"guideline-on-using-package-rcurl-and-xml-for-web-scraping","chapter":"24 Guideline on Using Package Rcurl and XML for Web Scraping","heading":"24 Guideline on Using Package Rcurl and XML for Web Scraping","text":"Sitong Qian","code":"\nlibrary(RCurl)\nlibrary(XML)"},{"path":"guideline-on-using-package-rcurl-and-xml-for-web-scraping.html","id":"introduction-2","chapter":"24 Guideline on Using Package Rcurl and XML for Web Scraping","heading":"24.1 Introduction","text":"comes world EDAV, rich dataset inevitably cornerstone success. obtaining dataset always easy job, sometimes, dataset dirty, waiting throughout clean using, might case ’s still born yet, piece-wise information, needed assembled data frame format. Thus, ’s bringing us question construct dataset none., want give approach extarct basic information need dataset construction website, namely web scraping, using package Rcurl XML. ease potential confusion, go concrete example step step, introducing functions go steps, explaining details behind functions simple way showing exactly extracting work.","code":""},{"path":"guideline-on-using-package-rcurl-and-xml-for-web-scraping.html","id":"extracting-information-for-constructing-dataset-rcurl-and-xml","chapter":"24 Guideline on Using Package Rcurl and XML for Web Scraping","heading":"24.2 Extracting Information for Constructing Dataset – Rcurl and XML","text":"","code":""},{"path":"guideline-on-using-package-rcurl-and-xml-for-web-scraping.html","id":"step-1-web-searching","chapter":"24 Guideline on Using Package Rcurl and XML for Web Scraping","heading":"24.2.1 Step 1: Web Searching","text":"first step choosing topic interested , Since ’s job hunting season, let’s say wanna know Data related job posted website CyberCoders. simply copy page browserBy clicking link, expected directed page like .Now, let’s put keyword DataHere, use getForm() function Rcurl Package.According Rcurl package description cran, getForm() provide facilities submitting HTML form using simple GET mechanism(appending name-value pairs parameters URL)straightfoward, getForm() work putting search word box click search buttom. keyword Data myinput, searchterms comes ? Now, go steps searchterms\nfollowing instruction valid macOS system\n\nUsing Chrome browser, site cybercoders, click View -> Developer -> ViewSourceThen redirected page gives HTML source code, page, see HTML page build hierarchy, quickly go page, find term describes search box line 130 name = “searchterms”finish first step, Web Searching. Clearly, different websites hierarchy tree possibly unique ways calling searchterms, Thus, using method, need look specific cases slightly modifications.","code":"\nlink = 'https://www.cybercoders.com/search'\nsearch = getForm(link,searchterms = 'Data' )"},{"path":"guideline-on-using-package-rcurl-and-xml-for-web-scraping.html","id":"step-2-cleanupparsing-search-results","chapter":"24 Guideline on Using Package Rcurl and XML for Web Scraping","heading":"24.2.2 Step 2: Cleanup(Parsing) Search Results","text":"previous step, end putting keywords Data searchterms. , search returns basically expected see enter Data search box directly website, click View Source.input search console, find returns HTML page looking really messy form. ’s getform() function converts page character.cut length, just took screenshot console, otherwise, output occupy several pages actual meaning.want, since HTML built hierarchy, forms can’t obtain information. Thus need return readable form. introduce another powerful function htmlParse XML packageHere, htmlParse simple can directly referred function name, parsing output HTML form.cut length, just took screenshot console, otherwise, output occupy several pages actual meaning.returning nice clean form, move next job, detect pattern!Web scraping really fun, time ’s build elegant neatness doesn’t mean always nice easy, sake time, just assume time.","code":"\ndocument = htmlParse(search)"},{"path":"guideline-on-using-package-rcurl-and-xml-for-web-scraping.html","id":"step-3-detect-the-pattern","chapter":"24 Guideline on Using Package Rcurl and XML for Web Scraping","heading":"24.2.3 Step 3: Detect the Pattern","text":"previous section, return results nice clean form, now need detect pattern. ’s fairly easy see variable document give us first page searching result. directly look website, page returned roughly 21 job positions, want divide 21 jobs can look .introduce function getNodeSet()According XML instruction cran, getNodeSet() find matching nodes internal XML tree. see class(document) find one “XMLInternalDocument”.Exactly want!discussed , HTML built hierarchy. ’s hard find jobs starts div class=“job-listing-item” Thus, now know correct function use know nodes, combine two together, get function. exactly 21 items list, corresponding 21 jobs display websites, showed first jobs later illustration","code":"\nclass(document)## [1] \"HTMLInternalDocument\" \"HTMLInternalDocument\" \"XMLInternalDocument\" \n## [4] \"XMLAbstractDocument\"\nlist = getNodeSet(document,\"//div[@class = 'job-listing-item']\")\nlist[1][[1]]## <div class=\"job-listing-item\">&#13;\n##     <div class=\"job-status\">&#13;\n##         &#13;\n##     <\/div>&#13;\n##     <div class=\"job-details-container\">&#13;\n##         <div class=\"job-title\">&#13;\n##             <a href=\"/data-engineer-job-455427\">Data Engineer<\/a>&#13;\n##         <\/div>&#13;\n##         <div class=\"details\">&#13;\n##             <div class=\"location\">Mountain View, CA <\/div>&#13;\n## &#13;\n## &#13;\n## &#13;\n##                 <div class=\"wage\"><span>Full-time<\/span> $80k - $130k<\/div>&#13;\n##             <div class=\"posted\"><span>Posted<\/span> 10/19/2021<\/div>&#13;\n##         <\/div>&#13;\n##         <div class=\"description\">&#13;\n##             If you are a Data Engineer with experience, please read on! This is a great opportunity for a Data Engineer who is looking to make a shift to Data Science or wanting to develop more skills. This indiv...&#13;\n##         <\/div>&#13;\n##             <div class=\"skills\">&#13;\n##                 <ul class=\"skill-list\"><li class=\"skill-item\">&#13;\n##                             <a href=\"/search/data-engineering-skills/\">&#13;\n##                                 <span class=\"left-off\"/>&#13;\n##                                 <span class=\"skill-name\">Data Engineering<\/span>&#13;\n##                                 <span class=\"right\"/>&#13;\n##                             <\/a>&#13;\n##                         <\/li>&#13;\n##                         <li class=\"skill-item\">&#13;\n##                             <a href=\"/search/data-science-skills/\">&#13;\n##                                 <span class=\"left-off\"/>&#13;\n##                                 <span class=\"skill-name\">Data Science<\/span>&#13;\n##                                 <span class=\"right\"/>&#13;\n##                             <\/a>&#13;\n##                         <\/li>&#13;\n##                         <li class=\"skill-item\">&#13;\n##                             <a href=\"/search/gathering-and-collecting-data-skills/\">&#13;\n##                                 <span class=\"left-off\"/>&#13;\n##                                 <span class=\"skill-name\">Gathering and Collecting Data<\/span>&#13;\n##                                 <span class=\"right\"/>&#13;\n##                             <\/a>&#13;\n##                         <\/li>&#13;\n##                         <li class=\"skill-item\">&#13;\n##                             <a href=\"/search/batch-processing-skills/\">&#13;\n##                                 <span class=\"left-off\"/>&#13;\n##                                 <span class=\"skill-name\">Batch Processing<\/span>&#13;\n##                                 <span class=\"right\"/>&#13;\n##                             <\/a>&#13;\n##                         <\/li>&#13;\n##                         <li class=\"skill-item\">&#13;\n##                             <a href=\"/search/api-skills/\">&#13;\n##                                 <span class=\"left-off\"/>&#13;\n##                                 <span class=\"skill-name\">API<\/span>&#13;\n##                                 <span class=\"right\"/>&#13;\n##                             <\/a>&#13;\n##                         <\/li>&#13;\n##                 <\/ul><\/div>&#13;\n##     <\/div>&#13;\n## <\/div>"},{"path":"guideline-on-using-package-rcurl-and-xml-for-web-scraping.html","id":"step-4-extract-information-on-each-job-post","chapter":"24 Guideline on Using Package Rcurl and XML for Web Scraping","heading":"24.2.4 Step 4: Extract Information on Each Job Post","text":"previous step, get list 21 jobs, now want extract actual information looking construct dataset. Based result, look variables like Job-Title,Wage,Location,Skill,Posted Date,Job Description, etcThen, extract variable name categories? look back first job reference. Let’s say wanna Job-TitleWe introduce function xpathSApplyAccording XML cran, can think xpathSApply two parts, xpath SApply, xpath scan page match result input, SApply returned .like , found job-title starts node div class=‘job-title’, combine function indicatorWhile title 1 located information want, slightly messy since ’s still contains XML format.magic tool, xmlValue, adding xmlValue function, get rid XML locators, just valueStill, irrevalant things, can use trimws fix , get nice pretty formThis xpathSApply function really powerful function extracting value need, ’s return character, can use regular expression clean-jobs. personally think important function XML package.1st job","code":"\ntest = list[1][[1]]\ntitle1 = xpathSApply(test, \".//div[@class = 'job-title']\")\ntitle1## [[1]]\n## <div class=\"job-title\">&#13;\n##             <a href=\"/data-engineer-job-455427\">Data Engineer<\/a>&#13;\n##         <\/div>\ntitle2 = xpathSApply(test, \".//div[@class = 'job-title']\",xmlValue)\ntitle2## [1] \"\\r\\n            Data Engineer\\r\\n        \"\ntitle3 = trimws(xpathSApply(test, \".//div[@class = 'job-title']\",xmlValue))\ntitle3## [1] \"Data Engineer\"\njob_title = trimws(unique(xpathSApply(test, \".//div[@class = 'job-title']\",xmlValue)))\nsalary_jobStatus = trimws(unique(xpathSApply(test, \".//div[@class = 'wage']\",xmlValue)))\nlocation = trimws(unique(xpathSApply(test, \".//div[@class = 'location']\",xmlValue)))\ndate = trimws(xpathSApply(test,\".//div[@class = 'posted']\",xmlValue))\ndescription =  trimws(xpathSApply(test,\".//div[@class = 'description']\",xmlValue))\npreferred_skills = trimws(unique(xpathSApply(test, \".//li[@class = 'skill-item']\",xmlValue)))\njob_title## [1] \"Data Engineer\"\nsalary_jobStatus## [1] \"Full-time $80k - $130k\"\nlocation## [1] \"Mountain View, CA\"\ndate## [1] \"Posted 10/19/2021\"\ndescription## [1] \"If you are a Data Engineer with experience, please read on! This is a great opportunity for a Data Engineer who is looking to make a shift to Data Science or wanting to develop more skills. This indiv...\"\npreferred_skills## [1] \"Data Engineering\"              \"Data Science\"                 \n## [3] \"Gathering and Collecting Data\" \"Batch Processing\"             \n## [5] \"API\""},{"path":"guideline-on-using-package-rcurl-and-xml-for-web-scraping.html","id":"step-5-combine-job-posts","chapter":"24 Guideline on Using Package Rcurl and XML for Web Scraping","heading":"24.2.5 Step 5: Combine Job Posts","text":", come next step, combining results job, well lots XML Rcurl package. However, thought intuitive step sake completeness, help build overall logical way thinking web scraping.Basically, apply one post, now want every post first page. code nothing fancy, just throw individual code “function form”.cut length, just output first three, output posts occupy several pages actual meaning.cut length, just output first three, output posts occupy several pages actual meaning.’s shown, results pretty much cleaned use probably need help regular expression make become actual dataset. since guideline focusing web scraping mainly. call end.","code":"\njob =\n  function(ind)\n  {\n    job_title = trimws(unique(xpathSApply(ind, \".//div[@class = 'job-title']\",xmlValue)))\n    salary_jobStatus = trimws(unique(xpathSApply(ind, \".//div[@class = 'wage']\",xmlValue)))\n    location = trimws(unique(xpathSApply(ind, \".//div[@class = 'location']\",xmlValue)))\n    date = trimws(xpathSApply(ind,\".//div[@class = 'posted']\",xmlValue))\n    description =  trimws(xpathSApply(ind,\".//div[@class = 'description']\",xmlValue))\n    preferred_skills = trimws(unique(xpathSApply(ind, \".//li[@class = 'skill-item']\",xmlValue)))\n    list(title = job_title, job_status =  salary_jobStatus,date = date,location = location,job_description = description,preferred_skills = preferred_skills)\n  }\n\npagecontentjoblist = function(link){\n    searchlinks = getForm(link,searchterms = 'Data' ) \n    documentlinks = htmlParse(searchlinks)\n    all_job_lists = getNodeSet(documentlinks,\"//div[@class = 'job-listing-item']\")\n    return(all_job_lists)\n}\n\nall_job_lists = pagecontentjoblist(link)\npost_all = lapply(all_job_lists, job)\npost_all[1:3]## [[1]]\n## [[1]]$title\n## [1] \"Data Engineer\"\n## \n## [[1]]$job_status\n## [1] \"Full-time $80k - $130k\"\n## \n## [[1]]$date\n## [1] \"Posted 10/19/2021\"\n## \n## [[1]]$location\n## [1] \"Mountain View, CA\"\n## \n## [[1]]$job_description\n## [1] \"If you are a Data Engineer with experience, please read on! This is a great opportunity for a Data Engineer who is looking to make a shift to Data Science or wanting to develop more skills. This indiv...\"\n## \n## [[1]]$preferred_skills\n## [1] \"Data Engineering\"              \"Data Science\"                 \n## [3] \"Gathering and Collecting Data\" \"Batch Processing\"             \n## [5] \"API\"                          \n## \n## \n## [[2]]\n## [[2]]$title\n## [1] \"Data Analyst - Google Tag Manager, A/B Testing\"\n## \n## [[2]]$job_status\n## [1] \"Full-time $90k - $130k\"\n## \n## [[2]]$date\n## [1] \"Posted 09/30/2021\"\n## \n## [[2]]$location\n## [1] \"Los Angeles, CA\"\n## \n## [[2]]$job_description\n## [1] \"If you are a Data Analyst with experience, please read on!    This is a full-time/permanent position, direct-hire with my client.    We are the world leading digital invitation platform that has been...\"\n## \n## [[2]]$preferred_skills\n## [1] \"GTM\"                \"Google Tag Manager\" \"Google Analytics\"  \n## [4] \"SQL\"                \"AB testing\"        \n## \n## \n## [[3]]\n## [[3]]$title\n## [1] \"Data Scientist\"\n## \n## [[3]]$job_status\n## [1] \"Full-time $100k - $150k\"\n## \n## [[3]]$date\n## [1] \"Posted 10/06/2021\"\n## \n## [[3]]$location\n## [1] \"Morrisville, NC\"\n## \n## [[3]]$job_description\n## [1] \"If you are a Data Scientist or Data Enthusiast with experience in bioinformatics, please read on!  We are looking to simplify the complex nature of cancer genomics and bring cutting edge technology an...\"\n## \n## [[3]]$preferred_skills\n## [1] \"Python\" \"Perl\"   \"SQL\"    \"R\"      \"SAS\""},{"path":"guideline-on-using-package-rcurl-and-xml-for-web-scraping.html","id":"conclusion-1","chapter":"24 Guideline on Using Package Rcurl and XML for Web Scraping","heading":"24.3 Conclusion","text":"go like web scraping using packages XML Rcurl, covered just basic approach using frequently used functions two packages. lots useful functions worth reading time. hope people read tutorial clear understanding idea Web Scraping, .","code":""},{"path":"guideline-on-using-package-rcurl-and-xml-for-web-scraping.html","id":"work-cited","chapter":"24 Guideline on Using Package Rcurl and XML for Web Scraping","heading":"24.4 Work Cited","text":"https://cran.r-project.org/web/packages/XML/XML.pdf\nhttps://cran.r-project.org/web/packages/RCurl/RCurl.pdf","code":""},{"path":"twitter-r-package-scraping-via-api-tutorial.html","id":"twitter-r-package-scraping-via-api-tutorial","chapter":"25 TwitteR R Package Scraping via API Tutorial","heading":"25 TwitteR R Package Scraping via API Tutorial","text":"Felix YeungSet :order begin using TwitteR package, first need create Twitter Account App can get API Access Keys & Tokens. exact steps:don’t one, go Twitter.com create account.Go apps.twitter.com create app *Note fill information creating app. easiest way write ’re exploring API.approved, can can finally start create app.completing steps, given opportunity save API Key, API Secret, Access Token, Access Token Secret. need save access API. *Note forgot save can always regenerate .Lastly, ’re done steps, can run install.packages(\"rtweet\") ’ll set!’s link full documentation: https://cran.r-project.org/web/packages/rtweet/rtweet.pdfStarting loading authenticiation token:keys/tokens acquired Set , can store token easy access. going need use token often ’re utilizing functions rtweet.Introduction useful functions:Friends & Followers\n- Friend account user follows\n- Follower account follows userThere’s functions enable pull friends followers account given handle.\n* get_friends() pulls list IDs friends user\n* get_followers() pulls list IDs follow userHere’s exampleWith list User IDs, can now use `lookup_users()’ find relevant information UserID.Tweets & FavoritesNext can look functions can pull information Tweets & Favorites.\n- Tweets character messages users can post Twitter\n- Favorites Tweets users likedHere useful functions:\nsearch_tweets()\nlookup_tweets()\n*get_favorites()Analysis & Interesting Application functions:Graphing # favorited tweets account timeNow basic building block functions, can put together interesting visualiations using Twitter data.first example , can graph number tweets @DataSciColumbia favorited!can see, account really active favorit-ing tweets 2017 2019. Maybe, go check owner account?Finding top hashtagsNext, can use search tweets function pull tweets mention @DataSciColumbia account find top hashtags (frequency) used mentioning account.","code":"\nlibrary(rtweet)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(DT)\nlibrary(ggplot2)\n# load rtweet\nlibrary(rtweet)\n\n# Store API Keys here. Use your own! These are fakes.\napikey <- \"bgBjMmye9UQESChqld2gjkDnm\"\napisecret <- \"P9xUNJ2PCbxlQ3znD6bj8jOM7VPSdqeujVmCjMUxYijBYFGA2c\"\naccestoken <- \"1283967367333191687-bMXBUIqjkbYcaZnMfacl9V0ijcYf9j\"\naccesssecret <- \"HAN0d943eDJFzmDpUrdSCcfWftkWnpJiaiMWCEGLylIHv\"\n\n#Create a token with the create_token function\n\ntoken <- create_token(\n  app = \"RPackageTest\",\n  consumer_key = apikey,\n  consumer_secret = apisecret,\n  access_token = accestoken,\n  access_secret = accesssecret)\n\ntoken\n#Get a list of friends for the @DataSciColumbia account\nfriends <- get_friends(\"DataSciColumbia\")\nmultifriends <- get_friends(c(\"Columbia\", \"DataSciColumbia\")) #Note you can pass multiple handles at the same time\n\n#Get a list of followers of the @DataSciColumbia account\nfollowers <- get_followers(\"DataSciColumbia\")\n\ndatatable(friends)\ndatatable(multifriends)\ndatatable(followers)\nusers <- c(followers$user_id)\nlookup_users(users[0:10]) #get information on 10 users that follow @DataSciColumbia\n# search tweets for a keyword or phrase\nsearch_tweets(q = \"Columbia Data Science\")\n#You can even specify the language or whether you want to include retweets\nsearch_tweets(\"Columbia Data Science\", lang = \"en\", include_rts = FALSE)\n\n#If you have just the status IDs, you can use the lookup_tweets() function to get number of tweets. \nlookup_tweets(c(\"1454214453990416386\", \"1454213087473672194\"))\n\n#If you have just the user handle, you can also look up what tweets a user have favorited.\nfavorites <- get_favorites(\"DataSciColumbia\", n = 3000)\nts_plot(favorites, \"weeks\")\n#Search for tweets that mention @DataSciColumbia\ntweets <- search_tweets(\"@DataSciColumbia\",n=1000,include_rts = FALSE,retryonratelimit=F)\n\n#Show a preview of screen names and tweets\npreview <- tweets %>% dplyr::select(screen_name,text)\ndatatable(preview)\n\n#Pull all the hashtags associated with the tweets\nhash <- tweets %>% dplyr::select(created_at,screen_name,hashtags)\nhash <- unnest(hash,cols=c(hashtags))\n\n#Get a list of all the hashtags and count by frequency\ntophash <- hash %>% filter(is.na(hashtags)==F) %>% \n            group_by(hashtags) %>% \n            summarise(count=n()) %>%\n            arrange(-count) %>%\n            arrange(count) %>% \n            mutate(hashtags=factor(hashtags,levels=hashtags))\n\n#Plot the hashtags in a geom bar chart\nggplot(tophash,aes(x=hashtags,y=count)) + geom_bar(stat='identity') + \n    ggtitle(label=\"Most popular hashtags that menioned @DataSciColumbia\") +\n    coord_flip()"},{"path":"introduction-to-data-manipulation.html","id":"introduction-to-data-manipulation","chapter":"26 Introduction to Data Manipulation","heading":"26 Introduction to Data Manipulation","text":"Yuhe Wang","code":"\nlibrary(tidyverse)\nlibrary(fueleconomy)\nlibrary(tidyverse)\nlibrary(lubridate)"},{"path":"introduction-to-data-manipulation.html","id":"data-wrangling-with-dplyr","chapter":"26 Introduction to Data Manipulation","heading":"26.1 Data Wrangling with dplyr","text":"","code":""},{"path":"introduction-to-data-manipulation.html","id":"pipe","chapter":"26 Introduction to Data Manipulation","heading":"26.1.1 Pipe:","text":"use %>% pipeline. %>% operation(…) == operation(, ….)","code":""},{"path":"introduction-to-data-manipulation.html","id":"tibble-6","chapter":"26 Introduction to Data Manipulation","heading":"26.1.2 Tibble","text":"Tibble type data structure similar data frame base R.Compared normal dataframee, tibble never changes type input, names variables, row names.","code":"\ntibble(x=1:5, y=1,z=x^2+y)## # A tibble: 5 × 3\n##       x     y     z\n##   <int> <dbl> <dbl>\n## 1     1     1     2\n## 2     2     1     5\n## 3     3     1    10\n## 4     4     1    17\n## 5     5     1    26"},{"path":"introduction-to-data-manipulation.html","id":"pick-observations-with-filter","chapter":"26 Introduction to Data Manipulation","heading":"26.1.3 Pick observations with filter()","text":"R provides standard suites: <, >=, <=, !=, ==, %% apply conditions rows","code":"\nvehicles %>% filter(year>1999)## # A tibble: 16,649 × 12\n##       id make  model  year class   trans   drive     cyl displ fuel    hwy   cty\n##    <dbl> <chr> <chr> <dbl> <chr>   <chr>   <chr>   <dbl> <dbl> <chr> <dbl> <dbl>\n##  1 16573 Acura 3.2CL  2001 Compac… Automa… Front-…     6   3.2 Prem…    27    17\n##  2 17489 Acura 3.2CL  2002 Compac… Automa… Front-…     6   3.2 Prem…    27    17\n##  3 18458 Acura 3.2CL  2003 Compac… Manual… Front-…     6   3.2 Prem…    26    17\n##  4 18459 Acura 3.2CL  2003 Compac… Automa… Front-…     6   3.2 Prem…    27    17\n##  5 15871 Acura 3.2TL  2000 Midsiz… Automa… Front-…     6   3.2 Prem…    27    17\n##  6 16734 Acura 3.2TL  2001 Midsiz… Automa… Front-…     6   3.2 Prem…    27    17\n##  7 17664 Acura 3.2TL  2002 Midsiz… Automa… Front-…     6   3.2 Prem…    27    17\n##  8 18629 Acura 3.2TL  2003 Midsiz… Automa… Front-…     6   3.2 Prem…    27    17\n##  9 15872 Acura 3.5RL  2000 Midsiz… Automa… Front-…     6   3.5 Prem…    22    16\n## 10 16735 Acura 3.5RL  2001 Midsiz… Automa… Front-…     6   3.5 Prem…    22    16\n## # … with 16,639 more rows"},{"path":"introduction-to-data-manipulation.html","id":"reorder-rows-with-arrange","chapter":"26 Introduction to Data Manipulation","heading":"26.1.4 Reorder rows with arrange()","text":"","code":"\nvehicles %>% arrange(year,class,trans)## # A tibble: 33,442 × 12\n##       id make      model   year class  trans drive   cyl displ fuel    hwy   cty\n##    <dbl> <chr>     <chr>  <dbl> <chr>  <chr> <chr> <dbl> <dbl> <chr> <dbl> <dbl>\n##  1 27049 Buick     Elect…  1984 Large… Auto… 2-Wh…     6   4.1 Regu…    19    14\n##  2 27050 Buick     Elect…  1984 Large… Auto… 2-Wh…     8   5   Regu…    20    14\n##  3 27051 Buick     Elect…  1984 Large… Auto… 2-Wh…     8   5.7 Dies…    26    18\n##  4 27057 Cadillac  Broug…  1984 Large… Auto… Rear…     8   4.1 Regu…    19    14\n##  5 27058 Cadillac  Broug…  1984 Large… Auto… Rear…     8   5.7 Dies…    26    18\n##  6 28105 Cadillac  Broug…  1984 Large… Auto… Rear…     8   4.1 Regu…    19    14\n##  7 28106 Cadillac  Fleet…  1984 Large… Auto… Rear…     6   4.3 Dies…    31    21\n##  8 28225 Chevrolet S10 P…  1984 Small… Auto… 2-Wh…     4   2   Regu…    24    18\n##  9 27219 Dodge     Ram 5…  1984 Small… Auto… 2-Wh…     4   2   Regu…    21    20\n## 10 27220 Dodge     Ram 5…  1984 Small… Auto… 2-Wh…     4   2   Regu…    20    18\n## # … with 33,432 more rows"},{"path":"introduction-to-data-manipulation.html","id":"create-new-variables-using-mutate","chapter":"26 Introduction to Data Manipulation","heading":"26.1.5 Create new variables using mutate()","text":"","code":"\nvehicles %>% mutate(cyl_2 = cyl*2)## # A tibble: 33,442 × 13\n##       id make  model  year class trans drive   cyl displ fuel    hwy   cty cyl_2\n##    <dbl> <chr> <chr> <dbl> <chr> <chr> <chr> <dbl> <dbl> <chr> <dbl> <dbl> <dbl>\n##  1 13309 Acura 2.2C…  1997 Subc… Auto… Fron…     4   2.2 Regu…    26    20     8\n##  2 13310 Acura 2.2C…  1997 Subc… Manu… Fron…     4   2.2 Regu…    28    22     8\n##  3 13311 Acura 2.2C…  1997 Subc… Auto… Fron…     6   3   Regu…    26    18    12\n##  4 14038 Acura 2.3C…  1998 Subc… Auto… Fron…     4   2.3 Regu…    27    19     8\n##  5 14039 Acura 2.3C…  1998 Subc… Manu… Fron…     4   2.3 Regu…    29    21     8\n##  6 14040 Acura 2.3C…  1998 Subc… Auto… Fron…     6   3   Regu…    26    17    12\n##  7 14834 Acura 2.3C…  1999 Subc… Auto… Fron…     4   2.3 Regu…    27    20     8\n##  8 14835 Acura 2.3C…  1999 Subc… Manu… Fron…     4   2.3 Regu…    29    21     8\n##  9 14836 Acura 2.3C…  1999 Subc… Auto… Fron…     6   3   Regu…    26    17    12\n## 10 11789 Acura 2.5TL  1995 Comp… Auto… Fron…     5   2.5 Prem…    23    18    10\n## # … with 33,432 more rows"},{"path":"introduction-to-data-manipulation.html","id":"create-new-calculations-by-catgories-using-summarize","chapter":"26 Introduction to Data Manipulation","heading":"26.1.6 Create new calculations by catgories using summarize()","text":"can use summarize get statistics different groups. following example, getting average difference air time scheduled air time, grouped different carriers. Note add “na.rm” inside functio remove NA, else see lot NAs.\nCommon operation functions:\nsd(x): standard deviation\nmean(x): mean\nIQR(x): interquartile range\nmad(x): median absolute deviation\nmin(x): min\nquantile(x, 0.5): ith quartile\nmax(x): max\nfirst(x): first row\nnth(x,1): nth row\nlast(): last row\nn(): count\nn_distinct(x): count distinct\nsum(): sum","code":"\nvehicles %>% group_by(class, fuel) %>% summarize(mean_cty =mean(cty, na.rm = TRUE))## # A tibble: 151 × 3\n## # Groups:   class [34]\n##    class        fuel                       mean_cty\n##    <chr>        <chr>                         <dbl>\n##  1 Compact Cars CNG                            24.5\n##  2 Compact Cars Diesel                         29.2\n##  3 Compact Cars Electricity                   110  \n##  4 Compact Cars Gasoline or E85                21.9\n##  5 Compact Cars Midgrade                       16  \n##  6 Compact Cars Premium                        17.6\n##  7 Compact Cars Premium Gas or Electricity     35  \n##  8 Compact Cars Premium or E85                 17.2\n##  9 Compact Cars Regular                        21.1\n## 10 Large Cars   CNG                            13.6\n## # … with 141 more rows"},{"path":"introduction-to-data-manipulation.html","id":"tidy-data-with-dplyr","chapter":"26 Introduction to Data Manipulation","heading":"26.2 Tidy Data with dplyr","text":"","code":""},{"path":"introduction-to-data-manipulation.html","id":"gatherspread","chapter":"26 Introduction to Data Manipulation","heading":"26.2.1 Gather/Spread","text":"can reshape table wide format long format using Gather. can reshape table wide format long format using Sprea vice versa. (following example untrue data)","code":"\nt1 <- tibble(country=c('China', 'US', 'Korea'), `1999` = c(123,323,4245),`2000` = c(12,32,424))\nt1## # A tibble: 3 × 3\n##   country `1999` `2000`\n##   <chr>    <dbl>  <dbl>\n## 1 China      123     12\n## 2 US         323     32\n## 3 Korea     4245    424\nt1 %>% gather(`1999`, `2000`,key='year',value = 'GDP')## # A tibble: 6 × 3\n##   country year    GDP\n##   <chr>   <chr> <dbl>\n## 1 China   1999    123\n## 2 US      1999    323\n## 3 Korea   1999   4245\n## 4 China   2000     12\n## 5 US      2000     32\n## 6 Korea   2000    424"},{"path":"introduction-to-data-manipulation.html","id":"seperateunite","chapter":"26 Introduction to Data Manipulation","heading":"26.2.2 Seperate/Unite","text":"can combine/separate values one column two, two one(using special characters). can add parameter “convert=TRUE” convert chars integer directly.","code":"\nt2 <- tibble(country=c('China', 'US', 'Korea'), rate=c('12/232','123/20384','2328/2301823'))\nt2 %>% separate(rate,into=c(\"numerator\", \"denominator\"),convert=TRUE)## # A tibble: 3 × 3\n##   country numerator denominator\n##   <chr>       <int>       <int>\n## 1 China          12         232\n## 2 US            123       20384\n## 3 Korea        2328     2301823"},{"path":"introduction-to-data-manipulation.html","id":"relational-data-with-dplyr","chapter":"26 Introduction to Data Manipulation","heading":"26.3 Relational Data with dplyr","text":"","code":""},{"path":"introduction-to-data-manipulation.html","id":"prerequisites","chapter":"26 Introduction to Data Manipulation","heading":"26.3.1 prerequisites","text":"KEYS DBMS attribute set attributes helps identify row relation. primary key uniquely identifies observation. foreign key uniquely identify observation another table. Join two table usually takes place two keys within different tables ensure single join.","code":""},{"path":"introduction-to-data-manipulation.html","id":"understanding-different-types-of-joins","chapter":"26 Introduction to Data Manipulation","heading":"26.3.2 Understanding different types of joins","text":"x () y\ninner join: return matching pairs existing tables\nleft join: keep observations x\nright join: keep observations y\nfull join:keep observations x y\nNote one tables can duplicate keys. tables duplicate keys, cause error. Usually, duplicate key one table can produce unexpected result. , best practice investigate tables firstly joining.case two tables different names keys, can use =c(“”=“b”)","code":"\n# These data are frictional \nx <- tibble(Country = c('China','US','Japan','Canada'), population=c(100,200,300,400))\ny <- tibble(Country = c('China','US','Japan','Mexico'), GDP=c(100,23,2142,234))\nleft_join(x, y, by='Country')## # A tibble: 4 × 3\n##   Country population   GDP\n##   <chr>        <dbl> <dbl>\n## 1 China          100   100\n## 2 US             200    23\n## 3 Japan          300  2142\n## 4 Canada         400    NA\nright_join(x, y, by='Country')## # A tibble: 4 × 3\n##   Country population   GDP\n##   <chr>        <dbl> <dbl>\n## 1 China          100   100\n## 2 US             200    23\n## 3 Japan          300  2142\n## 4 Mexico          NA   234\ninner_join(x, y, by='Country')## # A tibble: 3 × 3\n##   Country population   GDP\n##   <chr>        <dbl> <dbl>\n## 1 China          100   100\n## 2 US             200    23\n## 3 Japan          300  2142\nfull_join(x, y, by='Country')## # A tibble: 5 × 3\n##   Country population   GDP\n##   <chr>        <dbl> <dbl>\n## 1 China          100   100\n## 2 US             200    23\n## 3 Japan          300  2142\n## 4 Canada         400    NA\n## 5 Mexico          NA   234"},{"path":"introduction-to-data-manipulation.html","id":"datetime-with-lubridate","chapter":"26 Introduction to Data Manipulation","heading":"26.4 Datetime with Lubridate","text":"","code":"\nlibrary(tidyverse)\nlibrary(lubridate)"},{"path":"introduction-to-data-manipulation.html","id":"datetime-from-strings","chapter":"26 Introduction to Data Manipulation","heading":"26.4.1 Datetime from strings","text":"Lubridate able parse different format datetime stringsGetting components datetime","code":"\nymd('2020-01-01')## [1] \"2020-01-01\"\nmdy('March 1 2021')## [1] \"2021-03-01\"\ndmy('02/01/2020')## [1] \"2020-01-02\"\nt <- ymd_hms('2020-01-01 12:00:00')\nyear(t)## [1] 2020\nmonth(t)## [1] 1\n# day of the month\nmday(t)## [1] 1\n# day of the year\nyday(t)## [1] 1\n# day of the week\nwday(t)## [1] 4\nhour(t)## [1] 12\nminute(t)## [1] 0\nsecond(t)## [1] 0"},{"path":"introduction-to-data-manipulation.html","id":"timespan","chapter":"26 Introduction to Data Manipulation","heading":"26.4.2 Timespan","text":"Duration: exact number seconds\nPeriods: human units (week months)\nIntervals: starting ending pointDurationPeriods","code":"\ndminutes(10)## [1] \"600s (~10 minutes)\"\ndweeks(3)## [1] \"1814400s (~3 weeks)\"\ndyears(1)## [1] \"31557600s (~1 years)\"\nseconds(15)## [1] \"15S\"\ndays(7)## [1] \"7d 0H 0M 0S\"\nmonths(1:6)## [1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\" \"4m 0d 0H 0M 0S\"\n## [5] \"5m 0d 0H 0M 0S\" \"6m 0d 0H 0M 0S\"\nyears(1)/days(1)## [1] 365.25\ntoday() + years(1)## [1] \"2022-11-07\""},{"path":"introduction-to-data-manipulation.html","id":"string-manipulations-with-stringr","chapter":"26 Introduction to Data Manipulation","heading":"26.5 String manipulations with stringr","text":"","code":""},{"path":"introduction-to-data-manipulation.html","id":"matching-patterns","chapter":"26 Introduction to Data Manipulation","heading":"26.5.1 Matching Patterns","text":"can regular expression matching R easily .\nstring_view() useful function showcase string patterns. first input input variable, second input string trying match. following regular expression matches introduced using method.can match substring directly easily.can use ‘.’ wildcard match characterWe can use ‘^’ match string starting “”, “$” find string ending “”. can also use ‘^’ beginning “$” end make sure ’s exact match.can also specify many times character repeats . {n} represents exactly n times repetition,{n,}: n , {,n}: n, {n,m}: n mThere also extra type strings can match characters mentioned. ‘\\d’ matches digit,‘\\s’ matches white space, [xyz] matches x, y z, [^xyz] matches anything x, y z. noticing want match substring starting one backlash, specify two backlashes string matching.introduce couple methods useful conjunction use regular expression.\n1.str_detect(): see detect certain substring, return TRUE FALSE\n2.str_extract(): extract actual substring string\n3.str_subset(): return group strings matches certain pattern\n4.str_count(): count number substring appearances string\n5.str_replace(): replace substrings certain patterns\n6.str_split(): split string according patternsSource: R Data Science","code":"\na <-c('root', 'create','time','death')\nstr_view(a, \"ea\")\na <-c('root', 'create','time','death')\nstr_view(a, \"im.\")\na <-c('root', 'create','time','death','eath')\nstr_view(a, \"^c\")\nstr_view(a, \"^death$\")\nstr_view(a, \"e$\")\na <-'CCccoljenlq'\nstr_view(a, 'C{2}')\na <- 'xeqowhe22'\nstr_view(a, '\\\\d{2}')\nstr_view(a, '[xyz]')\nstr_detect(c('case','happy','sad'), '[ey]$')## [1]  TRUE  TRUE FALSE\nstr_extract_all(c('case','happy','sad'), '[ey]$')## [[1]]\n## [1] \"e\"\n## \n## [[2]]\n## [1] \"y\"\n## \n## [[3]]\n## character(0)\nstr_subset(c('case','happy','sad'), '[ey]$')## [1] \"case\"  \"happy\"\na <- 'laaalk3kr23'\nstr_count(a,'[al]{3}')## [1] 1\na <- 'laaalk3kr23'\nstr_replace(a,'[al]{3}','happy')## [1] \"happyalk3kr23\"\nstr_split('abc def',' ')## [[1]]\n## [1] \"abc\" \"def\""},{"path":"animating-the-plots-in-r.html","id":"animating-the-plots-in-r","chapter":"27 Animating the plots in R","heading":"27 Animating the plots in R","text":"SeokHyun Kim","code":""},{"path":"animating-the-plots-in-r.html","id":"introduction-3","chapter":"27 Animating the plots in R","heading":"27.1 Introduction","text":"gganimate interesting extension ggplot2 package create plots vivid animation R. community contribution project , ’ll show animate plots ggplot2 using strong features gganimate. can also customize graph change time using extension.","code":""},{"path":"animating-the-plots-in-r.html","id":"motivation-1","chapter":"27 Animating the plots in R","heading":"27.2 Motivation","text":"check url . amazing plots using gganimate!Links fancy fireworksCan imagine cool fireworks made using gganimate? Right saw plot website, truly impressed gganimate package can decided share great visualization package others!","code":""},{"path":"animating-the-plots-in-r.html","id":"load-required-packages","chapter":"27 Animating the plots in R","heading":"27.3 Load required packages","text":"","code":"\nlibrary(tidyverse)\nlibrary(gganimate) # main package I'll cover\nlibrary(nord) # color palettes\nlibrary(gifski) # convert image frames to high quality GIF\nlibrary(viridis) # generate color maps\nlibrary(colorspace) # toolbox for selecting colors"},{"path":"animating-the-plots-in-r.html","id":"dataset","chapter":"27 Animating the plots in R","heading":"27.4 Dataset","text":"","code":"\n# I've created dataframe named df which contains speed, strength, win information of each person through year\nhead(df, 10)##    win strength speed year name\n## 1   23       32    17 1995 John\n## 2    2       66    24 1996 John\n## 3    8       57    23 1997 John\n## 4    9       22    25 1998 John\n## 5    6       17    16 1999 John\n## 6   17       25    20 2000 John\n## 7   13       87    21 2001 John\n## 8   21       32    24 2002 John\n## 9    5       65    18 2003 John\n## 10   9       49    21 2004 John\n# Below code is used for creating each features\n# win <- sample(x=1:30, size=27, replace=T)\n# strength  <- sample(x=1:100, size=27, replace=T)\n# speed <- sample(x=15:25, size=27, replace=T)\n# year <- seq(1995, 2021)"},{"path":"animating-the-plots-in-r.html","id":"understanding-transition_states-in-gganimate","chapter":"27 Animating the plots in R","heading":"27.5 Understanding transition_states() in gganimate","text":"transition_states() function gganimate package animates plot based specific variable. (Transition several distinct states data). specifying variable, basis, can obtain GIF image video representing transition time states.","code":""},{"path":"animating-the-plots-in-r.html","id":"transition_states-usage","chapter":"27 Animating the plots in R","heading":"27.5.1 transition_states() Usage","text":"transition_length : relative length transitionstate_length : relative length state","code":"\nggplot(dataframe, aes(x=variable1, y=variable2, ...))+\n  geom_graph(...)+\n  transition_states(variable3,\n                    transition_length=...,\n                    state_length=...)"},{"path":"animating-the-plots-in-r.html","id":"transition_states-examples","chapter":"27 Animating the plots in R","heading":"27.5.2 transition_states() Examples","text":"","code":"\n# Example 1 - barplot\n# Before adding transition_states()\nggplot(df, aes(x=name, y=win, fill=name))+\n  geom_col(show.legend=FALSE)+\n  scale_fill_nord('afternoon_prarie')+\n  theme_minimal()+\n  facet_wrap(~year)\n# Example 1 - barplot\n# After adding transition_states()\nggplot(df, aes(x=name, y=win, fill=name))+\n  geom_col(show.legend=FALSE)+\n  scale_fill_nord('afternoon_prarie')+\n  theme_minimal()+\n  transition_states(year,\n                    transition_length=1.5,\n                    state_length=0.5)\n# Example 2 - scatterplot\n# Before adding transition_states()\nggplot(df, aes(x=win, y=strength, color=name))+\n  geom_point(size=5, alpha=0.5)+\n  scale_color_viridis(option='plasma', discrete=TRUE)+\n  theme_minimal()+\n  theme(legend.position='bottom')\n# Example 2 - scatterplot\n# After adding transition_states()\nggplot(df, aes(x=win, y=strength, color=name))+\n  geom_point(size=5, alpha=0.5)+\n  scale_color_viridis(option='plasma', discrete=TRUE)+\n  theme_minimal()+\n  theme(legend.position='bottom')+\n  transition_states(year,\n                    transition_length=1.2,\n                    state_length=0.2)"},{"path":"animating-the-plots-in-r.html","id":"understanding-transition_reveal-in-gganimate","chapter":"27 Animating the plots in R","heading":"27.6 Understanding transition_reveal() in gganimate","text":"transition_reveal() function gganimate package can create animation data continuously displayed time visualizing given Time Series data plot.","code":""},{"path":"animating-the-plots-in-r.html","id":"transition_reveal-usage","chapter":"27 Animating the plots in R","heading":"27.6.1 transition_reveal() Usage","text":"","code":"\nggplot(dataframe, aes(x=variable1, y=variable2, group=variable3, ...))+\n  geom_line()+\n  geom_point()+\n  ... +\n  transition_reveal(variable1)"},{"path":"animating-the-plots-in-r.html","id":"transition_reveal-examples","chapter":"27 Animating the plots in R","heading":"27.6.2 transition_reveal() Examples","text":"","code":"\n# Before adding transition_reveal()\nggplot(df, aes(x=year, y=win, group=name, color=name))+\n  geom_line()+\n  geom_point()+\n  scale_color_discrete_sequential('Sunset')+\n  theme_minimal()+\n  theme(legend.position='bottom')\n# After adding transition_reveal()\nggplot(df, aes(x=year, y=win, group=name, color=name))+\n  geom_line()+\n  geom_point()+\n  scale_color_discrete_sequential('Sunset')+\n  theme_minimal()+\n  theme(legend.position='bottom')+\n  transition_reveal(year)"},{"path":"animating-the-plots-in-r.html","id":"understanding-transition_time-in-gganimate","chapter":"27 Animating the plots in R","heading":"27.7 Understanding transition_time() in gganimate","text":"transition_time() function gganimate package variant transition_states(), tool visualizing dataframe indicating state specific point animation plot.","code":""},{"path":"animating-the-plots-in-r.html","id":"transition_time-usage","chapter":"27 Animating the plots in R","heading":"27.7.1 transition_time() Usage","text":"length time switched states set proportional interval actual time states. Therefore, one best way visualize data changes time.","code":"\nggplot(dataframe, aes(variable1, variable2, ...), ...)+\n  geom_point(...)+\n  transition_time(variable3)"},{"path":"animating-the-plots-in-r.html","id":"transition_time-examples","chapter":"27 Animating the plots in R","heading":"27.7.2 transition_time() Examples","text":"","code":"\n# Before adding transition_time()\nggplot(df, aes(x=strength, y=win, color=name, size=speed))+\n  geom_point(alpha=0.7)+\n  scale_color_discrete_sequential('Purple-Yellow', rev=FALSE)+\n  scale_y_log10()+\n  scale_size(range=c(3,10))+\n  theme_minimal()+\n  theme(legend.position='bottom')\n# After adding transition_time()\nggplot(df, aes(x=strength, y=win, color=name, size=speed))+\n  geom_point(alpha=0.7)+\n  scale_color_discrete_sequential('Purple-Yellow', rev=FALSE)+\n  scale_y_log10()+\n  scale_size(range=c(3,10))+\n  theme_minimal()+\n  theme(legend.position='bottom')+\n  labs(title='Year: {frame_time}')+\n  transition_time(year)"},{"path":"animating-the-plots-in-r.html","id":"understanding-shadow_wake-in-gganimate","chapter":"27 Animating the plots in R","heading":"27.8 Understanding shadow_wake() in gganimate","text":"shadow_wake() function used transition_time() transition_reveal() shadow place changing data passed. can set gradually reduce size, color, transparency shadow.","code":""},{"path":"animating-the-plots-in-r.html","id":"shadow_wake-usage","chapter":"27 Animating the plots in R","heading":"27.8.1 shadow_wake() Usage","text":"length shadow can set relative ratio total length animation, frame.","code":"\nggplot(dataframe, aes(x=variable1, y=variable2, ...))+\n  geom_point()+\n  ...+\n  transition_함수(variable3)+\n  shadow_wake(wake_length=0.1, alpha=0)"},{"path":"animating-the-plots-in-r.html","id":"shadow_wake-examples","chapter":"27 Animating the plots in R","heading":"27.8.2 shadow_wake() Examples","text":"","code":"\n# Before adding shadow_wake()\nggplot(df)+\n  geom_point(aes(x=strength, y=win, size=speed, color=name))+\n  scale_color_viridis(option='viridis', discrete=TRUE)+\n  scale_x_log10()+\n  scale_size(range=c(1, 3))+\n  theme_minimal()+\n  theme(legend.position='bottom')\n# After adding shadow_wake()\nggplot(df)+\n  geom_point(aes(x=strength, y=win, size=speed, color=name))+\n  scale_color_viridis(option='viridis', discrete=TRUE)+\n  scale_x_log10()+\n  scale_size(range=c(1, 3))+\n  theme_minimal()+\n  theme(legend.position='bottom')+\n  transition_reveal(year)+\n  shadow_wake(wake_length=0.1,\n              alpha=0, \n              size=2)"},{"path":"animating-the-plots-in-r.html","id":"conclusion-2","chapter":"27 Animating the plots in R","heading":"27.9 Conclusion","text":"covered making animated barplot, scatterplot, timeseries also shadow using gganimate, just tip iceberg awesome package can . realized project flexibility gganimate. Even data, can generate lot different types plots also get image video file gganimate. next time, chance work project regarding gganimate , instead using standardized numeric data, ’ll challenge completely new way visualization, example fireworks. encourage dive deep gganimate !","code":""},{"path":"animating-the-plots-in-r.html","id":"citation","chapter":"27 Animating the plots in R","heading":"27.10 Citation","text":"https://www.data-imaginist.com/2019/gganimate--transitioned---state--release/https://www.data-imaginist.com/2019/gganimate--transitioned---state--release/https://gganimate.com/https://gganimate.com/","code":""},{"path":"data-science-product-cycles-in-enterprises.html","id":"data-science-product-cycles-in-enterprises","chapter":"28 Data Science Product Cycles in Enterprises","heading":"28 Data Science Product Cycles in Enterprises","text":"Leo Du Hao LiAs Data Science students, typically work carefully prepared data problem sets professors designed lots effort guide students achieve learning objectives can mostly clearly measured within reasonable timeline. However, reality, almost never seamless achieve results. delivered Zoom talk Nov. 1st share unique perspectives different stages typical development life cycle Data Science powered products large enterprises, different teams involved, technologies often used, visualization tools techniques leveraged different stages.Due policies, share materials publicly. slide deck, well recording session available Courseworks submission, students taking EDAV Fall 2021 upon request.","code":""},{"path":"github-initial-setup.html","id":"github-initial-setup","chapter":"29 Github initial setup","heading":"29 Github initial setup","text":"Joyce Robbins","code":""},{"path":"github-initial-setup.html","id":"create-new-repo","chapter":"29 Github initial setup","heading":"29.1 Create new repo","text":"Create new repository copying template: http://www.github.com/jtr13/cctemplate following instructions README.","code":""},{"path":"github-initial-setup.html","id":"pages-in-repo-settings","chapter":"29 Github initial setup","heading":"29.2 Pages in repo settings","text":"Change source gh-pagesMay trigger GHA get work","code":""},{"path":"github-initial-setup.html","id":"add-packages-to-description-file","chapter":"29 Github initial setup","heading":"29.3 Add packages to DESCRIPTION file","text":"Need better process…Downloaded submissions CourseWorksCreate DESCRIPTION file. Add add dependencies projthis::proj_update_deps()https://twitter.com/ijlyttle/status/1370776366585614342Add Imports real DESCRIPTION file.Found problematic packages looking reverse dependencies packages failed install:devtools::revdep()Also used pak::pkg_deps_tree()Problems:magickrJava dependency qdap","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"tutorial-for-pull-request-mergers","chapter":"30 Tutorial for pull request mergers","heading":"30 Tutorial for pull request mergers","text":"","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"general","chapter":"30 Tutorial for pull request mergers","heading":"30.1 General","text":"following checklist steps perform merging pull request. point, ’re sure , request review one PR leaders.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-branch","chapter":"30 Tutorial for pull request mergers","heading":"30.2 Check branch","text":"PR submitted non-main branch.PR submitted main branch, provide instructions fix problem:Close PR.Close PR.Follow instructions forgetting branch committed pushed GitHub: https://edav.info/github#fixing-mistakesFollow instructions forgetting branch committed pushed GitHub: https://edav.info/github#fixing-mistakesIf trouble 2., delete local folder project, delete fork GitHub, start .trouble 2., delete local folder project, delete fork GitHub, start .Open new PR.Open new PR.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"examine-files-that-were-added-or-modified","chapter":"30 Tutorial for pull request mergers","heading":"30.3 Examine files that were added or modified","text":"ONE .Rmd file.ONE .Rmd file.additional resources resources/<project_name>/ folder.additional resources resources/<project_name>/ folder.files root directory besides .Rmd file.files root directory besides .Rmd file.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-.rmd-filename","chapter":"30 Tutorial for pull request mergers","heading":"30.4 Check .Rmd filename","text":".Rmd filename words joined underscores, white space. (Update: need branch name.).Rmd filename can contain lowercase letters. (Otherwise filenames sort nicely repo home page.)","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-.rmd-file-contents","chapter":"30 Tutorial for pull request mergers","heading":"30.5 Check .Rmd file contents","text":"file contain YAML header --- line.first line start single hashtag #, followed single whitespace, title.second line blank, followed author name(s).additional single hashtag headers chapter. (, new chapters created.)hashtag headers followed numbers since hashtags create numbered subheadings. Correct: ## Subheading. Incorrect: ## 3. Subheading.file contains setup chunk .Rmd file, contain setup label. (bookdown render fail duplicate chunk labels.)\n.e. use {r, include=FALSE} instead {r setup, include=FALSE}.\nSee sample .RmdLinks internal files must contain resources/<project_name>/ path, : ![Test Photo](resources/sample_project/election.jpg)file contain install.packages(), write functions, setwd(), getwd().’s anything else looks odd ’re sure, assign jtr13 review explain issue.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"request-changes","chapter":"30 Tutorial for pull request mergers","heading":"30.6 Request changes","text":"problems checks listed , explain pull request merged request changes following steps:, add changes requested label pull request.job pull request done now. contributors fix requests, review either move forward merge explain changes still need made.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"merge-the-pull-request","chapter":"30 Tutorial for pull request mergers","heading":"30.7 Merge the pull request","text":"good go, ’s time merge pull request. several steps.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"steps-to-merge-the-pr","chapter":"30 Tutorial for pull request mergers","heading":"30.7.1 Steps to Merge the PR","text":"Go main branch project (jtr13/cc21fall1) open _bookdown.yml fileGo main branch project (jtr13/cc21fall1) open _bookdown.yml fileCopy entire rmd_files section. look something like \nrmd_files: [ 'index.Rmd', # must first chapter 'assignment.Rmd', ...., ...., ]Copy entire rmd_files section. look something like \nrmd_files: [ 'index.Rmd', # must first chapter 'assignment.Rmd', ...., ...., ]Open branch submitted PR following steps:\naccess PR branch:\n\nMake sure PR branch checking PR branch name shown (main):\nOpen branch submitted PR following steps:access PR branch:Make sure PR branch checking PR branch name shown (main):Remove rmd_files: [] section paste one copied main branch project.Remove rmd_files: [] section paste one copied main branch project.Add name new file single quotes followed comma labelled section (eg. Cheatsheets, Tutorials etc).Add name new file single quotes followed comma labelled section (eg. Cheatsheets, Tutorials etc).Save edited version.Save edited version.Come back PR.Come back PR.Merge PR.Merge PR.Click Actions tabs check whether build successful (successful build green dot front actions). PLEASE NOTE actions take complete (approximately 5-6 mins depending number files rendered), might need wait time finally check whether build successful .Click Actions tabs check whether build successful (successful build green dot front actions). PLEASE NOTE actions take complete (approximately 5-6 mins depending number files rendered), might need wait time finally check whether build successful .case build fail able understand rectify please tag one PR Assigners can review . PLEASE revert merge create new branches workflow.case build fail able understand rectify please tag one PR Assigners can review . PLEASE revert merge create new branches workflow.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"pr-leaders-only-add-part-names-to-.rmd-for-every-first-article-in-part","chapter":"30 Tutorial for pull request mergers","heading":"30.7.2 PR Leaders only: Add part names to .Rmd for every first article in part","text":"adding first chapter PART.every first article part, add chapter name top .Rmd file, propose changes. example like .\n","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"merge-pr-and-leave-a-comment","chapter":"30 Tutorial for pull request mergers","heading":"30.7.3 Merge PR and leave a comment","text":"Now comes final step.develop experience confident things correctly, assign another PR merger review work:@aye21874 (Ayush), @clarissarjtai (Clarissa), @ejosied (Josie), @hwelinkim (Hyo Won), @ivanye2509 (Xin)\n@kfijan (Katharina), @ktsht (Alex), @mtz2110 (Maxwell), @s10singh97 (Shashwat), @ShiyuWang88 (Shiyu), @Shruti-Kaushal (Shruti), @verlocks (Zheyu)(Please fix names mistakes aren’t names go … don’t need submit pull request, just edit file commit main branch.)Go back conversation tab pull requests page, example:https://github.com/jtr13/cc20/pull/23#issuecomment-728506101Leave comments congratulations 🎉 (type :tada:) click green button merge.\n","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-updated-version","chapter":"30 Tutorial for pull request mergers","heading":"30.7.4 Check updated version","text":"successful merge means addition file files added project merge conflicts. mean book render deploy GitHub pages without issues. merge, take 5-10 minutes GitHub Actions render book deploy updated version. ’s problem notified email address . words, job done. However ’re interested, can check progress clicking Actions top repo.","code":""}]
